{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Chatbot Tutorial\n",
    "================\n",
    "**Author:** `Matthew Inkawhich <https://github.com/MatthewInkawhich>`_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we explore a fun and interesting use-case of recurrent\n",
    "sequence-to-sequence models. We will train a simple chatbot using movie\n",
    "scripts from the `Cornell Movie-Dialogs\n",
    "Corpus <https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__.\n",
    "\n",
    "Conversational models are a hot topic in artificial intelligence\n",
    "research. Chatbots can be found in a variety of settings, including\n",
    "customer service applications and online helpdesks. These bots are often\n",
    "powered by retrieval-based models, which output predefined responses to\n",
    "questions of certain forms. In a highly restricted domain like a\n",
    "company’s IT helpdesk, these models may be sufficient, however, they are\n",
    "not robust enough for more general use-cases. Teaching a machine to\n",
    "carry out a meaningful conversation with a human in multiple domains is\n",
    "a research question that is far from solved. Recently, the deep learning\n",
    "boom has allowed for powerful generative models like Google’s `Neural\n",
    "Conversational Model <https://arxiv.org/abs/1506.05869>`__, which marks\n",
    "a large step towards multi-domain generative conversational models. In\n",
    "this tutorial, we will implement this kind of model in PyTorch.\n",
    "\n",
    ".. figure:: /_static/img/chatbot/bot.png\n",
    "   :align: center\n",
    "   :alt: bot\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "  > hello?\n",
    "  Bot: hello .\n",
    "  > where am I?\n",
    "  Bot: you re in a hospital .\n",
    "  > who are you?\n",
    "  Bot: i m a lawyer .\n",
    "  > how are you doing?\n",
    "  Bot: i m fine .\n",
    "  > are you my friend?\n",
    "  Bot: no .\n",
    "  > you're under arrest\n",
    "  Bot: i m trying to help you !\n",
    "  > i'm just kidding\n",
    "  Bot: i m sorry .\n",
    "  > where are you from?\n",
    "  Bot: san francisco .\n",
    "  > it's time for me to leave\n",
    "  Bot: i know .\n",
    "  > goodbye\n",
    "  Bot: goodbye .\n",
    "\n",
    "**Tutorial Highlights**\n",
    "\n",
    "-  Handle loading and preprocessing of `Cornell Movie-Dialogs\n",
    "   Corpus <https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__\n",
    "   dataset\n",
    "-  Implement a sequence-to-sequence model with `Luong attention\n",
    "   mechanism(s) <https://arxiv.org/abs/1508.04025>`__\n",
    "-  Jointly train encoder and decoder models using mini-batches\n",
    "-  Implement greedy-search decoding module\n",
    "-  Interact with trained chatbot\n",
    "\n",
    "**Acknowledgements**\n",
    "\n",
    "This tutorial borrows code from the following sources:\n",
    "\n",
    "1) Yuan-Kuei Wu’s pytorch-chatbot implementation:\n",
    "   https://github.com/ywk991112/pytorch-chatbot\n",
    "\n",
    "2) Sean Robertson’s practical-pytorch seq2seq-translation example:\n",
    "   https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation\n",
    "\n",
    "3) FloydHub’s Cornell Movie Corpus preprocessing code:\n",
    "   https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparations\n",
    "------------\n",
    "\n",
    "To start, Download the data ZIP file\n",
    "`here <https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__\n",
    "and put in a ``data/`` directory under the current directory.\n",
    "\n",
    "After that, let’s import some necessities.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = []\n",
    "\n",
    "with open('glove/glove.6B.50d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "    \n",
    "#vectors = bcolz.carray(vectors[1:].reshape((400000, 50)), rootdir='../glove/6B.50.dat', mode='w')\n",
    "#vectors.flush()\n",
    "pickle.dump(words, open('glove/6B.50_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open('glove/6B.50_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pickle.load(open('glove/6B.50_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open('glove/6B.50_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & Preprocess Data\n",
    "----------------------\n",
    "\n",
    "The next step is to reformat our data file and load the data into\n",
    "structures that we can work with.\n",
    "\n",
    "The `Cornell Movie-Dialogs\n",
    "Corpus <https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__\n",
    "is a rich dataset of movie character dialog:\n",
    "\n",
    "-  220,579 conversational exchanges between 10,292 pairs of movie\n",
    "   characters\n",
    "-  9,035 characters from 617 movies\n",
    "-  304,713 total utterances\n",
    "\n",
    "This dataset is large and diverse, and there is a great variation of\n",
    "language formality, time periods, sentiment, etc. Our hope is that this\n",
    "diversity makes our model robust to many forms of inputs and queries.\n",
    "\n",
    "First, we’ll take a look at some lines of our datafile to see the\n",
    "original format.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/cornell movie-dialogs corpus/jokes-all-clean.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-eb71e20736e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprintLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jokes-all-clean.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-eb71e20736e5>\u001b[0m in \u001b[0;36mprintLines\u001b[0;34m(file, n)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/cornell movie-dialogs corpus/jokes-all-clean.txt'"
     ]
    }
   ],
   "source": [
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "printLines(os.path.join(corpus, \"jokes-all-clean.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create formatted data file\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "For convenience, we'll create a nicely formatted data file in which each line\n",
    "contains a tab-separated *query sentence* and a *response sentence* pair.\n",
    "\n",
    "The following functions facilitate the parsing of the raw\n",
    "*movie_lines.txt* data file.\n",
    "\n",
    "-  ``loadLines`` splits each line of the file into a dictionary of\n",
    "   fields (lineID, characterID, movieID, character, text)\n",
    "-  ``loadConversations`` groups fields of lines from ``loadLines`` into\n",
    "   conversations based on *movie_conversations.txt*\n",
    "-  ``extractSentencePairs`` extracts pairs of sentences from\n",
    "   conversations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits each line of the file into a dictionary of fields\n",
    "def loadLines(fileName, fields):\n",
    "    lines = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            lineObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "    return lines\n",
    "\n",
    "\n",
    "# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
    "def loadConversations(fileName, lines, fields):\n",
    "    conversations = []\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            convObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                convObj[field] = values[i]\n",
    "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "            lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "            # Reassemble lines\n",
    "            convObj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll call these functions and create the file. We’ll call it\n",
    "*formatted_movie_lines.txt*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fcb631c54ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define path to new file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatafile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"formatted_movie_lines.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Unescape the delimiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# Define path to new file\n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict, conversations list, and field ids\n",
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "\n",
    "# Load lines and process conversations\n",
    "print(\"\\nProcessing corpus...\")\n",
    "lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
    "print(\"\\nLoading conversations...\")\n",
    "conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n",
    "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extractSentencePairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "\n",
    "# Print a sample of lines\n",
    "print(\"\\nSample lines from file:\")\n",
    "printLines(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and trim data\n",
    "~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Our next order of business is to create a vocabulary and load\n",
    "query/response sentence pairs into memory.\n",
    "\n",
    "Note that we are dealing with sequences of **words**, which do not have\n",
    "an implicit mapping to a discrete numerical space. Thus, we must create\n",
    "one by mapping each unique word that we encounter in our dataset to an\n",
    "index value.\n",
    "\n",
    "For this we define a ``Voc`` class, which keeps a mapping from words to\n",
    "indexes, a reverse mapping of indexes to words, a count of each word and\n",
    "a total word count. The class provides methods for adding a word to the\n",
    "vocabulary (``addWord``), adding all words in a sentence\n",
    "(``addSentence``) and trimming infrequently seen words (``trim``). More\n",
    "on trimming later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "\n",
    "    source1 = open('jokes-all-clean.txt', encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    source1 = [normalizeString(s) for s in source1]\n",
    "    \n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [s.split(\". \", 1) for s in source1]\n",
    "    \n",
    "    pairs = [s  for s in pairs if len(s) == 2]\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'normalizeString' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-be0160297f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadVocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"story\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-91aeeb3428dc>\u001b[0m in \u001b[0;36mreadVocs\u001b[0;34m(corpus_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msource1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jokes-all-clean.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msource1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalizeString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-91aeeb3428dc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msource1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jokes-all-clean.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msource1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalizeString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalizeString' is not defined"
     ]
    }
   ],
   "source": [
    "len(readVocs(\"story\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can assemble our vocabulary and query/response sentence pairs.\n",
    "Before we are ready to use this data, we must perform some\n",
    "preprocessing.\n",
    "\n",
    "First, we must convert the Unicode strings to ASCII using\n",
    "``unicodeToAscii``. Next, we should convert all letters to lowercase and\n",
    "trim all non-letter characters except for basic punctuation\n",
    "(``normalizeString``). Finally, to aid in training convergence, we will\n",
    "filter out sentences with length greater than the ``MAX_LENGTH``\n",
    "threshold (``filterPairs``).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Reading lines...\n",
      "Read 9144 sentence pairs\n",
      "Trimmed to 9144 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 14403\n",
      "\n",
      "pairs:\n",
      "['i m glad to be on cable ', 'the truth is i ve dreamed of being a talk show host on basic cable ever since i was .']\n",
      "['it s not easy doing a late night show on a channel without a lot of money and that viewers have trouble finding ', 'so that s why i left nbc .']\n",
      "['earlier today former president george w ', 'bush appeared on oprah winfrey . when asked about being the leader of the free world oprah winfrey said it s not bad .']\n",
      "['apple just launched its online store in china ', 'apple says this is an exciting opportunity to sell ipods to the very kids who make them .']\n",
      "['a police officer in london is in trouble for allegedly slipping references to songs into his official reports ', 'authorities became suspicious when they read the part that said time of death i like big butts and i cannot lie .']\n",
      "['earlier this week angry demonstrators protested president obama s visit to indonesia ', 'apparently out of indonesians believe he s an american .']\n",
      "['amazon .com is coming under fire for selling a book about pedophilia ', 'if you think that s bad you should see what amazon says buyers of the book might also like .']\n",
      "['nasa is working on a robot capable of running the international space station ', 'the project was reported in the journal of things that could never possibly go wrong .']\n",
      "['it was recently announced that a fourth jason bourne movie will be made but without matt damon ', 'this one will be called the bourne straight to video .']\n",
      "['victoria s secret has unveiled a new million bra encrusted with diamonds topaz and sapphire ', 'they re calling it perfect for the woman who wants to get to second base with a gay man .']\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 300  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s.lower()\n",
    "\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "\n",
    "    source1 = open('jokes-all-clean.txt', encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    source1 = [normalizeString(s) for s in source1]\n",
    "    \n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [s.split(\". \", 1) for s in source1]\n",
    "    \n",
    "    pairs = [s  for s in pairs if len(s) == 2]\n",
    "    \n",
    "    \n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(\"story\", save_dir)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another tactic that is beneficial to achieving faster convergence during\n",
    "training is trimming rarely used words out of our vocabulary. Decreasing\n",
    "the feature space will also soften the difficulty of the function that\n",
    "the model must learn to approximate. We will do this as a two-step\n",
    "process:\n",
    "\n",
    "1) Trim words used under ``MIN_COUNT`` threshold using the ``voc.trim``\n",
    "   function.\n",
    "\n",
    "2) Filter out pairs with trimmed words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 14400 / 14400 = 1.0000\n",
      "Trimmed from 9144 pairs to 9144, 1.0000 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 1    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['PAD', 'SOS', 'EOS', '', 'chevrolet', 'doors', 'nutritious', 'nick', 'spinning', 'wonka', 'passengers', 'lengthen', 'hurting', 'coli', 'everest', 'differential', 'mosque', 'fries', 'portuguese', 'disappear', 'usually', 'whoopi', 'gotten', 'tsa', 'longevity', 'craigslist', 'burn', 'unbuttoning', 'arrest', 'brooklyn', 'rodrigo', 'visitors', 'bread', 'reads', 'hurricane', 'nice', 'chiefs', 'sesame', 'grandson', 'birth', 'councilman', 'philly', 'instance', 'resolution', 'ba', 'later', 'opportunity', 'marketing', 'defeating', 'someone', 'hostile', 'canerdians', 'curtain', 'pitcher', 'handlebar', 'hazed', 'racewalker', 'humanness', 'dancer', 'dustin', 'slam', 'media', 'argentinean', 'labeouf', 'its', 'antibiotics', 'ibiza', 'monitoring', 'ought', 'palin', 'shirtless', 'occupations', 'resist', 'caused', 'biathlon', 'matters', 'furious', 'cured', 'dignity', 'pakistan', 'rejected', 'zac', 'nfl', 'we', 'unreleased', 'prayers', 'unlocked', 'piglet', 'warhol', 'batcave', 'lithuania', 'carolina', 'said', 'ceiling', 'boyz', 'catalogs', 'vs', 'useless', 'lowers', 'armenia', 'talking', 'mcribs', 'positive', 'z', 'july', 'stirred', 'unzipped', 'virgins', 'developer', 'embroil', 'nabisco', 'urged', 'chapels', 'wesley', 'millennial', 'soon', 'chores', 'stoned', 'law', 'walks', 'parent', 'michelin', 'hiatus', 'initial', 'wander', 'depict', 'seals', 'spray', 'at', 'scale', 'heck', 'carpool', 'paramount', 'matter', 'lies', 'perimeter', 'winona', 'bickering', 'compact', 'taliban', 'respectful', 'particular', 'images', 'champagne', 'failed', 'coating', 'truman', 'california', 'diabetes', 'biggest', 'tourists', 'tips', 'issue', 'resign', 'irish', 'somewhat', 'prepared', 'piyush', 'jacket', 'pages', 'pantsuit', 'stem', 'abnormally', 'no', 'relate', 'unwittingly', 'binoculars', 'closure', 'backfiring', 'obama', 'rancher', 'cast', 'mahershala', 'pmsing', 'algebra', 'waterskiing', 'snooki', 'freemasons', 'should', 'alerts', 'hallway', 'divide', 'ginsburg', 'flood', 'unkind', 'specially', 'location', 'eddie', 'celebrities', 'motto', 'stand', 'exam', 'evacuating', 'tastykakes', 'contest', 'phoning', 'stickers', 'demi', 'rumored', 'fall', 'butter', 'cheer', 'accountable', 'inside', 'businesses', 'painted', 'franken', 'greco', 'airlifted', 'most', 'uranus', 'suspected', 'newcomer', 'already', 'desperately', 'godzilla', 'stiff', 'sporadically', 'chuck', 'latina', 'sarcasm', 'italians', 'gridlock', 'cocktails', 'fran', 'resigning', 'bobsledded', 'democrat', 'therapist', 'longest', 'nixon', 'chelsea', 'harold', 'arrangement', 'buckets', 'cannonball', 'amanda', 'slapped', 'paratroopers', 'sobriety', 'iqs', 'awoke', 'hum', 'brennan', 'wagon', 'city', 'item', 'sewer', 'lets', 'accompanied', 'filmmakers', 'wave', 'controlled', 'marino', 'relabeled', 'kind', 'governors', 'launcher', 'rogen', 'seacrest', 'cheerleaders', 'hipsters', 'knocks', 'analyst', 'prosthetic', 'baby', 'dairy', 'nova', 'snowboarding', 'prekoshus', 'flynn', 'jews', 'blind', 'sneaks', 'barbies', 'mural', 'shove', 'angela', 'whacked', 'mounted', 'veteran', 'celebrity', 'encouraging', 'cue', 'producers', 'joined', 'expressionless', 'prejudiced', 'minidress', 'oakwood', 'newsweek', 'repealed', 'billionaire', 'diner', 'sensual', 'doin', 'blindness', 'boss', 'caters', 'renamed', 'surreal', 'disneyland', 'link', 'forgave', 'hoda', 'appreciate', 'mic', 'lullabies', 'menorah', 'tough', 'perfected', 'unauthorized', 'month', 'present', 'endless', 'intentions', 'shoelaces', 'modifications', 'highlights', 'battling', 'approached', 'confidentiality', 'hugging', 'museum', 'bit', 'sheen', 'advocating', 'jintao', 'had', 'ripper', 'criabetes', 'fiberglass', 'mayans', 'engineers', 'pardons', 'measuring', 'marco', 'budweiser', 'exists', 'thought', 'christians', 'refusing', 'gaffe', 'periods', 'theater', 'protester', 'steroids', 'apparel', 'snake', 'wheel', 'unwatchable', 'plummeting', 'stricter', 'marcia', 'seuss', 'roadshow', 'beaches', 'sanded', 'chevron', 'civil', 'bottlenose', 'lapses', 'kermit', 'oakland', 'event', 'taxes', 'engaged', 'saw', 'abdominal', 'campaigned', 'nuclear', 'berkley', 'olives', 'signing', 'upsetting', 'farthest', 'saleh', 'demolished', 'stated', 'poorest', 'musician', 'joan', 'violating', 'dre', 'hearse', 'lambs', 'grow', 'sales', 'airlines', 'climaxes', 'cracking', 'proceeding', 'talent', 'missouri', 'folds', 'lobsters', 'urkel', 'midterms', 'mia', 'controller', 'deplorables', 'blend', 'downloading', 'pupils', 'boxers', 'everybody', 'abuser', 'overboard', 'ungroped', 'octopus', 'nightmare', 'scares', 'simplify', 'entry', 'intolerant', 'sick', 'levi', 'when', 'surgeries', 'kenny', 'kumar', 'pancakes', 'imitate', 'revival', 'torch', 'fits', 'jurassic', 'heinz', 'mortgage', 'mitzvah', 'herald', 'sherman', 'millions', 'plots', 'up', 'ghostbusters', 'defiance', 'exercises', 'theatre', 'sampling', 'chairman', 'shops', 'hand', 'rights', 'prerequisites', 'sprayed', 'angelina', 'skank', 'gracefully', 'substances', 'hunky', 'behind', 'fixing', 'clarity', 'colony', 'flies', 'vows', 'pills', 'watering', 'warding', 'intermingled', 'economist', 'camps', 'disgruntled', 'hungover', 'milky', 'playstation', 'mph', 'subscription', 'warrior', 'losangelescalifornia', 'wahlberg', 'tampon', 'guilt', 'python', 'divorced', 'round', 'tragically', 'bid', 'canceled', 'river', 'bronco', 'chicks', 'addicted', 'arizona', 'asking', 'appointing', 'unfriendly', 'capitols', 'studio', 'dedication', 'entered', 'afterall', 'fires', 'jepsen', 'noting', 'fcc', 'pearl', 'north', 'fee', 'pronoun', 'accomplishment', 'dream', 'generic', 'reformed', 'oatmeal', 'bloomingdales', 'ballads', 'platform', 'shouted', 'pathetic', 'wasted', 'tagg', 'googling', 'dubai', 'distraction', 'reply', 'accidently', 'makers', 'mouthguard', 'fantasizing', 'voice', 'self', 'conversations', 'able', 'measles', 'heading', 'quickly', 'narc', 'samuel', 'autumn', 'unfinished', 'rabbits', 'badmouthed', 'jayden', 'ski', 'upheld', 'signatures', 'siblings', 'scar', 'sabbath', 'cartel', 'rescuers', 'grandmothers', 'ferrari', 'craziest', 'intruders', 'reporting', 'tornado', 'downtown', 'conversation', 'mcdonalds', 'beckham', 'tortoise', 'spoken', 'strapped', 'laughter', 'kilo', 'sportsmanship', 'wished', 'breathing', 'accepting', 'gather', 'collision', 'situation', 'countries', 'panelists', 'jaws', 'conceive', 'complained', 'drowning', 'donations', 'centrifuges', 'desperate', 'cardiomyopathy', 'xie', 'howled', 'novelist', 'kids', 'boca', 'drug', 'aggressive', 'beep', 'colorblind', 'creationist', 'agassi', 'vomited', 'collection', 'script', 'small', 'sings', 'would', 'male', 'racist', 'napkin', 'eyed', 'buffering', 'turtles', 'rodeo', 'dorito', 'maher', 'reading', 'brosephus', 'fittest', 'recognized', 'overtime', 'cantor', 'stoner', 'lunch', 'cmt', 'roughly', 'philip', 'planned', 'teachers', 'ashleys', 'bathing', 'investigated', 'captures', 'disgusting', 'maury', 'advance', 'cartoons', 'overtaken', 'chillinois', 'pagers', 'subsidized', 'ditching', 'coins', 'carve', 'mideast', 'expense', 'domino', 'refrigerator', 'joaquin', 'prom', 'breaking', 'mugged', 'economic', 'heat', 'correspondents', 'marcus', 'inflammatory', 'carl', 'foods', 'dining', 'forgiven', 'fairy', 'oxfam', 'merkel', 'rendered', 'harm', 'sleepytime', 'aroused', 'poppins', 'customers', 'stroll', 'tramp', 'spencer', 'drinking', 'msnbc', 'lemonade', 'silence', 'benadryl', 'hunger', 'explain', 'feathered', 'construction', 'foreman', 'understood', 'farm', 'frownie', 'pms', 'snuck', 'departure', 'informing', 'beaker', 'shore', 'astros', 'batch', 'mar', 'amount', 'emma', 'donating', 'problem', 'medicines', 'expose', 'truckers', 'tunneled', 'market', 'richer', 'gov', 'homecoming', 'mattel', 'invitation', 'goodvibes', 'masturbate', 'ebola', 'pumping', 'polanski', 'comprised', 'traditional', 'hyped', 'rocks', 'armageddon', 'brandi', 'gooding', 'collaborate', 'booth', 'appear', 'exxon', 'futon', 'baldwin', 'trusts', 'eyes', 'animated', 'racehorse', 'physicist', 'convenience', 'abdul', 'discussing', '.s', 'staples', 'pressed', 'pried', 'mascot', 'embrace', 'you', 'mats', 'ethical', 'aliens', 'mainstream', 'placenta', 'tastic', 'staged', 'swears', 'avatars', 'valentine', 'earth', 'mushrooms', 'haywood', 'army', 'wrist', 'hack', 'meat', 'ass', 'elsa', 'visas', 'feet', 'terror', 'instagram', 'dazed', 'sounding', 'mattis', 'bookstore', 'hurt', 'rodriguez', 'plays', 'denial', 'electronic', 'contributors', 'nuh', 'toured', 'refuses', 'making', 'gnomes', 'trophy', 'soviet', 'captivity', 'cleared', 'nominees', 'types', 'flyer', 'hitchhiking', 'mcweirdhair', 'infant', 'immense', 'phrases', 'outlaw', 'ownership', 'explores', 'existence', 'captive', 'viewer', 'each', 'plant', 'healthiest', 'blacks', 'anyone', 'relinquish', 'increasing', 'supported', 'edge', 'exchanged', 'buggy', 'bodily', 'santos', 'barnum', 'gas', 'jumped', 'noticed', 'celebration', 'graduated', 'networking', 'butch', 'geckos', 'depressed', 'verizon', 'snowball', 'advocacy', 'filthy', 'lot', 'spitting', 'daytona', 'references', 'sneaker', 'produced', 'bain', 'burrito', 'population', 'caitlyn', 'convict', 'shelf', 'powered', 'evident', 'added', 'union', 'fe', 'containers', 'lounging', 'cubs', 'smashing', 'coney', 'devastated', 'encourage', 'brought', 'sunni', 'stupidest', 'qatar', 'celebrated', 'us', 'tsar', 'pads', 'malfunction', 'apprentices', 'logo', 'gained', 'trojan', 'gloves', 'mentioning', 'enterprise', 'important', 'anxiety', 'buzz', 'boneless', 'unity', 'wrong', 'whales', 'bars', 'spoke', 'wrapper', 'hammers', 'major', 'proudly', 'darryl', 'bag', 'donaldcare', 'morph', 'versailles', 'trust', 'football', 'effect', 'sterling', 'aaaay', 'deaf', 'directed', 'double', 'madea', 'vehicles', 'operation', 'tut', 'players', 'outer', 'flintstone', 'weaning', 'leader', 'suing', 'skirts', 'as', 'thief', 'armpits', 'beast', 'ribbed', 'critter', 'mad', 'but', 'wizard', 'averted', 'grandchildren', 'stormed', 'rats', 'strings', 'netanyahu', 'creates', 'false', 'offended', 'feingold', 'comments', 'tyler', 'severely', 'workers', 'gardener', 'guns', 'onion', 'saturday', 'dismissed', 'citi', 'coffee', 'grossly', 'allegiant', 'disaster', 'developers', 'forge', 'exposed', 'dumb', 'obrien', 'buzzkill', 'testicles', 'vetoed', 'framed', 'nba', 'chillax', 'contain', 'catching', 'turkeys', 'ringtone', 'oj', 'premium', 'professionalism', 'longform', 'lamppost', 'cubes', 'plagued', 'mchotvoice', 'impasse', 'mushroom', 'bacca', 'taken', 'scranton', 'threaten', 'approves', 'copsplaining', 'groundbreaking', 'bailey', 'atm', 'top', 'ref', 'describe', 'hollyweed', 'similarities', 'honeymoon', 'working', 'cellmates', 'hustler', 'blurred', 'mookie', 'misdemeanor', 'outlawed', 'hawking', 'countdown', 'bocelli', 'saucer', 'choreography', 'cookied', 'confront', 'gent', 'town', 'ill', 'autobiography', 'vanessa', 'partner', 'ankles', 'cellars', 'notify', 'locusts', 'statistics', 'hamburger', 'hold', 'submitted', 'priestly', 'family', 'proving', 'infidelity', 'pet', 'pension', 'penalty', 'moammar', 'minds', 'conflicted', 'quinn', 'taping', 'prescribing', 'mona', 'mcdaniels', 'flattered', 'cereals', 'tease', 'hours', 'www', 'broker', 'rumsfeld', 'unveiled', 'resorts', 'handling', 'tantrum', 'alito', 'salads', 'zikachu', 'hufflepuff', 'cause', 'leg', 'gayest', 'silvers', 'soldiers', 'cove', 'affects', 'el', 'islamic', 'interrupting', 'prototypes', 'worshipper', 'ming', 'prostitute', 'screw', 'threesome', 'accept', 'mittromney', 'masks', 'c', 'undermine', 'philanderer', 'attributes', 'envelopes', 'whore', 'recount', 'broadcasting', 'expelled', 'sites', 'thoughts', 'donald', 'abraham', 'filipino', 'psychotic', 'kisses', 'sharpee', 'comics', 'roof', 'unclear', 'rudimentary', 'cavity', 'pangaea', 'inn', 'attribute', 'privilege', 'cushions', 'sunglasses', 'promoting', 'aspirin', 'davidson', 'endowed', 'cyberbullied', 'pigeon', 'commit', 'ultrasound', 'beyonce', 'testicle', 'officers', 'dressage', 'ringling', 'techniques', 'congratulatory', 'astonishing', 'hypocrites', 'depicts', 'why', 'geniuses', 'transsexual', 'calorie', 'congratulations', 'confession', 'refuse', 'arsenio', 'juice', 'grip', 'wording', 'quade', 'elections', 'go', 'earthquake', 'arm', 'meal', 'mashed', 'runway', 'eco', 'worms', 'moon', 'papers', 'boarded', 'waiters', 'ashamed', 'living', 'dom', 'ball', 'laden', 'confessions', 'campbell', 'tumor', 'skip', 'nations', 'appliances', 'swiping', 'sorry', 'spokeswoman', 'band', 'newspaper', 'replied', 'premieres', 'unhealthiest', 'judo', 'promo', 'proud', 'literary', 'stiletto', 'dm', 'jebediah', 'blagojevich', 'turns', 'inaccurate', 'rowing', 'myspace', 'sang', 'raiders', 'pop', 'mating', 'stalking', 'hurdle', 'chant', 'action', 'television', 'belichick', 'deliberations', 'wall', 'congressmen', 'kegger', 'furlough', 'published', 'appeared', 'footprints', 'shot', 'taxidermist', 'virginity', 'label', 'liar', 'difference', 'henchman', 'israelites', 'version', 'typo', 'defrost', 'introduction', 'pound', 'willingness', 'standing', 'karzai', 'generate', 'brenda', 'mimes', 'sanity', 'goldfish', 'start', 'map', 'yep', 'aches', 'midwest', 'upskirt', 'sexiest', 'agreement', 'styrofoam', 'graders', 'stakes', 'shaved', 'adidas', 'magic', 'smut', 'carly', 'twist', 'field', 'nickel', 'located', 'temptress', 'strain', 'kat', 'advocate', 'polling', 'extracted', 'subtitles', 'guess', 'castle', 'dedicate', 'feeling', 'transactions', 'addresses', 'smoking', 'mint', 'cares', 'kotsenburg', 'fiving', 'doubles', 'rolex', 'tried', 'proceedings', 'sharing', 'subconsciously', 'victim', 'chains', 'helping', 'mega', 'ancestry', 'josh', 'remark', 'orthodox', 'olaf', 'demonstrators', 'rubik', 'counsel', 'midterm', 'gossip', 'headlights', 'away', 'resigns', 'matching', 'excuses', 'crazy', 'outlast', 'relaxed', 'houses', 'heartbreaking', 'daniels', 'handful', 'mcfly', 'status', 'settling', 'seances', 'garfield', 'starred', 'adopting', 'route', 'picard', 'meryl', 'marshmallow', 'lebron', 'participating', 'austrian', 'harder', 'asshole', 'cinnabons', 'haagen', 'beaten', 'nugget', 'illegally', 'hook', 'legs', 'basset', 'positions', 'snowboarders', 'dermatology', 'uconn', 'taxpayers', 'tomb', 'humanely', 'broadband', 'walls', 'museums', 'context', 'seekers', 'looper', 'skating', 'lingerie', 'guinness', 'cutouts', 'unintentionally', 'deports', 'ducky', 'pelvic', 'staycation', 'rentboy', 'alexa', 'shuttle', 'alphabet', 'charlotte', 'tourament', 'manufacturers', 'sitting', 'people', 'oscar', 'houseboat', 'squad', 'organs', 'locker', 'vice', 'sprinkle', 'venomous', 'succeeding', 'drifted', 'allergy', 'think', 'enable', 'occupied', 'eliminating', 'ces', 'executions', 'collude', 'stigmatized', 'jamie', 'underground', 'yup', 'services', 'infiltrated', 'banker', 'renders', 'prostitutes', 'disturbance', 'transgender', 'essentially', 'practice', 'faking', 'cauldron', 'avoid', 'publicity', 'calm', 'hornets', 'destinations', 'clubs', 'despicable', 'separated', 'international', 'versus', 'dinosaur', 'ability', 'this', 'perfect', 'helmsley', 'treasure', 'were', 'instant', 'steaks', 'needing', 'cobra', 'frontrunner', 'tag', 'passionate', 'legislature', 'obscene', 'discrimination', 'do', 'study', 'lings', 'prisoners', 'nam', 'argues', 'kournikova', 'impartiality', 'chain', 'confirms', 'pull', 'angst', 'kinko', 'heartwarming', 'roger', 'vowed', '.no', 'checking', 'imprisoned', 'pool', 'wikipedia', 'photographic', 'annual', 'widely', 'judgment', 'linda', 'republic', 'leggings', 'nuisance', 'laura', 'mississippi', 'jumps', 'implement', 'tablet', 'afterward', 'barry', 'written', 'ploy', 'mess', 'hassle', 'millionth', 'awhile', 'interpreter', 'exorcist', 'mud', 'despacito', 'weren', 'limbaugh', 'swiss', 'trenta', 'mache', 'bushcare', 'defeated', 'snickers', 'tracking', 'da', 'wtf', 'lobo', 'forefathers', 'pelosi', 'artist', 'hyena', 'amenities', 'manhood', 'vin', 'hunting', 'discussed', 'photograph', 'bite', 'disclosed', 'forehead', 'elsewhere', 'sunglass', 'quizzes', 'habitable', 'vanity', 'towards', 'lazy', 'method', 'flying', 'trash', 'box', 'impeached', 'slowest', 'payback', 'cigar', 'source', 'landscaping', 'bride', 'galaxy', 'pubic', 'bender', 'boned', 'deteriorating', 'embarrassment', 'baked', 'banned', 'and', 'latest', 'pox', 'grant', 'struggled', 'pi', 'pursued', 'i', 'narcissistic', 'entering', 'glitch', 'clue', 'placed', 'knowing', 'commuted', 'royalbaby', 'detailing', 'acrylics', 'creed', 'crowded', 'galileo', 'bureau', 'umbrella', 'villain', 'shit', 'hogan', 'could', 'rebuttal', 'wishing', 'terribly', 'eliot', 'overqualified', 'byron', 'tomatoes', 'workouts', 'reinforce', 'lg', 'earned', 'broader', 'allen', 'processor', 'well', 'memoriam', 'defeat', 'facebook', 'correspondent', 'drake', 'recall', 'pretending', 'kenya', 'massive', 'nsa', 'postponing', 'reaction', 'exchanging', 'beckett', 'robe', 'websites', 'secure', 'they', 'warner', 'coated', 'close', 'philippines', 'cumberbath', 'captain', 'trumpeters', 'accepted', 'cruise', 'bible', 'shells', 'breeding', 'marks', 'software', 'boyfriends', 'intention', 'peanut', 'rabbit', 'ashley', 'chrysler', 'viciously', 'rated', 'heard', 'costs', 'offshore', 'random', 'scolded', 'cheaters', 'courier', 'miller', 'switched', 'diana', 'renew', 'dan', 'neutral', 'tiger', 'palace', 'unless', 'traveller', 'miles', 'tinder', 'gasoline', 'beaver', 'masturbator', 'contested', 'popes', 'slow', 'forecasted', 'easing', 'just', 'vip', 'daughter', 'curve', 'copyrighted', 'andreas', 'general', 'toyota', 'wind', 'whispered', 'raided', 'tube', 'toyotas', 'mirror', 'pleasured', 'amy', 'guitarist', 'edelweiss', 'bribe', 'streets', 'overheard', 'club', 'begs', 'misused', 'oy', 'stunt', 'sonic', 'scientific', 'prairie', 'funded', 'hildebeest', 'bagel', 'appetites', 'lived', 'heah', 'regulate', 'dunkin', 'abba', 'war', 'rankings', 'dad', 'bargains', 'plague', 'highlighting', 'prohibits', 'incompetent', 'layover', 'harrison', 'marijuana', 'youth', 'alaska', 'urinating', 'freaking', 'actions', 'slander', 'porn', 'jaime', 'kid', 'be', 'exchanges', 'opium', 'enlarge', 'hero', 'punishment', 'began', 'polished', 'demonstrate', 'drugmakers', 'naked', 'mix', 'remember', 'delusional', 'harvesting', 'decent', 'vibrating', 'hidden', 'ranking', 'flippin', 'doodle', 'journalist', 'impeachment', 'schwab', 'precipitation', 'blends', 'kwon', 'dodgers', 'rich', 'voter', 'survived', 'dozens', 'die', 'tests', 'deserted', 'armrest', 'lines', 'jerks', 'before', 'homeland', 'flareup', 'toddler', 'cohen', 'simulation', 'prevent', 'marched', 'advertises', 'wrapped', 'members', 'deathbed', 'current', 'nervous', 'homogenized', 'congresswoman', 'khakistan', 'sonia', 't', 'enormity', 'elvises', 'listened', 'astrophysicist', 'hates', 'roar', 'crime', 'archdiocese', 'met', 'simpson', 'rowdy', 'mahmoud', 'adjectives', 'l', 'wraps', 'ethanol', 'convertible', 'clients', 'marshawn', 'new', 'planking', 'geico', 'agents', 'hamilton', 'groping', 'butterball', 'fridge', 'atoms', '.gov', 'compassion', 'settled', 'pavement', 'voters', 'shockingly', 'gradually', 'tron', 'grill', 'americano', 'salesman', 'otter', 'rhythm', 'condoleeza', 'clydesdale', 'enlargement', 'bullock', 'gutters', 'excitedly', 'corks', 'provides', 'xxx', 'regain', 'aerosol', 'vikings', 'automobiles', 'hearts', 'which', 'response', 'passport', 'weather', 'apply', 'suffers', 'honda', 'tale', 'cent', 'shock', 'hilary', 'freeman', 'salmon', 'mediate', 'h', 'boating', 'pairs', 'racially', 'occupation', 'batted', 'officiated', 'real', 'worn', 'weekend', 'disney', 'symbols', 'chamomile', 'wahoo', 'kaine', 'wearhouse', 'beginnings', 'public', 'edward', 'carries', 'buried', 'ounces', 'jr', 'luc', 'delhi', 'unavailable', 'accuser', 'donate', 'celebrating', 'habits', 'credit', 'citizen', 'coincidence', 'relating', 'gymnasium', 'taped', 'kardashiologists', 'ring', 'bomb', 'tripoli', 'papelbon', 'mckeon', 'stripe', 'inherit', 'stayed', 'corgi', 'renewal', 'clearing', 'emancipation', 'suspension', 'amsterdam', 'technique', 'hospitals', 'changing', 'announced', 'assertion', 'twitter', 'protective', 'dedicated', 'jobs', 'moscow', 'addressed', 'reputation', 'weak', 'premarital', 'comically', 'colombian', 'reconcile', 'beverly', 'defecate', 'employee', 'boldly', 'affect', 'appointments', 'krispies', 'scanners', 'starbucks', 'combine', 'repopulate', 'tanks', 'corps', 'dash', 'bonfire', 'survival', 'far', 'dis', 'engineering', 'kingpin', 'spying', 'pullout', 'minority', 'celibate', 'psa', 'atlanta', 'leaves', 'hacked', 'pick', 'sometime', 'nuggets', 'drag', 'sanders', 'bits', 'everyday', 'fantasy', 'partnership', 'dirty', 'giraffes', 'stadiums', 'improvement', 'dips', 'converse', 'oppose', 'tour', 'hawaii', 'pm', 'credited', 'tipped', 'teenage', 'w', 'bouncy', 'rains', 'tobacco', 'hello', 'april', 'barking', 'sighed', 'beaming', 'southerners', 'rushing', 'reevaluated', 'recalled', 'pie', 'sparkle', 'deficit', 'quiznos', 'hockey', 'gender', 'rebuilding', 'hormones', 'agencies', 'woodrow', 'loving', 'arresting', 'jet', 'disturbed', 'escaped', 'beatles', 'squaw', 'manage', 'plan', 'teammates', 'retweeted', 'predator', 'fingerprint', 'romantic', 'depardieu', 'listed', 'sharper', 'appearances', 'carat', 'levels', 'scores', 'peachtree', 'abedin', 'elect', 'manilow', 'beatlemania', 'wash', 'requiring', 'swimmable', 'recognizing', 'sixty', 'dylan', 'symptoms', 'augusta', 'embryo', 'grilling', 'praising', 'unseated', 'forget', 'pumped', 'fattr', 'inducted', 'easthampton', 'stripping', 'bet', 'solvent', 'harassment', 'dividends', 'lots', 'unmarried', 'burrows', 'suckabees', 'ranked', 'trusted', 'jovi', 'broncos', 'curling', 'supporting', 'discounts', 'although', 'reviews', 'reinforced', 'jim', 'q', 'debut', 'admits', 'cheerleader', 'authored', 'crossbow', 'plaque', 'overcrowding', 'hydrogen', 'rainwater', 'retire', 'chimp', 'thousands', 'believe', 'playground', 'ballot', 'laced', 'motionless', 'communications', 'shocked', 'learners', 'tighten', 'athletic', 'frito', 'camped', 'lose', 'stairs', 'dumbledore', 'oldest', 'stockroom', 'icrap', 'exposure', 'british', 'electing', 'luckily', 'sing', 'er', 'sting', 'drained', 'checks', 'furley', 'vermont', 'falsely', 'investigations', 'believable', 'dolllar', 'staind', 'awake', 'doubt', 'car', 'designers', 'operations', 'marries', 'ultra', 'gadgets', 'teenagers', 'gosh', 'diploma', 'haiti', 'protesters', 'nativity', 'designation', 'privacy', 'showbiz', 'keanu', 'arguing', 'norway', 'smallpox', 'alarming', 'op', 'mysterious', 'divorce', 'convention', 'civilization', 'regulation', 'godaddy', 'shingles', 'bisexual', 'dianne', 'creator', 'snaps', 'archived', 'dave', 'courting', 'apprentice', 'princesses', 'says', 'looks', 'fedoras', 'makeover', 'tits', 'nacho', 'pierson', 'trailer', 'chance', 'pervert', 'steers', 'spicy', 'inchers', 'calendar', 'scandal', 'service', 'sportswear', 'angus', 'coca', 'fyre', 'metlife', 'disproven', 'particularly', 'nun', 'speech', 'jupiter', 'insulted', 'grand', 'racing', 'feel', 'machines', 'ones', 'formally', 'vol', 'siberia', 'landmark', 'roboto', 'penguins', 'startled', 'weakness', 'rounded', 'lyft', 'abbey', 'shaving', 'nannies', 'michelangelo', 'riviera', 'thomas', 'vergara', 'teamed', 'shake', 'uninhabitable', 'madman', 'drum', 'fines', 'clean', 'recycled', 'terminator', 'streamed', 'reception', 'achilles', 'foreclosed', 'chis', 'measured', 'eharmony', 'sincerely', 'make', 'softly', 'temporarily', 'intercourse', 'mofos', 'hernia', 'soliciting', 'applied', 'frogs', 'baptist', 'soonish', 'hussein', 'pave', 'spirit', 'mouthy', 'significant', 'gatherings', 'crew', 'roll', 'assisted', 'alexander', 'digesting', 'bond', 'survive', 'guessing', 'kickstarter', 'church', 'artificially', 'addressing', 'boundaries', 'options', 'grounds', 'tougher', 'fathered', 'week', 'congress', 'acura', 'dolce', 'inarritu', 'timeout', 'livestream', 'brightly', 'collar', 'roy', 'planet', 'fuck', 'abstaining', 'forks', 'hemsworth', 'zinger', 'been', 'yummy', 'poquito', 'quidditch', 'disrespect', 'metaphor', 'reopen', 'assistance', 'housewives', 'abstinence', 'dropped', 'planning', 'herbal', 'nay', 'instinct', 'lago', 'starring', 'puzzles', 'yates', 'hangovers', 'biscotti', 'naughty', 'approximately', 'skiers', 'lorenzo', 'balloons', 'animals', 'sutra', 'funyuns', 'usa', 'macchio', 'sung', 'pujols', 'fortune', 'call', 'cell', 'egypt', 'davinci', 'resubmit', 'impregnated', 'touring', 'track', 'ds', 'arrange', 'harmony', 'hardback', 'season', 'handy', 'awkwardly', 'yahtzee', 'limitless', 'opinions', 'rage', 'features', 'chaperone', 'inflation', 'glaucoma', 'rushed', 'nephews', 'contacted', 'melanoma', 'bookstores', 'grader', 'association', 'business', 'lakers', 'blogging', 'hesitant', 'deceiving', 'sports', 'prevents', 'security', 'bashing', 'redone', 'recuperating', 'entertain', 'fanatical', 'females', 'mouchebags', 'newsletter', 'whereas', 'exhausted', 'winslow', 'understudy', 'phelps', 'thatcher', 'tibet', 'shawshank', 'beneficial', 'hike', 'simon', 'pablo', 'wonder', 'projected', 'wallet', 'tentative', 'critical', 'girls', 'columbia', 'calmer', 'virgin', 'peyote', 'reasons', 'comprende', 'idaho', 'charging', 'spinal', 'astronomers', 'sandra', 'nets', 'venti', 'americans', 'done', 'advertisers', 'bowel', 'deepdish', 'lee', 'learning', 'october', 'email', 'spends', 'mcbrayer', 'helms', 'ventilation', 'issued', 'maxim', 'fatties', 'afghan', 'emmys', 'nudist', 'hound', 'bathroom', 'hipper', 'crowbar', 'nog', 'buick', 'habit', 'humorous', 'finally', 'librarians', 'republicans', 'winklevoss', 'jeremy', 'shifts', 'sliced', 'rethink', 'improv', 'pounders', 'kennedy', 'learn', 'terrell', 'note', 'audited', 'praised', 'cocaine', 'profitable', 'wealth', 'toll', 'grande', 'jc', 'bug', 'porches', 'tanning', 'fogle', 'o', 'teenager', 'smith', 'ya', 'tenderness', 'mankind', 'road', 'coincidentally', 'popin', 'differences', 'nicolas', 'digits', 'costello', 'pornographic', 'dangled', 'incidents', 'christ', 'spiritual', 'tremor', 'now', 'taxable', 'measures', 'murdered', 'sie', 'klingon', 'fees', 'indians', 'phd', 'friday', 'nervously', 'falling', 'crawled', 'discrepancy', 'laurence', 'sickening', 'riders', 'schwarzenegger', 'freckles', 'bashed', 'govenor', 'neve', 'retract', 'texted', 'bathrobe', 'sleazy', 'milwaukee', 'dependents', 'statehood', 'unveiling', 'manufacturer', 'gon', 'climb', 'klux', 'none', 'bookmark', 'refer', 'discussion', 'incest', 'freaked', 'resignation', 'tear', 'prosperity', 'elements', 'broken', 'bald', 'snorting', 'migrating', 'spring', 'pile', 'evicted', 'forming', 'hyenas', 'waking', 'meteorologists', 'glute', 'cottage', 'waterboarding', 'sat', 'search', 'sit', 'prozac', 'borrow', 'visiting', 'megan', 'points', 'arrived', 'transitioning', 'our', 'blockbuster', 'mardi', 'restroom', 'chavez', 'pastures', 'goes', 'sane', 'stomach', 'lowe', 'entirely', 'backfire', 'sums', 'nestle', 'shoe', 'possibilities', 'polite', 'wear', 'erupted', 'limo', 'define', 'muggings', 'sunny', 'calms', 'beard', 'picnic', 'uses', 'freezes', 'heaviest', 'scented', 'reign', 'posh', 'consumption', 'compass', 'enters', 'ash', 'hampton', 'outcry', 'postponed', 'frequently', 'slogan', 'welders', 'breasturant', 'misses', 'going', 'cons', 'hamm', 'attendees', 'knuckles', 'document', 'pronunciation', 'helped', 'jew', 'beiber', 'keys', 'openly', 'opposing', 'revealing', 'favre', 'purchasing', 'maps', 'sunset', 'collaborating', 'grams', 'pharmacy', 'representative', 'acropolis', 'renouncing', 'joked', 'smacked', 'onstage', 'bay', 'belief', 'scratching', 'nominee', 'push', 'bono', 'photographed', 'mighty', 'store', 'messaging', 'saving', 'uranium', 'am', 'article', 'financiers', 'tumblr', 'pundits', 'supreme', 'rico', 'lexus', 'pricing', 'inexplicably', 'dds', 'bar', 'youngest', 'korea', 'spectators', 'bootilicious', 'errors', 'findings', 'broomstick', 'fraud', 'enraged', 'wrestler', 'hash', 'facial', 'propositioning', 'spiderman', 'inhaling', 'amherst', 'kerry', 'stupid', 'showed', 'overhear', 'jerry', 'decriminalize', 'bun', 'cheeks', 'bamboo', 'karen', 'cheesy', 'adhd', 'ruins', 'pee', 'proclaimed', 'burlesque', 'however', 'academic', 'stolen', 'replacements', 'today', 'referring', 'strangest', 'master', 'creation', 'shakur', 'paisley', 'deleted', 'motorized', 'accusing', 'shameless', 'indonesia', 'mcdavid', 'jared', 'pawlenty', 'bother', 'neither', 'exploiting', 'maya', 'concession', 'deerfield', 'kit', 'pan', 'bakery', 'hamlet', 'romney', 'marinara', 'earplugs', 'sage', 'carter', 'bunch', 'embark', 'artists', 'introduced', 'medicine', 'fix', 'moroccan', 'tours', 'pollution', 'sadder', 'shooter', 'western', 'flex', 'californian', 'cords', 'gmail', 'friends', 'print', 'developing', 'hybrid', 'aside', 'pikachus', 'appendage', 'stations', 'cattrall', 'insisted', 'webcast', 'flag', 'roars', 'school', 'suffered', 'beauty', 'park', 'veto', 'spending', 'atlantic', 'cumberbeyond', 'exception', 'salary', 'conceptions', 'moonlighting', 'robot', 'belongs', 'intellectual', 'agency', 'parents', 'diver', 'lice', 'indicate', 'obstructed', 'fathers', 'nip', 'craze', 'mojave', 'deflect', 'runnings', 'compromise', 'emit', 'converting', 'unannounced', 'unicycle', 'amnesia', 'unique', 'maryland', 'nationals', 'illegitimate', 'keebler', 'nickelback', 'atari', 'deals', 'hamas', 'cruising', 'nature', 'dangerously', 'fi', 'answer', 'domestic', 'economy', 'disorder', 'institution', 'pursue', 'lacing', 'drastic', 'object', 'lobster', 'doggie', 'intimate', 'fleeting', 'suggestion', 'domain', 'boycott', 'devil', 'barbra', 'hot', 'ties', 'strip', 'godmother', 'queen', 'surveyed', 'gum', 'bravo', 'churches', 'absurd', 'cap', 'hd', 'locate', 'enlarger', 'tilda', 'rehabbing', 'grads', 'capture', 'angrier', 'governorships', 'michelle', 'love', 'repulsive', 'cat', 'scotia', 'drunks', 'es', 'discriminatory', 'sham', 'bike', 'pensions', 'repent', 'municipal', 'mcconnell', 'rainfall', 'dame', 'katy', 'libraries', 'evil', 'fantastic', 'mound', 'chums', 'encrypted', 'estate', 'section', 'fork', 'copyright', 'meltdown', 'sawed', 'requested', 'fattest', 'fur', 'debuted', 'hoppy', 'jingle', 'fistler', 'errands', 'kfcs', 'warming', 'caroling', 'glassholes', 'citizenship', 'mojito', 'luge', 'plastic', 'standards', 'informed', 'companion', 'rollercoaster', 'duties', 'hut', 'chanel', 'custody', 'knock', 'bae', 'deranged', 'dominated', 'inflated', 'weirdo', 'package', 'tang', 'lamest', 'farmville', 'see', 'passover', 'flavored', 'nuke', 'mraz', 'gq', 'bases', 'naturally', 'fishburne', 'judge', 'angelenos', 'surveys', 'medically', 'avatar', 'rhino', 'antiquing', 'slap', 'personally', 'rereleased', 'buttstuff', 'fresno', 'chazz', 'models', 'examine', 'madden', 'opponents', 'jen', 'francis', 'arizonans', 'coffees', 'hbo', 'interns', 'tripp', 'twenties', 'skippers', 'facts', 'appropriate', 'espn', 'leaving', 'hitman', 'portions', 'topping', 'container', 'handled', 'nominated', 'hard', 'defamation', 'phones', 'creeper', 'marathon', 'stadium', 'girlfriends', 'share', 'trucking', 'settles', 'leaky', 'alabama', 'yorkers', 'classes', 'following', 'remove', 'scheme', 'extremely', 'afloat', 'floyd', 'discontinuing', 'kirstie', 'influential', 'swimsuits', 'lane', 'daredevil', 'tomahawk', 'error', 'debaters', 'sexxxygingernotconanobrien', 'tie', 'nj', 'quietly', 'seeger', 'fived', 'temple', 'preacher', 'dogs', 'generator', 'denver', 'ex', 'scarborough', 'distance', 'slavery', 'apologies', 'timberwolves', 'labeled', 'christy', 'foreplay', 'less', 'languages', 'oxford', 'bikes', 'raid', 'slaves', 'playlist', 'sisters', 'soul', 'liking', 'murders', 'latte', 'matador', 'seinfeld', 'rooftop', 'carton', 'floors', 'robotic', 'sharp', 'moral', 'sounded', 'resulted', 'competed', 'lace', 'gatsby', 'mime', 'jetpack', 'punitive', 'momentarily', 'notorious', 'primo', 'beef', 'introduce', 'greens', 'aquatic', 'rabbi', 'flynt', 'birmingham', 'farmers', 'steph', 'beds', 'jessica', 'henson', 'butterflies', 'biscuit', 'transformers', 'initiatives', 'coffin', 'benefitted', 'opponent', 'invoice', 'erected', 'walkout', 'capita', 'kissed', 'swindled', 'convicted', 'unmanned', 'troops', 'prescription', 'louis', 'signals', 'lacking', 'patrick', 'regis', 'nutshell', 'sorrentino', 'geezerville', 'pointed', 'wolfetown', 'autographed', 'channels', 'germany', 'relationship', 'playboy', 'esteem', 'albino', 'suck', 'tea', 'depressing', 'mogul', 'sailing', 'arthritis', 'day', 'debated', 'cuddle', 'magnetic', 'electable', 'smash', 'thee', 'ohio', 'worldwide', 'maggie', 'greeted', 'disk', 'attempt', 'spaceship', 'goodell', 'slices', 'monument', 'pacific', 'fighters', 'grey', 'one', 'breath', 'squandering', 'passage', 'bonds', 'alter', 'danza', '.woah', 'woods', 'shorty', 'meatball', 'mendes', 'nebraska', 'league', 'figuring', 'include', 'vulva', 'bambino', 'students', 'leaders', 'gardening', 'overhaul', 'seasonal', 'speculate', 'anderson', 'corrupt', 'inaccuracies', 'supports', 'spinner', 'maverick', 'arabian', 'surface', 'planted', 'replacing', 'mcdonald', 'replace', 'cities', 'overly', 'nicolascage', 'describing', 'bacharach', 'seminar', 'sometimes', 'swap', 'merged', 'enquirer', 'detention', 'streaming', 'lead', 'greece', 'blasted', 'orientation', 'profession', 'rush', 'carjacked', 'toning', 'kills', 'equal', 'weighed', 'alma', 'participate', 'yesterday', 'conditioning', 'tears', 'secretary', 'aguilera', 'global', 'grace', 'stubble', 'justice', 'mirren', 'twelve', 'wrath', 'duo', 'ripa', 'obstacle', 'drinkable', 'outback', 'enjoying', 'originated', 'hopefully', 'fest', 'visionary', 'forfeiture', 'promiscuous', 'constitutional', 'melted', 'legalize', 'daddies', 'registration', 'caffeine', 'hispanic', 'sightings', 'removal', 'installment', 'fracture', 'spin', 'attributed', 'presents', 'tush', 'letdown', 'complete', 'slim', 'crackdown', 'restoring', 'bryce', 'except', 'impregnating', 'hopkins', 'recklessness', 'phew', 'crashed', 'exoneration', 'pinkberry', 'jennifer', 'tackled', 'employers', 'viv', 'charges', 'inspired', 'netflix', 'tastings', 'weed', 'separation', 'oligarch', 'dui', 'messenger', 'kia', 'serenity', 'touching', 'tax', 'established', 'sealed', 'stroller', 'buy', 'relevance', 'gaddafi', 'sandwiched', 'staffer', 'stories', 'hiring', 'limited', 'justputtingitoutthere', 'respected', 'dolezal', 'politically', 'redesign', 'step', 'gracious', 'aisles', 'promote', 'occasions', 'graf', 'narrowing', 'trigger', 'spare', 'havana', 'franchise', 'barackobama', 'developed', 'ours', 'craves', 'bananas', 'vasectomies', 'tokyo', 'begins', 'deer', 'ultimate', 'nasa', 'renounced', 'tweet', 'zygote', 'wielding', 'cinematography', 'jurors', 'christie', 'postal', 'bacon', 'gbagbo', 'complain', 'tournament', 'comprehend', 'realize', 'chesty', 'ozzie', 'withdrawal', 'amazed', 'cambridge', 'internship', 'sending', 'interruptions', 'weinergate', 'cunnilingus', 'network', 'confirm', 'drive', 'vaccine', 'reflect', 'dorm', 'enemy', 'repressive', 'pees', 'coordinates', 'repackage', 'evolution', 'mandarin', 'ann', 'cheap', 'column', 'agent', 'introducing', 'intruder', 'scene', 'junk', 'scaldy', 'lips', 'fund', 'stake', 'according', 'laughed', 'nepal', 'pains', 'mr', 'iwillhavemygranddaughterexplainthistome', 'mental', 'comforts', 'systems', 'unlike', 'nhl', 'switch', 'deserve', 'leno', 'surviving', 'ponies', 'pin', 'preferred', 'mit', 'pitchman', 'endorsement', 'crips', 'tender', 'complaining', 'notices', 'scrutiny', 'magazine', 'guys', 'subpoena', 'charlie', 'scan', 'photo', 'foursome', 'biceps', 'highlight', 'bursts', 'yellow', 'conway', 'folks', 'whatsapp', 'cherish', 'containing', 'earning', 'craft', 'vick', 'theirs', 'age', 'advances', 'hyundai', 'osbourne', 'woman', 'streisand', 'vast', 'spielberg', 'pigeons', 'revolutionized', 'single', 'cold', 'vancouver', 'edit', 'birdman', 'pajancho', 'manhole', 'weapons', 'storylines', 'stigma', 'serial', 'vote', 'whiskey', 'categories', 'trapped', 'valued', 'identifies', 'music', 'brides', 'editor', 'irs', 'testament', 'fugitive', 'eyebrows', 'mouths', 'buildings', 'uns', 'odyssey', 'bouncing', 'headaches', 'disgrace', 'boobs', 'redskins', 'adoption', 'plead', 'northeast', 'baseman', 'muslims', 'smirked', 'tuesdays', 'taylor', 'sinking', 'passwords', 'displays', 'cruiser', 'khakis', 'chafee', 'chemical', 'properties', 'flattering', 'gravy', 'nambia', 'mel', 'wicked', 'damaged', 'kicked', 'discounted', 'penetrate', 'long', 'forgotten', 'lifeboat', 'buns', 'conserve', 'corsage', 'burglar', 'original', 'anger', 'verdict', 'liam', 'cartwheel', 'saint', 'alcoholics', 'cannot', 'zuoshi', 'because', 'deluxe', 'courtside', 'greeting', 'reagan', 'wiz', 'manuel', 'mold', 'clarify', 'ksum', 'grade', 'proof', 'clearance', 'uncovered', 'imitation', 'visit', 'cube', 'prostituting', 'loaner', 'badly', 'haven', 'cared', 'crouch', 'meow', 'francisco', 'monkeys', 'dodger', 'releases', 'price', 'likely', 'sbefriendables', 'diplomacy', 'grandfather', 'decriminalized', 'audition', 'thirsty', 'sleeves', 'sweep', 'uncles', 'wage', 'hug', 'soups', 'glouchebags', 'notre', 'payer', 'softening', 'liver', 'yogi', 'caribbean', 'underway', 'greetings', 'nieces', 'oprah', 'banking', 'skaters', 'slice', 'masters', 'looted', 'businessman', 'washroom', 'timberlake', 'locos', 'shoulder', 'bending', 'achieving', 'middleton', 'penny', 'pressuring', 'pitched', 'fringe', 'insert', 'kayak', 'incorrectly', 'exploits', 'etiquette', 'web', 'vocabulary', 'brain', 'unstoppable', 'remains', 'dish', 'showering', 'vlad', 'lifeguards', 'marrying', 'texas', 'mccartney', 'few', 'finalists', 'gnome', 'dawn', 'memos', 'fitness', 'douche', 'participated', 'career', 'swarm', 'pseudonym', 'recognize', 'pipes', 'jump', 'exes', 'artillery', 'mummy', 'breakout', 'impression', 'outside', 'tell', 'gluten', 'louisville', 'germiest', 'gyns', 'caveman', 'rob', 'indeed', 'miserables', 'yankees', 'ibm', 'grumpy', 'pinterest', 'conditions', 'chat', 'beautiful', 'mentions', 'sailor', 'infrequent', 'freedom', 'sheer', 'manny', 'intersection', 'itself', 'me', 'sporting', 'buttons', 'brew', 'atms', 'chili', 'dads', 'memphis', 'andrea', 'trumbo', 'roast', 'miley', 'headsets', 'harassed', 'must', 'kilpatrick', 'evolved', 'party', 'posse', 'mate', 'hardball', 'gynecologist', 'posting', 'springer', 'chimpanzee', 'shaped', 'sandals', 'removes', 'lance', 'tribe', 'sicko', 'routine', 'cardiologically', 'olympics', 'upton', 'nyet', 'automatically', 'rutgers', 'cleaned', 'cookbook', 'ilovetbs', 'contributions', 'alienate', '.', 'procreate', 'dictionary', 'taste', 'overpay', 'requests', 'careers', 'noble', 'dials', 'delude', 'remote', 'fold', 'barometer', 'optimist', 'inviting', 'dog', 'greeter', 'institutions', 'division', 'africa', 'coin', 'handshake', 'tragic', 'censors', 'faked', 'reeves', 'process', 'factor', 'jenner', 'lewd', 'hugged', 'mello', 'medalist', 'hostess', 'conveyed', 'squeezing', 'melman', 'mixed', 'colored', 'capitan', 'lacrosse', 'jenny', 'kittys', 'nothing', 'briefly', 'glowing', 'bada', 'taunting', 'comedy', 'listening', 'jimi', 'canned', 'absence', 'metalworker', 'panicked', 'mark', 'jablowmi', 'mozart', 'training', 'toughest', 'creature', 'nicki', 'scare', 'radioactive', 'koran', 'direction', 'dependent', 'stop', 'reinforcing', 'explosions', 'vegan', 'mavericks', 'empty', 'retitled', 'goddammit', 'islands', 'thumbs', 'pumpkin', 'cyberterrorists', 'portion', 'speak', 'factual', 'wins', 'enhanced', 'tyrannosaurus', 'temporary', 'denise', 'presley', 'vibe', 'granted', 'naming', 'grief', 'elephants', 'posted', 'dare', 'russia', 'peters', 'ein', 'property', 'qualify', 'crue', 'faith', 'republican', 'twinkies', 'text', 'counter', 'embarrassing', 'demand', 'medications', 'distract', 'overweight', 'roth', 'degrees', 'duh', 'cheerio', 'baskin', 'jerk', 'farmer', 'flibanserin', 'seconds', 'rd', 'bader', 'reed', 'theft', 'gilmore', 'scheduled', 'sharktopus', 'hardee', 'unverified', 'goodbye', 'young', 'stretched', 'calming', 'makeup', 'ukulele', 'podiatrist', 'electrodes', 'parole', 'accepts', 'purge', 'eagle', 'feminist', 'barilla', 'applebee', 'hairless', 'burrell', 'twilight', 'roommate', 'underwater', 'grades', 'left', 'sneakers', 'bloomer', 'scotland', 'backspace', 'sovereign', 'peanuts', 'spied', 'my', 'house', 'pray', 'disproves', 'newborns', 'solutions', 'wow', 'seem', 'assure', 'indictments', 'oxycontin', 'comprise', 'sidekick', 'rower', 'match', 'motor', 'frankly', 'bogota', 'protested', 'southern', 'railcars', 'oz', 'local', 'patented', 'targeted', 'reform', 'greenhouse', 'ongoing', 'weighing', 'outrage', 'regularly', 'historical', 'jockey', 'atticus', 'bullied', 'base', 'secrets', 'discovered', 'dispose', 'bells', 'regular', 'dragon', 'cardinals', 'recovery', 'trademarked', 'timing', 'overpopulation', 'helpful', 'brother', 'tells', 'cleaver', 'bullet', 'thou', 'wildfires', 'quote', 'swapped', 'infuriated', 'noticeable', 'convicts', 'rowling', 'shady', 'reluctant', 'carried', 'rapists', 'successor', 'leblanc', 'slovenia', 'inches', 'deport', 'glorious', 'anatomy', 'extraterrestrial', 'oaks', 'journalists', 'interrupt', 'pander', 'penney', 'sperm', 'wakes', 'asylum', 'snapchat', 'orgasm', 'mated', 'identical', 'eastwood', 'whatever', 'fled', 'punch', 'across', 'once', 'lectures', 'rowmates', 'retailer', 'rate', 'paraphrasing', 'astronauts', 'storage', 'lobbying', 'regarding', 'gusta', 'uninsured', 'clamquake', 'filing', 'ramen', 'compound', 'cup', 'tree', 'whistleblower', 'accusers', 'abs', 'raw', 'morale', 'successful', 'friendship', 'paternity', 'mater', 'happiness', 'approval', 'dragging', 'educator', 'pak', 'board', 'educating', 'speakers', 'clicked', 'coached', 'thank', 'mistaken', 'pause', 'formal', 'spine', 'disappointing', 'guantanamo', 'messages', 'oklahoma', 'peruvian', 'maniacally', 'salmonella', 'unpacked', 'shareholders', 'opposition', 'conscience', 'hospitalized', 'kung', 'aretha', 'burka', 'regulations', 'psoriasis', 'kremlin', 'rubbed', 'froth', 'bangs', 'evangelical', 'kenyans', 'ridiculous', 'taunted', 'allows', 'dip', 'socially', 'soldier', 'relationships', 'underrepresented', 'dmx', 'vandalizing', 'homosexuality', 'portugal', 'addiction', 'leonardo', 'delivering', 'payless', 'dennis', 'brothels', 'bearded', 'coincidently', 'speedy', 'sent', 'cramming', 'bryant', 'pieces', 'elena', 'outfits', 'convince', 'cleric', 'defendant', 'sumo', 'mariah', 'aluminum', 'daniel', 'wendys', 'pace', 'worker', 'sexist', 'entitled', 'mining', 'primaries', 'rome', 'volunteers', 'darkened', 'seemed', 'injected', 'vieira', 'name', 'heidi', 'anthems', 'footprint', 'goods', 'proceeds', 'bad', 'duet', 'thongs', 'treasurer', 'workshop', 'tennessee', 'eagles', 'lego', 'kama', 'gold', 'backing', 'awkwardness', 'meredith', 'jillian', 'invisible', 'hulk', 'yard', 'sumner', 'metamucil', 'corrected', 'wrestling', 'updates', 'patrolmen', 'fiance', 'rouhani', 'bruins', 'tested', 'tillerson', 'montana', 'arabic', 'obesity', 'archaeologist', 'partying', 'macron', 'biker', 'thieves', 'lasseter', 'frontier', 'jealous', 'show', 'deciding', 'agree', 'wandering', 'insurance', 'from', 'jonah', 'discovering', 'gershwin', 'amish', 'founders', 'consume', 'sleeps', 'breaks', 'grandchild', 'embellished', 'downs', 'proven', 'gloria', 'yelling', 'bloc', 'amputating', 'red', 'nuts', 'flux', 'reestablished', 'harbor', 'crunch', 'against', 'thickness', 'proficient', 'chanting', 'perspective', 'za', 'sucks', 'middleweight', 'testing', 'cynical', 'oreos', 'evacuated', 'sea', 'supercharge', 'lol', 'constitution', 'fourth', 'guests', 'desk', 'habla', 'borrowing', 'drought', 'toe', 'potato', 'sob', 'costars', 'harmful', 'californians', 'scrotum', 'wings', 'fame', 'record', 'talkshow', 'royal', 'strippers', 'humans', 'strategic', 'virginia', 'cumberbatch', 'choosing', 'pleasure', 'christina', 'wise', 'uc', 'draft', 'charger', 'cameo', 'cynthia', 'soho', 'pharaoh', 'confess', 'nobel', 'realism', 'spain', 'datsun', 'proposing', 'starters', 'penalizing', 'horan', 'electoral', 'barkley', 'cracked', 'never', 'desirable', 'egging', 'monogamous', 'weighs', 'passes', 'attract', 'ipad', 'monk', 'hashtag', 'danced', 'hits', 'portrayal', 'traditions', 'risk', 'enabler', 'monetary', 'siamese', 'rourke', 'overprescribed', 'kochs', 'funk', 'mets', 'hugs', 'raged', 'invasions', 'libya', 'independents', 'surgically', 'dwts', 'shadows', 'sewage', 'kanye', 'troy', 'smartwatch', 'numbers', 'maximum', 'groupies', 'potent', 'pelicans', 'apocalypse', 'news', 'actually', 'rematch', 'underreacters', 'areas', 'lieberman', 'unfortunately', 'gross', 'tackling', 'tariffs', 'cryer', 'laughingstock', 'floor', 'rumor', 'identified', 'impressive', 'uneventful', 'remained', 'teller', 'comey', 'creeps', 'karate', 'deez', 'slipping', 'avenge', 'builds', 'near', 'peed', 'volunteered', 'member', 'trips', 'breathalyzer', 'liberace', 'posters', 'causes', 'clues', 'prompted', 'mrs', 'panda', 'research', 'precede', 'avengers', 'uprisings', 'impossible', 'eva', 'aceboo', 'three', 'hacking', 'gay', 'heigl', 'gratuitous', 'obligated', 'towel', 'button', 'stressful', 'memories', 'vaginas', 'believing', 'literature', 'inotice', 'undocumented', 'lil', 'chainz', 'windowless', 'booing', 'briefings', 'nevada', 'hat', 'efficiently', 'mild', 'carnival', 'involving', 'awaiting', 'witherspoon', 'cows', 'prospects', 'suspicion', 'mission', 'spoil', 'lodge', 'abducted', 'vibrator', 'yemen', 'depends', 'malia', 'collapsed', 'costco', 'bong', 'exaggerated', 'cannons', 'hoo', 'feathers', 'mahatma', 'grad', 'reflects', 'exercising', 'ukrainian', 'olympic', 'tossed', 'bro', 'airbags', 'rendition', 'brawlers', 'busson', 'backs', 'libertarian', 'ing', 'miraculously', 'questionable', 'obnoxious', 'flagpole', 'subject', 'subconscious', 'jodie', 'reunited', 'genealogy', 'paperwork', 'managers', 'atom', 'raising', 'sno', 'anxious', 'steal', 'shocking', 'jose', 'statehouse', 'treat', 'challenge', 'lavender', 'billboard', 'explaining', 'stands', 'careful', 'averages', 'magenta', 'prevention', 'secretly', 'merely', 'robes', 'caves', 'negligent', 'fake', 'suicidal', 'runner', 'garden', 'memory', 'immigration', 'opens', 'hooker', 'worships', 'brokaw', 'shaken', 'trippin', 'reminded', 'flags', 'campus', 'hermanator', 'nokia', 'whose', 'portobello', 'pit', 'sapphire', 'notch', 'items', 'pawn', 'won', 'slurs', 'halfway', 'worst', 'clarkson', 'wages', 'marlins', 'philadelphia', 'eye', 'psychologists', 'tuning', 'akron', 'industry', 'manicotti', 'dresses', 'drivable', 'invaded', 'pitching', 'palestine', 'tensions', 'backpack', 'gripping', 'specifically', 'ask', 'water', 'po', 'children', 'mercedes', 'competitors', 'undo', 'cannabis', 'shortcomings', 'increases', 'cpac', 'rushmore', 'screamed', 'thai', 'altalune', 'temperature', 'vanished', 'omg', 'forensic', 'rap', 'imperfect', 'decree', 'auction', 'commemorative', 'spotted', 'infected', 'stella', 'policies', 'ribfest', 'gaye', 'known', 'smiley', 'dvr', 'chalupas', 'perform', 'cello', 'required', 'males', 'reverses', 'elite', 'greenlit', 'guam', 'hologram', 'circus', 'almost', 'katrina', 'dragons', 'advise', 'robbins', 'saddest', 'properly', 'nudity', 'bookmakers', 'launch', 'perhaps', 'ladder', 'curry', 'cpr', 'spouse', 'lorde', 'driveway', 'recruits', 'confident', 'overshadow', 'roseanne', 'lower', 'closeted', 'jeeves', 'mirandas', 'putin', 'voluntarily', 'ran', 'phrase', 'yay', 'endeavor', 'hobbit', 'potential', 'alarm', 'skydiving', 'interaction', 'douglas', 'kreme', 'jailed', 'truth', 'trade', 'president', 'businessmen', 'needles', 'mubarak', 'posed', 'pauly', 'overconfident', 'scratch', 'aground', 'sully', 'november', 'initiative', 'chris', 'worsen', 'tastes', 'mitch', 'glue', 'formerly', 'genderless', 'dirk', 'clinched', 'dispensaries', 'gigantic', 'ancient', 'simpsons', 'cheetos', 'stacking', 'prestige', 'dry', 'cheered', 'trekkie', 'berry', 'dissolve', 'flashed', 'sachs', 'habemus', 'botoxia', 'bullshit', 'ben', 'react', 'festivals', 'nobody', 'tasteful', 'olga', 'player', 'provision', 'stafford', 'violently', 'regards', 'airbnb', 'possibility', 'celebrate', 'movement', 'possibly', 'riot', 'lo', 'iphone', 'leo', 'molly', 'forcing', 'soil', 'pratt', 'add', 'sajak', 'polar', 'lifelong', 'douchey', 'nine', 'duggars', 'ram', 'infomercial', 'amc', 'clause', 'burbankwas', 'disciples', 'cents', 'congratulating', 'tyson', 'sight', 'senses', 'background', 'vine', 'waved', 'nato', 'imaginable', 'loser', 'drawer', 'titties', 'gusher', 'inappropriate', 'mckinley', 'send', 'glasgow', 'costas', 'sensible', 'hotmail', 'microphone', 'stroke', 'rehabilitation', 'flames', 'feed', 'vulnerable', 'merlot', 'heated', 'finds', 'fitch', 'loretta', 'lively', 'conservatism', 'numerous', 'fda', 'flagrant', 'decrease', 'crossed', 'environmental', 'has', 'homepage', 'neighbors', 'grass', 'colito', 'charged', 'luckiest', 'underneath', 'fetish', 'microwavable', 'description', 'browning', 'bringing', 'commercial', 'hawks', 'distinction', 'boxing', 'dragged', 'conceal', 'mock', 'camouflage', 'vw', 'accomplishments', 'some', '.world', 'chimpanzees', 'lsu', 'electrical', 'alleged', 'radioshack', 'zero', 'guest', 'groupon', 'differently', 'sext', 'ignore', 'existed', 'stair', 'mcnugget', 'austerity', 'crafted', 'suppliers', 'useful', 'managing', 'trumpcare', 'johnnie', 'tight', 'seal', 'rifle', 'buyer', 'batter', 'giuliani', 'receiving', 'apostles', 'carved', 'personal', 'legislators', 'smashed', 'marvel', 'staring', 'portraying', 'silenced', 'migrants', 'degrading', 'copying', 'breastaraunts', 'misspelling', 'ween', 'sarcastically', 'jong', 'rover', 'farrow', 'payments', 'banana', 'hate', 'babyback', 'fever', 'ms', 'attacking', 'transcript', 'meals', 'gonna', 'halt', 'yearning', 'crumbled', 'annan', 'lay', 'chemicals', 'chaz', 'egan', 'shards', 'petraeus', 'papadopolous', 'dormant', 'illegal', 'true', 'politics', 'plans', 'pioneered', 'schumer', 'technologically', 'dives', 'billionth', 'horrific', 'dj', 'jedi', 'comment', 'offenders', 'beginning', 'macy', 'rots', 'emerges', 'function', 'whom', 'searches', 'punchline', 'telenovela', 'looting', 'racy', 'easter', 'gomez', 'date', 'signal', 'insults', 'rugby', 'parrots', 'bulk', 'feud', 'diseases', 'contenders', 'swipe', 'mug', 'autographs', 'place', 'migraines', 'icebergs', 'hive', 'shorts', 'fasting', 'shia', 'spent', 'pusha', 'croissant', 'touches', 'reports', 'dubbed', 'suspicious', 'unit', 'premiums', 'barn', 'docked', 'j', 'trainer', 'explanation', 'investigators', 'nancy', 'clippers', 'violence', 'privates', 'receive', 'texting', 'voting', 'cutbacks', 'carey', 'endangered', 'entendres', 'hemisphere', 'interior', 'approved', 'baristas', 'wailing', 'curing', 'suicide', 'bunk', 'volcanic', 'helmet', 'falcon', 'waaay', 'loose', 'smooth', 'anti', 'transition', 'priuses', 'billions', 'farewell', 'soft', 'renewed', 'modeling', 'elf', 'unskilled', 'hostilities', 'apple', 'investigating', 'odds', 'hopeful', 'televangelist', 'documentary', 'fertilization', 'applying', 'being', 'instructor', 'serenading', 'investigator', 'universe', 'blade', 'attracted', 'renowned', 'wayyyy', 'ambiguously', 'worry', 'lisa', 'imprison', 'sus', 'weaving', 'sector', 'bitch', 'reaching', 'halen', '.crew', 'cleaning', 'nicer', 'flinstones', 'menus', 'senators', 'poodle', 'jeff', 'families', 'invention', 'strips', 'along', 'forces', 'belligerent', 'cute', 'cuba', 'wandered', 'therapy', 'lip', 'scissors', 'dimensional', 'evasion', 'microwave', 'unease', 'craving', 'sundae', 'narrowed', 'softball', 'bidder', 'operated', 'rocky', 'unbalanced', '.coli', 'scandals', 'penthouse', 'evander', 'anticipated', 'doctors', 'concerted', 'superbowl', 'title', 'france', 'advised', 'coolest', 'victims', 'swiped', 'duke', 'zookeepers', 'non', 'demographic', 'actively', 'sticks', 'hernandez', 'great', 'nino', 'renovation', 'leaking', 'accusation', 'tmz', 'circles', 'oven', 'ceelo', 'fritos', 'square', 'missiles', 'frisbee', 'oranges', 'donation', 'indonesians', 'lenny', 'airlift', 'loves', 'stallone', 'under', 'bieber', 'devils', 'breakfastarianism', 'closest', 'burgeoning', 'penalized', 'pants', 'viceprezjoeb', 'foreskins', 'doughnuts', 'unsolicited', 'goodluck', 'ellen', 'department', 'florence', 'spanking', 'difficult', 'efficient', 'renee', 'ease', 'jp', 'satisfaction', 'promotional', 'evening', 'professed', 'minors', 'clog', 'relief', 'flaw', 'nope', 'halloween', 'influences', 'dunham', 'within', 'advisor', 'nas', 'vision', 'bodyguard', 'unpatriotic', 'urinates', 'reward', 'buzzfeed', 'outcome', 'surpassed', 'poehler', 'dealership', 'geopolitical', 'downward', 'baggage', 'bias', 'retrial', 'ruining', 'roles', 'swedish', 'putting', 'bacteria', 'progressive', 'environment', 'mind', 'optimistic', 'nerds', 'cremation', 'rewrote', 'husband', 'kingdom', 'eric', 'allow', 'th', 'peepers', 'auto', 'daft', 'banks', 'handcuffs', 'xi', 'gone', 'ghana', 'passing', 'pure', 'rectalsearch', 'sellers', 'aniston', 'ind', 'hyperloop', 'emerald', 'percentage', 'failure', 'excuse', 'flu', 'searching', 'twenty', 'terrifies', 'surplus', 'shouldn', 'unbearable', 'huntsman', 'cosmo', 'fulfill', 'infertile', 'ruined', 'siding', 'superhero', 'painkiller', 'enforcing', 'replaced', 'squirrel', 'sunburn', 'bought', 'diesel', 'infused', 'monster', 'officiate', 'elvis', 'motivation', 'visible', 'manchester', 'food', 'five', 'mini', 'expert', 'testimony', 'necessarily', 'too', 'deliberately', 'pamphlets', 'vampire', 'scholars', 'shown', 'kong', 'misunderstandings', 'moved', 'million', 'carpet', 'expiration', 'porch', 'carmen', 'block', 'burnt', 'poncho', 'perv', 'stalk', 'state', 'dances', 'avoided', 'layoffs', 'exit', 'rides', 'geology', 'reckoning', 'salts', 'giraffe', 'pharmaceutical', 'friendly', 'bonerprez', 'nation', 'specialty', 'governor', 'zaq', 'licked', 'willis', 'shamwow', 'exotic', 'hdtv', 'gangster', 'pushing', 'anonymous', 'butts', 'chik', 'watch', 'dental', 'hooter', 'outraged', 'avocado', 'century', 'blitzer', 'wildfire', 'ambassador', 'unimaginable', 'foosball', 'libido', 'entire', 'weddings', 'brains', 'easily', 'scooping', 'juan', 'handgun', 'sacred', 'jethbo', 'ninth', 'cleopatra', 'unstable', 'resides', 'videogame', 'ahead', 'hen', 'yearbook', 'aren', 'responsibility', 'tourist', 'breadsticks', 'view', 'puerto', 'risky', 'inappropriately', 'bridge', 'balance', 'picked', 'frying', 'aisle', 'chew', 'showing', 'revive', 'retirement', 'merchandise', 'pr', 'altogether', 'circulating', 'summoned', 'yolk', 'courageous', 'shorter', 'hayley', 'parthenon', 'feasibility', 'israelis', 'packs', 'crocodiles', 'shower', 'elaborate', 'miss', 'popadick', 'daylight', 'dancers', 'elitist', 'possess', 'austria', 'cafe', 'embarked', 'klum', 'contestants', 'ascended', 'hinting', 'fighting', 'prevented', 'umpire', 'surfaced', 'lovers', 'wasteful', 'lattes', 'leftovers', 'partially', 'teaches', 'deeply', 'blades', 'raises', 'peterson', 'specifies', 'goofy', 'prescribed', 'drew', 'outnumber', 'spank', 'uber', 'affair', 'sisterhood', 'favored', 'risks', 'investigate', 'gofundme', 'remake', 'towns', 'probation', 'indianapolis', 'engraving', 'commodore', 'rows', 'bulls', 'strong', 'caring', 'wish', 'vanilla', 'natural', 'naval', 'funeral', 'barricade', 'administered', 'divided', 'pitbull', 'hoped', 'quilting', 'wheeler', 'yeah', 'olive', 'practicing', 'arbitrator', 'gellar', 'monopoly', 'summer', 'inaugural', 'harvested', 'down', 'attending', 'kangaroos', 'flannel', 'aloha', 'lockdown', 'slobs', 'shop', 'hair', 'charlize', 'vogue', 'principles', 'punishing', 'raton', 'wouldn', 'pistorius', 'hurled', 'addictive', 'mantyhose', 'pesky', 'palminteri', 'navy', 'depth', 'regrets', 'bless', 'bunnies', 'rising', 'disapproves', 'mammal', 'mandyrichter', 'allure', 'disabilities', 'finances', 'ceo', 'honduras', 'scored', 'tabloid', 'stuf', 'obvious', 'dictate', 'admitting', 'circumcision', 'unregulated', 'federal', 'stan', 'account', 'cybersecurity', 'wanna', 'lipstick', 'presidency', '.soup', 'mama', 'emerged', 'destiny', 'shatner', 'rhetorical', 'offices', 'hatch', 'lobby', 'employ', 'dark', 'skimpy', 'versa', 'believed', 'banged', 'scientists', 'skateboarder', 'happening', 'marriage', 'organization', 'violated', 'defends', 'imagination', 'fingers', 'circuit', 'ears', 'appearance', 'combing', 'prestigious', 'warwick', 'quiz', 'chauvinist', 'command', 'pornography', 'weirdest', 'majority', 'skittles', 'shroud', 'billionaires', 'individually', 'cholesterol', 'mcentire', 'tunnel', 'assist', 'whoville', 'chocolate', 'political', 'unfair', 'pledge', 'mileage', 'hang', 'odor', 'disperse', 'gathering', 'ignoring', 'gamers', 'likey', 'signs', 'stupidface', 'hill', 'staff', 'bezos', 'fastest', 'swallowing', 'degrasse', 'neighs', 'madoff', 'nicely', 'michael', 'temper', 'teens', 'thirds', 'crabtree', 'reliance', 'apology', 'luther', 'check', 'bump', 'operates', 'sketch', 'budgets', 'motorcade', 'admitted', 'bake', 'endure', 'porsche', 'household', 'startling', 'interracial', 'insects', 'wasn', 'purchases', 'institute', 'xbox', 'intelligence', 'tapas', 'sewn', 'liquid', 'thick', 'insistence', 'jung', 'ages', 'drones', 'arid', 'overhead', 'solange', 'minute', 'sworn', 'inequality', 'approach', 'meanest', 'heckler', 'communist', 'errico', 'whips', 'hooked', 'singers', 'shuffleboard', 'registered', 'handcuff', 'resident', 'trespassing', 'firm', 'curiosity', 'goalies', 'grasp', 'carshank', 'renting', 'alcohol', 'spanish', 'focus', 'parlor', 'hemingway', 'gets', 'planks', 'drastically', 'cheats', 'casey', 'connected', 'henry', 'pad', 'knicks', 'scrabble', 'geologists', 'embarrassed', 'shuts', 'meatloaf', 'scarier', 'mein', 'entrance', 'jetblue', 'cabin', 'metric', 'werewolf', 'sox', 'names', 'phenomenon', 'rough', 'parliamentary', 'manservant', 'unwrapping', 'tallest', 'else', 'tiffany', '.probably', 'plummet', 'feelings', 'wherever', 'orders', 'grease', 'lieu', 'mtv', 'cuomo', 'longoria', 'puppy', 'uncle', 'belt', 'carts', 'camp', 'inning', 'selena', 'policemen', 'acres', 'cadaver', 'geostorm', 'deep', 'freeing', 'vomiting', 'poor', 'elephant', 'visions', 'flowers', 'injure', 'era', 'illustrious', 'sunlight', 'quieted', 'jays', 'wednesday', 'translation', 'infectious', 'grim', 'judas', 'supermarket', 'traced', 'accomplish', 'strike', 'cheerios', 'lehrer', 'lesbian', 'substitutes', 'squeal', 'advantage', 'hermit', 'views', 'cupholders', 'strangely', 'comiccon', 'decreasing', 'elected', 'pantene', 'cirrhosis', 'spunky', 'coyotes', 'gayer', 'selected', 'censor', 'gains', 'exploded', 'enact', 'rib', 'unlock', 'maintains', 'killer', 'penises', 'retweeting', 'milkshake', 'golfer', 'accuses', 'fun', 'want', 'unattractive', 'aware', 'brien', 'battery', 'armed', 'often', 'pig', 'unbroken', 'traces', 'refers', 'slutty', 'al', 'caterpillar', 'kinda', 'signature', 'audiobook', 'graveyard', 'grievances', 'prick', 'credo', 'televisions', 'cringes', 'loko', 'street', 'suarez', 'psyched', 'medieval', 'uruguay', 'bugging', 'nothingness', 'sparkling', 'europe', 'noise', 'monthly', 'sprinkled', 'independence', 'toilet', 'jacks', 'orgy', 'uproar', 'crash', 'trillion', 'kourtney', 'presentation', 'scientist', 'term', 'caucus', 'blocks', 'minimum', 'ohhhhhs', 'shockwaves', 'killers', 'romniguez', 'cavaliers', 'concerts', 'mt', 'sprinter', 'striptease', 'breed', 'alejandro', 'crullers', 'since', 'umbilical', 'solid', 'deodorant', 'pandas', 'phone', 'tweeted', 'dig', 'admires', 'total', 'repaired', 'cockroaches', 'oooh', 'julie', 'rolled', 'synced', 'stylist', 'bachman', 'ups', 'confidence', 'macklemore', 'performance', 'merger', 'waterpark', 'bloodstream', 'watched', 'keynote', 'supporter', 'are', 'chug', 'roommates', 'berlin', 'darker', 'supplied', 'naptime', 'tropical', 'enough', 'online', 'wifi', 'spectrum', 'revelations', 'shadow', 'reason', 'specials', 'fleece', 'erectile', 'outbreak', 'transforms', 'pedophile', 'stops', 'alt', 'jackie', 'scrappy', 'antonio', 'fighter', 'cobblestone', 'out', 'e', 'purchased', 'albums', 'overturn', 'hemp', 'piers', 'carrier', 'infamous', 'robbery', 'belonging', 'somethings', 'sticker', 'fresh', 'saved', 'playoff', 'trumpadopolous', 'vindictive', 'cassettes', 'iceland', 'stacks', 'heterosexual', 'gifts', 'ralph', 'unfamiliar', 'stretcher', 'unarmed', 'superpowers', 'aiming', 'bright', 'officially', 'donated', 'priced', 'snapped', 'word', '.am', 'launching', 'photoshopped', 'apocalyptic', 'eavesdropped', 'deposits', 'viewing', 'ot', 'funds', 'lump', 'traditionally', 'payers', 'chardonnay', 'occur', 'monarch', 'lozenge', 'divider', 'ketchup', 'village', 'handbags', 'traffic', 'answers', 'slave', 'grindr', 'discoverers', 'hears', 'angeles', 'televised', 'rapper', 'swearing', 'credits', 'drescher', 'vamanaos', 'stores', 'touch', 'morning', 'cornerstones', 'chancellor', 'sobbing', 'gumbo', 'lindsay', 'duterte', 'determination', 'shook', 'inadequate', 'landline', 'joint', 'information', 'involves', 'preventing', 'tales', 'threat', 'canadian', 'narrow', 'died', 'guarantee', 'mvp', 'unsafe', 'patdowns', 'baseball', 'theron', 'ballet', 'kobe', 'disregard', 'mosquitoes', 'interviewer', 'gullible', 'slept', 'exempt', 'viewership', 'missile', 'harvey', 'miniseries', 'khloe', 'doc', 'holden', 'colonel', 'continent', 'diamond', 'nike', 'courage', 'ransom', 'irrelevant', 'tense', 'llewyn', 'stealing', '.biz', 'fashion', 'yoda', 'saints', 'unfollowed', 'snowboarder', 'amazeballs', 'recovered', 'lunchbox', 'concerned', 'detected', 'pbr', 'played', 'mafia', 'uninjured', 'botched', 'guthrie', 'dial', 'critics', 'sean', 'duration', 'milfs', 'prodigies', 'permit', 'diarrhea', 'fan', 'spotify', 'religion', 'exhuming', 'skeet', 're', 'explained', 'princes', 'epidemic', 'compartment', 'inaugurate', 'segways', 'oceans', 'abe', 'gadaffi', 'midwesterners', 'apathetic', 'resume', 'harvard', 'jar', 'tripled', 'segway', 'experimental', 'happiest', 'rogaine', 'bob', 'surprising', 'deflategate', 'candidates', 'flees', 'plug', 'springsteen', 'warts', 'sniper', 'forgot', 'rear', 'february', 'bitchface', 'tub', 'locking', 'reconsider', 'genisys', 'maybe', 'muammar', '.com', 'industrial', 'floss', 'stun', 'frees', 'sensation', 'loses', 'neeson', 'rousing', 'moviegoers', 'page', 'blames', 'spock', 'autocorrect', 'distancing', 'bruno', 'thoughtful', 'lime', 'nominate', 'rotary', 'harrelson', 'zombie', 'golden', 'vuvuzela', 'generation', 'emoji', 'ego', 'fired', 'fourteen', 'representatives', 'rachel', 'archery', 'wonderful', 'strikes', 'jindal', 'uniforms', 'experiments', 'keeper', 'reboot', 'stared', 'buff', 'shoebox', 'cain', 'recording', 'bostonians', 'droves', 'slowing', 'extreme', 'rent', 'rabbis', 'followers', 'personnel', 'off', 'favors', 'elevator', 'remarks', 'dc', 'trees', 'assigned', 'beeswax', 'abortions', 'berlusconi', 'disrespectful', 'dickasaur', 'plymouth', 'sandiego', 'globes', 'incorrect', 'breakfast', '.the', 'prepare', 'ronan', 'result', 'wasting', 'slapping', 'way', 'williams', 'kelli', 'ioc', 'all', 'elisabeth', 'loops', 'rolling', 'front', 'tonys', 'fords', 'krispy', 'romance', 'crazies', 'hardest', 'embassy', 'supermoon', 'hards', 'floridians', 'stare', 'portable', 'groot', 'supremacist', 'occupying', 'breach', 'whatevs', 'doesn', 'bracing', 'test', 'margarita', 'forbidden', 'arabia', 'brownies', 'offered', 'born', 'kitty', 'money', 'orgasms', 'resell', 'fulfilling', 'hawk', 'harsh', 'shopping', 'fridays', 'stanford', 'seattle', 'reserved', 'deliver', 'monitored', 'marc', 'labelled', 'engineered', 'spouses', 'defending', 'limp', 'mistrial', 'banderas', 'immigrant', 'similarly', 'terrorists', 'lollapalooza', 'simpler', 'reference', 'tucked', 'okayed', 'thailand', 'febreeze', 'childhood', 'restrictive', 'attacks', 'falls', 'ban', 'protected', 'calmed', 'deported', 'buffet', 'forced', 'packets', 'paltrow', 'stricken', 'dialing', 'happily', 'bouncer', 'ecstatic', 'goooooallll', 'holidays', 'upcoming', 'thanked', 'shitless', 'interrupted', 'gonzalez', 'mace', 'drugs', 'minded', 'orwell', 'muscle', 'binder', 'inclusive', 'connecticut', 'misery', 'spokesman', 'airplane', 'forthcoming', 'hell', 'computers', 'programming', 'ascension', 'smoke', 'dignified', 'indicted', 'loophole', 'william', 'insecure', 'memes', 'lenses', 'involvement', 'slide', 'correct', 'detailed', 'baywatch', 'controversies', 'idea', 'sound', 'selfie', 'figured', 'material', 'development', 'slipped', 'prostitution', 'poppy', 'books', 'empowering', 'trombone', 'ahmadinejad', 'operate', 'childbirth', 'explains', 'garbage', 'wedgie', 'motivational', 'riding', 'cyborg', 'baio', 'pistole', 'prenup', 'guts', 'a', 'robertson', 'speechwriter', 'selfies', 'alias', 'stutterers', 'restaurant', 'suggested', 'sodomites', 'windows', 'tubman', 'decaf', 'dessert', 'words', 'activist', 'discriminates', 'kingsley', 'colicky', 'borderline', 'surrender', 'apollo', 'hotel', 'flat', 'checked', 'arsonist', 'atheist', 'religious', 'massed', 'sunbathing', 'legalizing', 'income', 'nerd', 'sizes', 'comfortable', 'golf', 'vapor', 'civilized', 'adjustable', 'gilbert', 'brief', 'zombies', 'sketching', 'anthony', 'upon', 'blackhawks', 'solemnly', 'customer', 'bris', 'trip', 'gypsy', 'chapters', 'lantern', 'highest', 'irishman', 'divisions', 'primetime', 'arnie', 'sail', 'refugee', 'attempting', 'toaster', 'removed', 'stray', 'committee', 'experiment', 'drunko', 'bottom', 'shoulders', 'levine', 'affleck', 'bombing', 'fetch', 'soaks', 'parodies', 'darth', 'louisiana', 'lingo', 'induced', 'preexisting', 'complex', 'same', 'hey', 'jaw', 'logging', 'ballers', 'lined', 'norquist', 'layer', 'orb', 'videotaped', 'join', 'unleashing', 'symphony', 'auctioned', 'lesbians', 'thursday', 'clash', 'prematurely', 'amazon', 'induce', 'polizzi', 'blake', 'isn', 'phillies', 'turquoise', 'stock', 'firemen', 'destined', 'lin', 'sheboygan', 'continues', 'chaos', 'allies', 'fuming', 'religions', 'describes', 'enacted', 'halted', 'manners', 'those', 'contained', 'afghani', 'troubled', 'attractive', 'somebody', 'crave', 'fishermen', 'fifth', 'severance', 'period', 'flashing', 'typical', 'hijacking', 'millennium', 'evenings', 'smoked', 'rating', 'coulter', 'stab', 'walking', 'previous', 'vilsack', 'paying', 'koosh', 'clermont', 'dispersed', 'razzie', 'cosby', 'balled', 'shampoo', 'implies', 'clarified', 'cougar', 'declassified', 'application', 'fizzio', 'distillery', 'beardy', 'popemobile', 'reflux', 'solution', 'cash', 'lanka', 'dined', 'oversight', 'methane', 'radiohead', 'weathermen', 'unsend', 'gnarly', 'spread', 'hostages', 'wisconsin', 'catapulted', 'priority', 'bidding', 'diabety', 'asked', 'interact', 'subscribe', 'owes', 'struggling', 'workout', 'wrigley', 'howard', 'lifespan', 'harley', 'withdrew', 'extensive', 'bieberfan', 'ultimately', 'macbeth', 'condemn', 'fellas', 'taiwan', 'accomplished', 'eager', 'scam', 'thrilled', 'veterans', 'subjects', 'forgets', 'retires', 'nicknames', 'minnie', 'improves', 'allergic', 'ids', 'blew', 'laps', 'hef', 'lowered', 'builders', 'premier', 'shhh', 'principal', 'lives', 'wed', 'comparing', 'steel', 'airport', 'carlos', 'matzo', 'angle', 'shots', 'matches', 'emirates', 'culprit', 'troop', 'draper', 'risen', 'clinic', 'apb', 'throughout', 'punching', 'wyoming', 'laughs', 'plagiarized', 'danger', 'embracing', 'caucuses', 'bitching', 'unwell', 'sinkhole', 'chicago', 'simulate', 'yuppy', 'renewable', 'casio', 'blocked', 'zika', 'universities', 'hail', 'benched', 'derrick', 'kidding', 'forbes', 'yello', 'contributor', 'finalist', 'niro', 'scoop', 'indiana', 'depot', 'performing', 'reflection', 'course', 'bolivia', 'commitment', 'buys', 'guy', 'quitter', 'snails', 'gospel', 'firing', 'smokers', 'lake', 'margaret', 'hip', 'auburn', 'chewing', 'currently', 'mentioned', 'sustaining', 'djibouti', 'funny', 'reverend', 'rocket', 'gacy', 'transgendered', 'divisive', 'suckapalooza', 'orgies', 'greasy', 'ahold', 'kaepernick', 'district', 'designer', 'jinbao', 'usain', 'compuserve', 'filmed', 'pinch', 'northwestern', 'sermon', 'delicious', 'inspections', 'promising', 'woody', 'earnings', 'attractions', 'hathaway', 'escalating', 'lovin', 'scary', 'unprofessional', 'handle', 'hicks', 'snorkeling', 'factory', 'tearing', 'hiking', 'genitals', 'cleveland', 'outgoing', 'negativity', 'await', 'pharrell', 'compatible', 'bestseller', 'grubbing', 'biracial', 'console', 'seeking', 'squarepants', 'defection', 'notes', 'ugly', 'waitresses', 'narrated', 'sundress', 'exclusive', 'john', 'third', 'brownie', 'definitive', 'caviar', 'mabel', 'neighbor', 'scarecrow', 'sponges', 'groban', 'skyrocketing', 'users', 'easier', 'piss', 'knees', 'sentenced', 'locals', 'entrepreneur', 'saffiano', 'fraternity', 'onto', 'owner', 'judicial', 'rudest', 'jocks', 'titled', 'medalists', 'monks', 'growers', 'incidentally', 'abel', 'catholics', 'clint', 'trampled', 'mammograms', 'champ', 'frappuccino', 'rings', 'sentencing', 'fragile', 'preview', 'introverted', 'innocence', 'playboys', 'advising', 'bunny', 'hope', 'cannes', 'ligers', 'inflates', 'results', 'substance', 'splash', 'obstruction', 'showers', 'preserve', 'straw', 'bp', 'unpopularity', 'doubling', 'blame', 'bribery', 'brazilian', 'or', 'arusha', 'procedures', 'ape', 'underinflated', 'drain', 'torture', 'parking', 'nickelodeon', 'redstone', 'buzzed', 'uk', 'orange', 'meatballs', 'libyan', 'identity', 'stash', 'y', 'engraver', 'posing', 'cokeheads', 'mangold', 'moderate', 'handcuffed', 'junior', 'rappers', 'motley', 'around', 'wearing', 'piano', 'detained', 'martial', 'atheism', 'jewish', 'fallout', 'length', 'diet', 'intoxicated', 'crouton', 'header', 'toy', 'swing', 'vinegar', 'indoor', 'serena', 'laptops', 'arteries', 'play', 'peasant', 'pinatas', 'gun', 'connecting', 'voiceover', 'heywood', 'anvil', 'bueller', 'swam', 'glasses', 'arrivals', 'lends', 'trendy', 'disrespected', 'knight', 'backstage', 'lights', 'sheet', 'during', 'mano', 'turin', 'fluorescent', 'named', 'ranger', 'shotgun', 'moaning', 'muscles', 'columnists', 'expendables', 'peppermint', 'winslet', 'disputed', 'premature', 'stocked', 'handwriting', 'arkadina', 'unintended', 'viral', 'asses', 'fully', 'flooded', 'panel', 'he', 'tracked', 'shinzo', 'foxx', 'pasty', 'sorority', 'anheuser', 'phase', 'sarah', 'snipes', 'backwards', 'last', 'the', 'consumer', 'anal', 'nadya', 'inhale', 'cds', 'flee', 'tone', 'alex', 'solstice', 'decriminalizing', 'jeopardy', 'bree', 'outdone', 'clothing', 'historians', 'rack', 'healthy', 'sausage', 'occasion', 'afternoon', 'smells', 'reelection', 'pal', 'caffienefree', 'emails', 'buddies', 'streep', 'nunberg', 'flubbed', 'syrup', 'ballmer', 'drapes', 'gumble', 'climbing', 'survivor', 'couric', 'santa', 'trillions', 'adoring', 'husbands', 'late', 'sweet', 'bat', 'penniless', 'sharpton', 'entity', 'shelter', 'visual', 'colors', 'mischievous', 'seagull', 'dictatorship', 'triple', 'warmth', 'rope', 'delaware', 'del', 'product', 'humanitarian', 'strongest', 'penn', 'screenplays', 'stuffed', 'notarized', 'drummer', 'parachute', 'deliveries', 'cutest', 'films', 'sporty', 'without', 'seeing', 'coco', 'retrieve', 'drank', 'sweater', 'salute', 'imperfections', 'cheesehead', 'protect', 'revamp', 'helpless', 'jordan', 'nights', 'philosophers', 'mcmuffin', 'bags', 'sweaters', 'newpopenewrules', 'rousey', 'herman', 'bullying', 'broadcasts', 'consuming', 'coined', 'depressions', 'pimps', 'realizing', 'll', 'here', 'snowden', 'glazed', 'consists', 'nutmeg', 'bang', 'fairground', 'disagreements', 'described', 'sideboob', 'altercation', 'admire', 'augmentation', 'alba', 'wichita', 'waiting', 'childrearing', 'denzel', 'several', 'pretty', 'duran', 'drinkers', 'chatroom', 'buffets', 'foot', 'powder', 'drives', 'digs', 'phish', 'grandparents', 'vibrators', 'chimney', 'rebecca', 'jokingly', 'defensive', 'gunning', 'fewer', 'psychiatric', 'criticized', 'ambushing', 'endings', 'yale', 'dispenser', 'irma', 'bronze', 'fey', 'baconalia', 'shout', 'respects', 'punished', 'accelerator', 'fukushima', 'authorizing', 'mayan', 'escobar', 'trained', 'obamaphobic', 'bitter', 'neal', 'addition', 'cfo', 'grabbing', 'recreated', 'if', 'collectibles', 'treasury', 'dove', 'walker', 'breastfeeding', 'attendants', 'archimedes', 'sells', 'experts', 'conspiracy', 'declare', 'protestors', 'recalling', 'gain', 'further', 'roker', 'vomit', 'buttocks', 'skyrocketed', 'filter', 'acknowledged', 'hackysack', 'transformation', 'size', 'experiencing', 'hay', 'cornerback', 'physically', 'breaches', 'cutout', 'table', 'masturbated', 'alternative', 'munchies', 'mixing', 'engines', 'rhymes', 'mart', 'zellweger', 'minister', 'swimmer', 'exposing', 'ridden', 'holocaust', 'shakespeare', 'escorts', 'breastfed', 'zooey', 'about', 'campaigning', 'dakota', 'drama', 'modified', 'central', 'winners', 'fancy', 'fly', 'professionals', 'surgery', 'prime', 'prescriptions', 'columbus', 'misunderstood', 'armadillo', 'rejuvenation', 'uphold', 'preschoolers', 'count', 'girl', 'glen', 'chip', 'pillows', 've', 'abstain', 'hands', 'fiorina', 'covered', 'inlcude', 'hammer', 'nina', 'seats', 'resembles', 'janeiro', 'butt', 'koreatown', 'pinata', 'breastfeed', 'world', 'embedded', 'next', 'fart', 'frustration', 'cuisine', 'bern', 'conviction', 'understanding', 'shipping', 'ed', 'millan', 'office', 'lying', 'aimed', 'occasional', 'publishing', 'gras', 'revenant', 'measure', 'smug', 'flame', 'benedict', 'load', 'cards', 'kardashia', 'gallons', 'schultz', 'angered', 'ballad', 'moron', 'gadhafi', 'drop', 'hasselhoff', 'nut', 'newborn', 'burgers', 'erotic', 'smurf', 'lightweight', 'cloned', 'bacterial', 'motorists', 'inarticulate', 'creditors', 'comparison', 'stranger', 'another', 'advice', 'butler', 'cravings', 'referee', 'sunscreen', 'jablowme', 'afford', 'mubarek', 'irony', 'reminds', 'apologizing', 'mo', 'concert', 'anne', 'delight', 'hoses', 'kasich', 'scope', 'foreign', 'instructions', 'barrel', 'confused', 'robber', 'isosceles', 'seriously', 'something', 'congrats', 'constituents', 'basis', 'karaoke', 'hooking', 'stooges', 'nipples', 'fury', 'redacted', 'wound', 'hosni', 'biting', 'volcano', 'seth', 'cumberbed', 'rejecting', 'longer', 'tonto', 'tip', 'juggs', 'offensive', 'abc', 'sidewalk', 'khamenei', 'pouring', 'bends', 'climate', 'tan', 'knocked', 'enthusiasm', 'crossword', 'memorizing', 'kardashian', 'german', 'nursing', 'veganism', 'yet', 'dinner', 'plummeted', 'goldberg', 'marquez', 'interview', 'indispensable', 'diagnose', 'airports', 'pillow', 'waxing', 'virtual', 'silly', 'gays', 'ship', 'newlyweds', 'midnight', 'devos', 'investor', 'moan', 'derogatory', 'sanchez', 'hud', 'boost', 'hires', 'connotations', 'afraid', 'impoverished', 'dilapidated', 'decade', 'bowl', 'sapiens', 'jersey', 'mccarthy', 'boycotting', 'ymca', 'vp', 'dreadlocks', 'pregnancy', 'shrimpy', 'tentacle', 'searched', 'dicaprio', 'cambodia', 'hurley', 'largely', 'earlier', 'humvees', 'poetry', 'concerns', 'haircut', 'urine', 'dies', 'invade', 'peak', 'amateur', 'decision', 'trekkies', 'nickname', 'ken', 'pair', 'cursed', 'counterfeit', 'ceremony', 'dates', 'moore', 'sum', 'leaf', 'deflates', 'alienated', 'raul', 'goals', 'resort', 'filed', 'mcbites', 'yell', 'couplings', 'chose', 'interfere', 'meaning', 'underestimate', 'garcia', 'ensure', 'babysitters', 'amazing', 'monsters', 'occurs', 'mooning', 'task', 'reusable', 'complaints', 'diagonally', 'attended', 'charmin', 'twisted', 'packages', 'guilty', 'foreclosure', 'fitbit', 'homeless', 'squint', 'sensibilities', 'admit', 'pay', 'blackmailed', 'meggings', 'omelets', 'spangled', 'nyu', 'pacquaio', 'edited', 'rub', 'seller', 'clad', 'shortened', 'hereby', 'dominos', 'vanna', 'hijacked', 'organisms', 'stamping', 'costumes', 'methylvania', 'lengths', 'protocol', 'antonin', 'jagger', 'glad', 'comcast', 'revolution', 'paperback', 'restrained', 'debate', 'lasso', 'prefers', 'unwanted', 'clock', 'evolving', 'kagan', 'robots', 'express', 'tom', 'quitting', 'flamin', 'watchmen', 'anywhere', 'wangs', 'adam', 'replicate', 'meeee', 'ramadan', 'trespasser', 'excess', 'heavyweight', 'lgbt', 'jihad', 'duolingo', 'icon', 'chinese', 'carrie', 'airplanes', 'buying', 'poke', 'ad', 'consent', 'klein', 'becoming', 'poorly', 'leveling', 'jumbotron', 'category', 'criticizing', 'evolutionarily', 'figure', 'trails', 'holding', 'assembled', 'mars', 'aaron', 'september', 'tightens', 'puppeteer', 'stack', 'calls', 'julia', 'coding', 'marry', 'closely', 'bogus', 'wintour', 'smoothing', 'islamabad', 'shell', 'tweeter', 'fling', 'supermodel', 'ron', 'tanner', 'hadassah', 'halifax', 'hangs', 'suggestions', 'sparked', 'whoever', 'chamber', 'taurus', 'rays', 'endorsing', 'topaz', 'foundation', 'pakistani', 'leather', 'vindicates', 'weasel', 'eighty', 'mask', 'spelled', 'flight', 'follow', 'barrymore', 'speaking', 'petition', 'rewarded', 'commemorating', 'king', 'position', 'stones', 'goal', 'congratulate', 'wendy', 'sinai', 'sucking', 'rick', 'retainer', 'appreciates', 'aquaman', 'cyrus', 'courthouse', 'phil', 'chipper', 'geraldo', 'terrorizing', 'seized', 'sleep', 'cramps', 'islam', 'mammogram', 'slot', 'refugees', 'relish', 'paint', 'edinburgh', 'shows', 'ready', 'quentin', 'encouraged', 'hers', 'portals', 'overwhelming', 'ucla', 'shiny', 'jeffery', 'weirder', 'resembling', 'tribes', 'vile', 'emotionally', 'devotion', 'trailing', 'rigatoni', 'tables', 'koreans', 'lean', 'ton', 'consumers', 'homo', 'side', 'strength', 'gaynor', 'lynyrd', 'eastern', 'traumatize', 'ccino', 'amputated', 'fundraising', 'mayo', 'fistfight', 'multi', 'owns', 'lab', 'ink', 'baths', 'hotline', 'norelco', 'with', 'pessimists', 'prosecutor', 'team', 'tricked', 'goodly', 'inspection', 'miners', 'leonard', 'choices', 'them', 'leaks', 'quoting', 'offense', 'murderers', 'shutdown', 'temperatures', 'natalie', 'resumed', 'podium', 'mount', 'memo', 'ecstasy', 'selection', 'dialed', 'chest', 'filner', 'tortilla', 'grinch', 'hoosier', 'order', 'writing', 'comic', 'london', 'clinics', 'ago', 'crust', 'hint', 'deposit', 'prada', 'troubles', 'espouse', 'tulsa', 'cho', 'combed', 'locks', 'frustrated', 'fishing', 'storms', 'profound', 'jealously', 'israel', 'rape', 'blues', 'confessed', 'twins', 'tristate', 'quicken', 'cover', 'freud', 'flavors', 'imaginary', 'blog', 'steering', 'audit', 'help', 'epa', 'wocks', 'gwb', 'assange', 'discernable', 'dean', 'turning', 'muppets', '.o', 'horton', 'grueling', 'verge', 'sprinkles', 'below', 'knows', 'whores', 'melting', 'subtract', 'stopping', 'mistreated', 'hardware', 'mc', 'olbermann', 'notice', 'capital', 'firebrand', 'outfit', 'ers', 'seafood', 'blabbing', 'severed', 'surveyors', 'stability', 'voicemail', 'claimed', 'animal', 'cousins', 'chin', 'applaud', 'gravity', 'welcoming', 'region', 'slightly', 'twerked', 'hoverboards', 'italy', 'profit', 'whitest', 'newest', 'nutella', 'plain', 'bitchy', 'cowards', 'wii', 'transcripts', 'impersonating', 'floating', 'easy', 'lion', 'condition', 'ventriloquist', 'badass', 'unsportsmanlike', 'end', 'resigned', 'grammer', 'group', 'overpaid', 'happen', 'rainforest', 'disconnected', 'audience', 'pickup', 'papier', 'toast', 'pixar', 'christopher', 'pissed', 'shirts', 'recommending', 'walmart', 'scott', 'vienna', 'castro', 'crazier', 'evidently', 'followed', 'impeach', 'handed', 'peeks', 'apart', 'unblocked', 'prospective', 'looked', 'bull', 'breast', 'kick', 'kristen', 'magician', 'puzzle', 'update', 'hellacious', 'phoned', 'surprises', 'packing', 'todd', 'simplifying', 'textbook', 'loafers', 'grandsons', 'poverty', 'laundry', 'sleeping', 'rabies', 'estevez', 'makes', 'rant', 'particle', 'community', 'conservative', 'networks', 'stepped', 'throne', 'strengthen', 'tween', 'prospect', 'fill', 'elevate', 'grabs', 'silent', 'groom', 'nephew', 'google', 'flunking', 'd', 'pruitt', 'dobby', 'distinguish', 'anything', 'arrested', 'injustice', 'ivanka', 'acid', 'wiener', 'closet', 'ernest', 'proclaiming', 'such', 'gerard', 'revoke', 'harry', 'amigos', 'undying', 'shared', 'chart', 'harmed', 'legend', 'shrill', 'fleet', 'video', 'impress', 'taser', 'batshit', 'olivia', 'cargo', 'thighs', 'daughters', 'gle', 'nurses', 'nicknamed', 'annoyed', 'unhealthy', 'tickle', 'referees', 'proportional', 'celine', 'fellow', 'weird', 'ceremonies', 'aides', 'fermented', 'michaels', 'odd', 'compete', 'hometown', 'coolers', 'heels', 'tijuana', 'leaner', 'widen', 'forgive', 'tapping', 'goatees', 'others', 'super', 'immediately', 'leia', 'pottery', 'derby', 'chock', 'submarine', 'oath', 'crawl', 'coors', 'lords', 'deleting', 'turnout', 'intervention', 'maintain', 'taxi', 'shattered', 'descending', 'unofficial', 'postmaster', 'court', 'faulty', 'analysts', 'ab', 'mention', 'suspiciously', 'torah', 'departed', 'ladies', 'microbes', 'murdoch', 'legitimate', 'awarded', 'fish', 'peeps', 'image', 'glaad', 'v', 'through', 'nimoy', 'gingrich', 'challenging', 'elbowed', 'ending', 'megyn', 'have', 'bahamas', 'sticking', 'gentle', 'stronger', 'priest', 'dolls', 'yourself', 'skirt', 'ode', 'diverted', 'billboards', 'expensive', 'cuts', 'malaysia', 'shirt', 'jungle', 'lucky', 'miranda', 'kangaroo', 'swapping', 'fade', 'realm', 'sin', 'above', 'loom', 'unplanned', 'virginians', 'basic', 'demanded', 'joakim', 'clergy', 'unzipping', 'eating', 'kate', 'minus', 'disappears', 'criminal', 'walters', 'monitors', 'tacky', 'congressional', 'graduation', 'fed', 'vegas', 'capability', 'delaying', 'atheists', 'second', 'intercom', 'individual', 'married', 'undefeated', 'apologize', 'authentic', 'statements', 'minnesotans', 'soothing', 'detroit', 'scream', 'extramarital', 'nonsense', 'warriors', 'pretended', 'syncing', 'stephanie', 'understands', 'oddly', 'occasionally', 'controversial', 'shouldtrumprun', 'legal', 'discriminate', 'redheaded', 'roper', 'mayoral', 'instilling', 'teasing', 'catholic', 'steroid', 'art', 'brrrains', 'chairs', 'geyser', 'facility', 'grilled', 'allegations', 'referred', 'hips', 'bracelets', 'adderall', 'look', 'expired', 'fist', 'peppers', 'harbaugh', 'rodman', 'lamborghini', 'bristol', 'electricity', 'quilt', 'necessary', 'overrated', 'addicts', 'pornhub', 'deserves', 'repeat', 'nyc', 'destroy', 'wrote', 'info', 'slugger', 'sundown', 'released', 'crook', 'mystifying', 'damon', 'fig', 'finger', 'meeting', 'finishes', 'angrily', 'marked', 'praise', 'oneself', 'asia', 'dangerous', 'magazines', 'accidental', 'deliberated', 'tattoos', 'gambler', 'branson', 'charities', 'tablecloths', 'decorated', 'kfc', 'duggar', 'believes', 'powerful', 'penis', 'gloomy', 'tucking', 'bridges', 'ally', 'coconuts', 'pete', 'dressed', 'open', 'unbelievable', 'fitzgerald', 'corrective', 'sauteed', 'poisoning', 'delegate', 'then', 'dec', 'loud', 'themed', 'popped', 'forgiveness', 'lucrative', 'horny', 'cape', 'owned', 'tech', 'burped', 'barnes', 'researchers', 'apparently', '.things', 'medicare', 'reported', 'parades', 'lack', 'casual', 'babysitting', 'changes', 'lacks', 'chickens', 'spam', 'trump', 'supporters', 'aristotle', 'patrol', 'rider', 'banning', 'timmy', 'purchase', 'clips', 'treatment', 'terms', 'duuude', 'streams', 'wood', 'gore', 'reverse', 'handlers', 'reveals', 'records', 'witchcraft', 'states', 'cultural', 'maxi', 'wants', 'burns', 'ocean', 'handsome', 'respect', 'wild', 'campaigns', 'cracker', 'dickens', 'expecting', 'ikcin', 'archaeologists', 'jolie', 'goats', 'opposed', 'donor', 'meant', 'csi', 'sexted', 'ufc', 'definitely', 'invested', 'teams', 'paid', 'gary', 'marines', 'counselor', 'keep', 'cajun', 'upset', 'readers', 'tyrant', 'american', 'calvin', 'squirtle', '?', 'spacey', 'fiction', 'oopsie', 'spun', 'guards', 'jammed', 'citizens', 'fedex', 'menstrual', 'adjusting', 'tunnels', 'pepper', 'carriage', 'luggage', 'lured', 'titans', 'expenses', 'counts', 'hassan', 'financially', 'syllable', 'substitute', 'birds', 'jihadi', 'ironic', 'level', 'traded', 'complicated', 'alien', 'friend', 'stank', 'promoted', 'criminals', 'modify', 'aladdin', 'nigerian', 'fo', 'strokes', 'pays', 'weatherman', 'kitchen', 'disease', 'hoho', 'nbc', 'misinterpreted', 'endorsements', 'stretch', 'scrolls', 'falsetto', 'bullets', 'colombia', 'antarctic', 'lifted', 'frequent', 'douchebaggery', 'elks', 'performances', 'corinthians', 'opposites', 'two', 'bands', 'injecting', 'symbolism', 'sony', 'brexit', 'kelloggs', 'recovering', 'lautner', 'shades', 'masturbating', 'content', 'de', 'legislation', 'severity', 'whether', 'onboard', 'stormy', 'him', 'pen', 'air', 'holmes', 'windshield', 'ocd', 'university', 'in', 'swastikas', 'dump', 'supermodels', 'flacco', 'rebroadcast', 'malik', 'cbs', 'kylie', 'tabulated', 'coalition', 'exclusively', 'elementary', 'gimme', 'massages', 'lockout', 'uh', 'swear', 'wig', 'motorcycles', 'maze', 'chill', 'diego', 'distributed', 'opposes', 'raise', 'rip', 'shining', 'nwa', 'misunderstanding', 'prop', 'trek', 'investors', 'doorman', 'wrecks', 'boston', 'feature', 'conan', 'treats', 'perignon', 'learned', 'bestselling', 'snapping', 'turkish', 'burglars', 'janim', 'brazil', 'tab', 'dishes', 'chosen', 'idina', 'vacations', 'stewart', 'seated', 'haired', 'joseph', 'snacks', 'obstruct', 'specimen', 'dissident', 'unemployment', 'genital', 'energy', 'boiling', 'repelled', 'slut', 'agenda', 'altered', 'gandhi', 'beliefs', 'drunk', 'mean', 'prisoner', 'baker', 'persuasive', 'headed', 'assad', 'pluto', 'revenge', 'balanced', 'unpopular', 'spongebob', 'povich', 'letting', 'assembly', 'contacting', 'alligator', 'beijing', 'knew', 'lopez', 'spitzer', 'heroin', 'wee', 'fema', 'accountants', 'hashanah', 'goalie', 'lately', 'cooked', 'breakthrough', 'organized', 'knockoff', 'thanking', 'tasered', 'wedding', 'emptied', 'toilets', 'reproduction', 'kicks', 'continue', 'barbie', 'umm', 'hijab', 'masseuse', 'phenom', '.k', 'shitshow', 'enjoy', 'prior', 'baloney', 'knives', 'live', 'pokemon', 'wields', 'physician', 'served', 'dea', 'lifelike', 'sponsored', 'toxins', 'handcrafts', 'goalsevelt', 'growth', 'mother', 'cuddly', 'wealthy', 'artifacts', 'moos', 'worse', 'quaid', 'case', 'meanwhile', 'primate', 'shitload', 'iran', 'criticism', 'preparation', 'rulings', 'genetic', 'consequences', 'wingmen', 'burts', 'stepping', 'wussystan', 'garcetti', 'happy', 'durst', 'commerce', 'months', 'scalia', 'judd', 'prays', 'teen', 'sharpie', 'bert', 'puns', 'coincide', 'gretzki', 'rested', 'firefighters', 'stars', 'direct', 'amazingly', 'sepp', 'markle', 'ruled', 'morgan', 'avoiding', 'speilbergs', 'mon', 'plural', 'speed', 'vendors', 'graffiti', 'humphries', 'priebus', 'providing', 'suckers', 'poses', 'secret', 'reebok', 'chai', 'wakanda', 'problemo', 'sexting', 'york', 'lesson', 'gwyneth', 'douchebags', 'negative', 'silver', 'abogado', 'these', 'avenger', 'indecent', 'weiner', 'nurse', 'bing', 'bodies', 'doable', 'pretzel', 'cheapskate', 'darwinism', 'stylish', 'diversity', 'sandy', 'made', 'billy', 'moderators', '.l', 'thru', 'matadors', 'snowstorm', 'inhibitions', 'trix', 'drowned', 'motorola', 'breyer', 'sort', 'shift', 'ever', 'calf', 'prone', 'premiere', 'irresponsible', 'snow', 'songs', 'offering', 'collins', 'zookeeper', 'mike', 'midair', 'hour', 'darwin', 'cams', 'path', 'banner', 'inherited', 'fundraisers', 'homework', 'based', 'example', 'cure', 'tricycle', 'extremists', 'loaded', 'willingly', 'chihuahua', 'clouds', 'eisenhower', 'calculated', 'iconic', 'tgif', 'wen', 'scrub', 'jamaican', 'wives', 'bronx', 'ruth', 'brewed', 'shitting', 'horn', 'heartthrob', 'punish', 'core', 'crush', 'rusty', 'received', 'rectum', 'improper', 'nurturing', 'russian', 'jaden', 'replacement', 'stubbornly', 'heckled', 'proposal', 'equivalent', 'premiered', 'collect', 'foe', 'semester', 'transplanted', 'pirate', 'kim', 'concussion', 'dr', 'withdrawing', 'probably', 'bedroom', 'demagogue', 'returns', 'vacate', 'bishop', 'battleship', 'slash', 'optometrist', 'degree', 'charles', 'dayum', 'sexually', 'achy', 'activities', 'interviewing', 'screenings', 'sofia', 'repeal', 'waging', 'conception', 'hindenburg', 'bill', 'newspapers', 'ends', 'steak', 'co', 'squander', 'gluttony', 'reduced', 'hangover', 'cookie', 'eaten', 'bosses', 'pic', 'kinds', 'achieve', 'attempts', 'lohans', 'coordinated', 'rainbow', 'kale', '.true', 'touched', 'prince', 'passed', 'rivera', 'frequenting', 'january', 'defund', 'origins', 'memorabilia', 'documentaries', 'basket', 'technological', 'sneaking', 'refused', 'barrier', 'station', 'primitive', 'land', 'sexo', 'inner', 'donnell', 'charity', 'orangutan', 'discount', 'nose', 'debts', 'wilson', '.m', 'candles', 'beg', 'millennials', 'soaker', 'teach', 'ratted', 'freudian', 'failings', 'gerrymandering', 'relates', 'incivility', 'monday', 'greatest', 'laying', 'booty', 'dogg', 'relax', 'forth', 'sheikh', 'norad', 'bell', 'mosquito', 'trustworthy', 'enforcement', 'truthful', 'mordecai', 'excitement', 'worthwhile', 'somersault', 'nonstop', 'dora', 'conferences', 'ordinance', 'gina', 'knelt', 'couch', 'packaging', 'slovenian', 'bigoted', 'access', 'luis', 'condom', 'duffle', 'frame', 'adviser', 'pilot', 'crimes', 'barely', 'days', 'janine', 'thousandth', 'theorist', 'high', 'performer', 'karashian', 'nye', 'writer', 'squidward', 'copied', 'stick', 'overcompensating', 'turned', 'wimpy', 'cabs', 'power', 'files', 'witch', 'sooo', 'netting', 'lend', 'steelers', 'appendectomy', 'encourages', 'veil', 'affairs', 'candidacy', 'faithful', 'metaphors', 'branded', 'bears', 'dna', 'packers', 'gutted', 'redistributes', 'recreate', 'torn', 'polygraph', 'flav', 'kofi', 'birthrate', 'dtf', 'fondly', 'jenkins', 'underpants', 'shitsville', 'loosen', 'reactor', 'amtrak', 'stitches', 'site', 'rupert', 'furniture', 'interim', 'unveil', 'rod', 'cooperation', 'appease', 'proposed', 'like', 'vacuum', '.c', 'reenactments', 'screwin', 'textbooks', 'boko', 'climbs', 'blast', 'census', 'rosa', 'triggered', 'jackman', 'gaga', 'bridal', 'tripped', 'chia', 'cage', 'expletives', 'marketed', 'waffles', 'gave', 'retired', 'chariot', 'cesar', 'kiss', 'mistook', 'modeled', 'busty', 'laser', 'seizure', 'feuding', 'similar', 'alternatives', 'shipwreck', 'unprotected', '.b', 'duct', 'wrecking', 'deceptive', 'childbirths', 'belarus', 'resistant', 'intruded', 'ramses', 'advancement', 'shelley', 'exhale', 'wing', 'mac', 'hopes', 'fatty', 'beverage', 'ag', 'knife', 'iwilldiealone', 'monologues', 'jonas', 'infringement', 'salvation', 'cheese', 'f', 'ricky', 'shoes', 'forward', 'lynch', 'downwind', 'collector', 'plates', 'traveled', 'financial', 'choir', 'rift', 'mop', 'fearless', 'cyber', 'parade', 'fascinated', 'fives', 'yelled', 'pinta', 'nelson', 'statute', 'paula', 'pizzas', 'quick', 'groundhog', 'objected', 'more', 'pending', 'pirates', 'dout', 'connor', 'bachmann', 'dispensary', 'judges', 'politicians', 'olsen', 'tourism', 'incumbent', 'come', 'bypass', 'gallon', 'transylvania', 'librarian', 'wrap', 'cardboard', 'what', 'hosting', 'libyans', 'underwriters', 'society', 'videotape', 'fallen', 'intentionally', 'cashier', 'bitten', 'killing', 'tools', 'giggled', 'debt', 'bizkit', 'airing', 'facilities', 'contact', 'mode', 'needed', 'underage', 'jesse', 'metallica', 'jebs', 'criticizes', 'russians', 'wrangler', 'white', 'powell', 'got', 'adulthood', 'connects', 'tapped', 'holt', 'machete', 'excited', 'hypochondriac', 'weisser', 'lama', 'checkout', 'represents', 'reserve', 'arrogance', 'bear', 'endorses', 'adele', 'labor', 'luckier', 'midway', 'andy', 'kardashazoic', 'oyster', 'viewed', 'download', 'essays', 'mcrib', 'liotta', 'timed', 'concludes', 'cellphone', 'hurricanes', 'humble', 'belvedere', 'entice', 'blanco', 'batman', 'pursuit', 'chillary', 'literally', '.i', 'apologized', 'alley', 'liquidated', 'chunks', 'gibson', 'taught', 'horse', 'diggin', 'commercials', 'fax', 'stamps', 'garybusey', 'herself', 'printing', 'schindler', 'enhancement', 'santorum', 'agony', 'glove', 'ate', 'enjoyed', 'pollsters', 'whereabouts', 'moist', 'sliding', 'wolves', 'limits', 'puberty', 'mathematician', 'ludacris', 'ricans', 'liberty', 'nightly', 'purpose', 'entertaining', 'serbian', 'dishwasher', 'barber', 'serve', 'ballooned', 'knowledge', 'hendrix', 'previously', 'very', 'weeds', 'stress', 'souffle', 'acts', 'n', 'inflatable', 'boob', 'hitting', 'stapled', 'anymore', 'whenever', 'freeze', 'hiding', 'sears', 'caps', 'pled', 'whopping', 'pacino', 'raining', 'competitively', 'joblessness', 'horses', 'bush', 'photoshoot', 'nowhere', 'david', 'futuristic', 'pakistanis', 'prison', 'cardinal', 'cowboy', 'joy', 'brewing', 'sixth', 'shame', 'underwear', 'investigatin', 'idiot', 'hearings', 'clown', 'gesture', 'anniversary', 'copies', 'endorsed', 'enriching', 'westminster', 'oreo', 'smartphone', 'policy', 'middle', 'cocacola', 'code', 'ethiopia', 'ryder', 'implemented', 'argument', 'goddamn', 'negotiations', 'hit', 'omaha', 'trademark', 'schoolchildren', 'hooters', 'any', 'final', 'physical', 'nicholas', 'travellers', 'gisele', 'tweets', 'titus', 'dress', 'demoted', 'gotham', 'brad', 'mutants', 'politely', 'language', 'scarjo', 'softcore', 'spies', 'confusing', 'twinkie', 'speedo', 'breasts', 'bungee', 'declined', 'engage', 'stamina', 'issues', 'tackle', 'unprepared', 'loyal', 'patron', 'angels', 'precaution', 'longstanding', 'duracell', 'creators', 'shemp', 'canonizing', 'buckingham', 'factories', 'rightfully', 'mommy', 'grammy', 'younger', 'causing', 'mueller', 'flaming', 'schedule', 'cognitive', 'works', 'formation', 'rioted', 'chemistry', 'couldn', 'extinct', 'outta', 'preschool', 'unleash', 'yolo', 'patriotism', 'egyptians', 'cyberattack', 'testosterone', 'inmate', 'span', 'places', 'prequel', 'angriest', 'kyle', 'bored', 'sochi', 'wolverine', 'duffel', 'judaism', 'originally', 'constant', 'setback', 'even', 'cones', 'cranky', 'emilio', 'painting', 'corruption', 'french', 'hummer', 'teas', 'resources', 'hallucinogenic', 'june', 'mayors', 'impersonator', 'devoted', 'riverside', 'producing', 'fair', 'estimated', 'cups', 'consulted', 'robbed', 'drinker', 'agnew', 'whisperer', 'explodes', 'sweetheart', 'hart', 'principled', 'give', 'reasonably', 'stripper', 'orioles', 'devices', 'gettysburg', 'michigan', 'patties', 'max', 'overcompensator', 'soooo', 'creating', 'metoo', 'wealthiest', 'rumors', 'pedophilia', 'delusion', 'newer', 'abandon', 'spotlight', 'disguised', 'superior', 'jumbo', 'offspring', 'bumblebees', 'patted', 'scans', 'apples', 'ay', 'provide', 'translations', 'packed', 'bone', 'tremendous', 'spell', 'dartmouth', 'stalling', 'lawn', 'subsidy', 'gunn', 'tarantino', 'competitive', 'burning', 'patdown', 'pharoah', 'britain', 'jfk', 'doing', 'criticisms', 'men', 'busey', 'boy', 'education', 'relieve', 'skiing', 'curse', 'birdies', 'mickey', 'anaconda', 'patent', 'dangers', 'ipod', 'dilbert', 'sheik', 'comfort', 'dismangle', 'hoof', 'snap', 'clinically', 'gamal', 'innovative', 'bo', 'acceptance', 'programmed', 'posts', 'kelsey', 'jones', 'mandate', 'generating', 'cheapest', 'cats', 'implants', 'busters', 'raisins', 'patients', 'junkie', 'rival', 'reduce', 'obtained', 'weinstein', 'cosmetic', 'hills', 'fiiiine', 'nh', 'residence', 'remaining', 'indirect', 'cable', 'commander', 'misquoted', 'select', 'intelligent', 'soap', 'anthem', 'blogger', 'koch', 'generated', 'deadbeat', 'mentos', 'tricks', 'frank', 'care', 'deporting', 'mentally', 'leaping', 'eliminates', 'photos', 'realistic', 'grover', 'toupee', 'hu', 'replaces', 'recordings', 'dashboard', 'bumblebee', 'happened', 'lawmakers', 'okay', '.j', 'protest', 'louder', 'friction', 'smallest', 'abruptly', 'collecting', 'melania', 'actresses', 'culinary', 'stereotypes', 'lsd', 'phoenix', 'sharon', 'dolphins', 'trevor', 'regret', 'disliked', 'burned', 'euro', 'hallows', 'possible', 'tony', 'shaquille', 'deportation', 'unattended', 'ignores', 'still', 'armor', 'withdraw', 'tesla', 'treadmill', 'bees', 'residents', 'surpassing', 'shrinkage', 'audible', 'persistent', 'everyone', 'hookers', 'jenna', 'briefing', 'hoes', 'koala', 'sullivan', 'washington', 'fear', 'sunday', 'cait', 'person', 'genitalia', 'consolation', 'invite', 'profanity', 'votes', 'screenplay', 'greet', 'dude', 'expressions', 'possessing', 'crashes', 'suspect', 'outs', 'commented', 'sac', 'longtime', 'horror', 'missing', 'entails', 'godly', 'pneumonia', 'purse', 'haircuts', 'straight', 'permission', 'headquartered', 'hefner', 'dulls', 'rants', 'dockers', 'tones', 'jackass', 'dents', 'smoothie', 'evangelista', 'prescribe', 'rehab', 'saluting', 'sons', 'berries', 'insensitive', 'preceded', 'washing', 'leprechauns', 'clothes', 'coach', 'opera', 'diminished', 'extradited', 'outrageous', 'toward', 'smalls', 'recorded', 'cars', 'duck', 'papal', 'spiced', 'leave', 'dallas', 'potter', 'commando', 'zimbabwe', 'egomaniacal', 'religiously', 'explorer', 'couples', 'wal', 'rid', 'crunchy', 'cooking', 'saudi', 'bayne', 'revere', 'dropper', 'mnuchin', 'assaulting', 'weeknd', 'observation', 'rebuild', 'virus', 'andre', 'divers', 'adolf', 'testify', 'tailpipe', 'country', 'franklin', 'suggests', 'eleanor', 'sensor', 'favor', 'doritos', 'terrorism', 'japenese', 'skins', 'related', 'conference', 'wipe', 'especially', 'mick', 'basically', 'scoring', 'slight', 'penguin', 'cheating', 'sold', 'raunchy', 'spiny', 'bent', 'broke', 'nauseous', 'brunettes', 'directions', 'crushing', 'bumped', 'waffle', 'issuing', 'pyeongchang', 'giving', 'wardrobe', 'mongolia', 'communication', 'id', 'safety', 'complimented', 'speaks', 'artistic', 'staffers', 'drugging', 'hallucination', 'squirrels', 'tire', 'score', 'fight', 'christine', 'appletini', 'highly', 'cadbury', 'coldest', 'panties', 'rand', 'kill', 'sponsors', 'controversy', 'fool', 'undescended', 'penile', 'transform', 'eisenberg', 'sample', 'sandler', 'steakhouse', 'alert', 'faxing', 'slurring', 'obamas', 'unaware', 'tow', 'fit', 'remain', 'allegiance', 'reconciled', 'educational', 'goldman', 'huma', 'ribs', 'science', 'pitt', 'commonwealth', 'shifted', 'vcrs', 'sky', 'appeal', 'sylvester', 'eaters', 'athlete', 'diverse', 'meter', 'assumption', 'berated', 'pain', 'habitat', 'low', 'voted', 'dongen', 'scouts', 'inch', 'calories', 'paused', 'nighter', 'pulling', 'part', 'mustache', 'hikers', 'seabiscuit', 'audacious', 'condo', 'summit', 'tortured', 'profiling', 'devastating', 'broom', 'booed', '.p', 'clooney', 'lent', 'ingredient', 'ferrera', 'assured', 'quintuplets', 'redheads', 'centrifuge', 'escape', 'reservation', 'vhs', 'engaging', 'stopped', 'formula', 'chimichanga', 'whispering', 'doorbell', 'lbs', 'moving', 'rockefeller', 'claus', 'commentator', 'meerkats', 'craig', 'circumcised', 'aldrin', 'lasts', 'legendary', 'gift', 'eli', 'tries', 'philbin', 'bank', 'inexpensive', 'bonnet', 'dunked', 'carson', 'governments', 'delete', 'an', 'experiences', 'eight', 'mummies', 'disinvited', 'arousal', 'hamill', 'hamana', 'booze', 'barron', 'inventors', 'nascar', 'backstreet', 'il', 'schwartz', 'planes', 'loudly', 'germans', 'betsy', 'ivy', 'menopause', 'forest', 'flosses', 'millimeters', 'ipods', 'jay', 'wand', 'marching', 'pony', 'book', 'supersoakers', 'resurrecting', 'dissent', 'trove', 'number', 'bigger', 'joe', 'leading', 'announcer', 'cragel', 'barrels', 'cutler', 'corporations', 'fiasco', 'carry', 'stenographer', 'display', 'bullpens', 'prodigy', 'moments', 'reindeer', 'linebacker', 'disposal', 'emotional', 'hardcore', 'popular', 'norm', 'wayne', 'japan', 'outselling', 'adopt', 'rum', 'damp', 'potty', 'battlefield', 'sunken', 'buffett', 'aboard', 'frat', 'shooting', 'outnumbers', 'elmo', 'absolutely', 'laundromat', 'semi', 'qwikster', 'string', 'lone', 'beyond', 'sun', 'controlling', 'proposals', 'unsuccessfully', 'try', 'educated', 'pep', 'jackson', 'heal', 'bradley', 'his', 'sasha', 'megalomania', 'musket', 'huge', 'belly', 'hacker', 'ambien', 'caa', 'alternate', 'feeds', 'kentucky', 'honoring', 'vegetarian', 'denies', 'b', 'cakes', 'goodnight', 'commission', 'neil', 'reek', 'cyberattacks', 'telecast', 'militant', 'kotex', 'competing', 'riots', 'objects', 'criticize', 'demanding', 'point', 'story', 'enlist', 'polluter', 'bakersfield', 'expect', 'destroyed', 'smiling', 'grasshopper', 'posture', 'seaworld', 'thar', 'sunburned', 'julian', 'southwest', 'pigs', 'roasting', 'request', 'wordplay', 'enduring', 'chumbawumba', 'gatorade', 'quarter', 'rips', 'fault', 'leaked', 'hating', 'tara', 'worked', 'growing', 'holds', 'gorsuch', 'warehouse', 'rhyme', 'percocet', 'genders', 'catalog', 'your', 'tim', 'joining', 'unexplained', 'obsessed', 'silvio', 'sunscreens', 'ok', 'travel', 'kickers', 'who', 'obituary', 'metals', 'hansen', 'sonogram', 'tripping', 'orbetter', 'lebanon', 'achieves', 'easytone', 'ducking', 'garton', 'mayweather', 'voices', 'legoland', 'sub', 'vending', 'ham', 'paths', 'selecting', 'hairy', 'bauer', 'serving', 'theorists', 'pride', 'sauna', 'allah', 'continuum', 'stonehenge', 'preemptive', 'mayer', 'conscious', 'clintons', 'beck', 'hostility', 'kilims', 'outdoor', 'prove', 'touchdowns', 'socks', 'legitimately', 'laid', 'wars', 'border', 'considers', 'condor', 'lie', 'decides', 'ivory', 'gifted', 'crumbling', 'arquette', 'role', 'canyon', 'strategist', 'eventually', 'splitting', 'pulled', 'tupac', 'thanks', 'gavel', 'came', 'heaven', 'fat', 'bitches', 'mothers', 'confrontation', 'yom', 'deemed', 'wreck', 'electric', 'burst', 'suspenders', 'dated', 'destruction', 'encountering', 'toasted', 'shouting', 'harshing', 'stored', 'angry', 'holiness', 'loan', 'sharapova', 'ingenious', 'humming', 'diamonds', 'spice', '.a', 'turtle', 'brown', 'slips', 'smurfs', 'graduating', 'brigham', 'betts', 'drivers', 'create', 'schnitzel', 'coat', 'imports', 'talk', 'wasteland', 'canada', 'technology', 'shaking', 'focused', 'cousin', 'saladworks', 'tooth', 'privately', 'warcraft', 'former', 'tapes', 'creative', 'affordable', 'normal', 'cheeseburgers', 'efron', 'disqualified', 'vicodin', 'priorities', 'rams', 'judgement', 'legislator', 'boehner', 'tonight', 'sweating', 'forum', 'foul', 'precious', 'functioning', 'ahoy', 'tequila', 'thrill', 'cycling', 'tracy', 'opened', 'martin', 'recipe', 'milk', 'ads', 'bagging', 'celebrations', 'suffer', 'squid', 'poet', 'anarchy', 'accordance', 'observers', 'bellies', 'existential', 'spot', 'jameson', 'reruns', 'jigglypuff', 'renaming', 'coma', 'giggle', 'woo', 'many', 'hottest', 'greater', 'victory', 'georgia', 'guide', 'editing', 'theaters', 'zesty', 'respond', 'choice', 'histories', '.w', 'pooper', 'retiring', 'supergirl', 'native', 'extras', 'quit', 'equipped', 'bushy', 'furloughed', 'alibi', 'nailed', 'mormonism', 'skype', 'personalities', 'beeper', 'painfully', 'turmoil', 'yogurt', 'dench', 'preserved', 'peyton', 'spurs', 'light', 'overturned', 'violin', 'adrian', 'special', 'hazmat', 'paranoid', 'seasons', 'approximate', 'terminally', 'holders', 'tribute', 'thurman', 'biden', 'pac', 'pikachu', 'burrel', 'bans', 'unparalleled', 'prize', 'welcomes', 'tricky', 'heavier', 'verses', 'skill', 'shacks', 'kits', 'stunned', 'confuse', 'leafy', 'owens', 'disapprove', 'demands', 'mine', 'fining', 'distressed', 'tempting', 'surrendered', 'sophomore', 'downhill', 'marking', 'obamaphobia', 'evangelicals', 'peeing', 'tacos', 'predicted', 'granddaughter', 'merge', 'uss', 'eden', 'worthless', 'mile', 'ingles', 'tweeting', 'transgenderism', 'ireland', 'mediator', 'brussels', 'dwarf', 'illinois', 'management', 'browse', 'raft', 'mayor', 'hinted', 'characters', 'flip', 'contrast', 'behavior', 'sugar', 'topic', 'denounced', 'promethium', 'ankle', 'legislative', 'nutritional', 'fried', 'coal', 'interested', 'indigenous', 'van', 'sos', 'brakes', 'executed', 'wine', 'tombstone', 'stoners', 'bicycle', 'snatched', 'gazelle', 'chu', 'company', 'longen', 'ford', 'target', 'millionaire', 'quoted', 'cameroon', 'urges', 'intend', 'actual', 'swamp', 'desired', 'warnog', 'plummets', 'dizziness', 'cake', 'recourse', 'forecast', 'grateful', 'ironically', 'rushes', 'congressman', 'reimbursed', 'commiserating', 'carroll', 'publicist', 'ku', 'fractions', 'neanderthals', 'navajo', 'quaker', 'jermaine', 'common', 'neck', 'performed', 'including', 'sanitary', 'mispronounced', 'drawing', 'ethics', 'cornrows', 'carol', 'falcons', 'championship', 'plunged', 'pajamas', 'servant', 'authorities', 'marvin', 'gop', 'owe', 'molesting', 'require', 'heavy', 'chobani', 'dismal', 'plate', 'hydrant', 'themselves', 'writers', 'rosalind', 'thirty', 'insiders', 'reconnect', 'photographer', 'recruited', 'endorse', 'cave', 'johnson', 'undergoing', 'walkway', 'cnn', 'stocking', 'nudes', 'correctly', 'pittsburgh', 'involved', 'comb', 'formed', 'determining', 'pets', 'keg', 'plathaccino', 'housekeeper', 'nude', 'draw', 'cone', 'limit', 'lufthansa', 'dementia', 'inauguration', 'cheri', 'flier', 'odysseys', 'nearby', 'buddy', 'canceling', 'jury', 'escort', 'jewelers', 'rae', 'senior', 'bargain', 'obuzzkill', 'while', 'spiro', 'races', 'remembers', 'photographers', 'pleading', 'latinos', 'progress', 'isolate', 'sanctions', 'via', 'relatable', 'downey', 'gene', 'refs', 'cologne', 'upside', 'injured', 'fifties', 'scooter', 'excrete', 'bannon', 'skills', 'prosecute', 'win', 'meth', 'chan', 'liberating', 'wines', 'visits', 'things', 'foster', 'passions', 'sh', 'allowing', 'bigly', 'delay', 'everywhere', 'comeback', 'dear', 'carmageddon', 'patriotic', 'smell', 'gps', 'stall', 'concussions', 'fbi', 'vitamin', 'flagship', 'naacp', 'charisma', 'cliff', 'trigonometry', 'rapist', 'device', 'wanted', 'apparent', 'slutsapalooza', 'bolt', 'forties', 'landlord', 'astan', 'become', 'password', 'unemployed', 'investigates', 'planets', 'upright', 'smuggle', 'borrowed', 'bats', 'reducing', 'manbang', 'fabulous', 'cops', 'inheritance', 'christmas', 'curious', 'fast', 'raiding', 'act', 'filling', 'dispute', 'listen', 'homicide', 'engraved', 'screening', 'patricia', 'oh', 'donkey', 'buffs', 'dull', 'series', 'elevators', 'quicker', 'ships', 'magnitude', 'lovechild', 'omelette', 'beauchamp', 'chips', 'tina', 'forecasters', 'murphy', 'shaming', 'vibrates', 'tally', 'adult', 'revealed', 'than', 'propose', 'crowd', 'procedure', 'women', 'spokesperson', 'plenty', 'moment', 'gangs', 'responsible', 'faced', 'split', 'designated', 'classify', 'rank', 'rectal', 'coughed', 'successfully', 'only', 'hosted', 'sure', 'viewers', 'incredibly', 'games', 'completely', 'wears', 'drone', 'presidents', 'healing', 'rather', 'trace', 'browns', 'screaming', 'south', 'fluids', 'pronounce', 'crisp', 'deen', 'unqualified', 'announcing', 'belgium', 'cherokee', 'keyboard', 'newtons', 'australian', 'asian', 'repair', 'programs', 'questioned', 'applicants', 'ain', 'grown', 'bloodshot', 'sr', 'erections', 'reaches', 'dee', 'pledged', 'violent', 'ace', 'titles', 'cheater', 'vault', 'space', 'penciled', 'ride', 'smithsonian', 'agricultural', 'fact', 'reunite', 'haha', 'mates', 'tau', 'confirmed', 'amber', 'lohan', 'compromised', 'deaths', 'signoff', 'creatures', 'smelling', 'glenn', 'sherlock', 'springs', 'authors', 'todos', 'tehran', 'drafted', 'worrying', 'marriott', 'usher', 'acquired', 'might', 'flew', 'sooner', 'drink', 'moderately', 'skyping', 'winked', 'soy', 'overcompensate', 'boom', 'practical', 'cool', 'k', 'puts', 'escaping', 'painkillers', 'dnc', 'baldness', 'claim', 'coldplay', 'urination', 'bleeps', 'launches', 'chubby', 'adultery', 'awakens', 'wiretapped', 'patraeus', 'oscars', 'blue', 'cvs', 'wheelchair', 'institutes', 'url', 'ipads', 'interfered', 'attaches', 'founder', 'lewinsky', 'depart', 'pasta', 'chewables', 'honor', 'pfizer', 'internet', 'festivities', 'starts', 'tassels', 'female', 'hugepenis', 'depend', 'converted', 'damage', 'industrialized', 'coaches', 'consistent', 'monitor', 'snowquester', 'solves', 'interviewed', 'skin', 'hadn', 'chopped', 'afternoons', 'fools', 'boxes', 'boxer', 'florida', 'slang', 'metropolitan', 'bath', 'consulting', 'weapon', 'shortlist', 'suit', 'held', 'bed', 'cry', 'blackjack', 'deeper', 'phat', 'slowly', 'profiles', 'fillers', 'dildos', 'youtube', 'aim', 'laptop', 'bargaining', 'geez', 'justified', 'comedians', 'assume', 'library', 'polly', 'outhouse', 'npr', 'bitcoin', 'poland', 'honeys', 'unnecessarily', 'carbon', 'decide', 'addict', 'attention', 'separate', 'wiggles', 'wore', 'genetics', 'cannon', 'portray', 'guard', 'omarosa', 'univision', 'connect', 'autocorrected', 'abuses', 'macarthur', 'reversed', 'exploited', 'schools', 'nachos', 'murderton', 'mistakes', 'mistakenly', 'yu', 'cheaper', 'list', 'futons', 'patriots', 'shut', 'remembered', 'tendon', 'neurotic', 'iii', 'mingle', 'unflattering', 'hints', 'blasting', 'san', 'erection', 'lauer', 'finals', 'flops', 'jiggling', 'either', 'billion', 'metal', 'funnel', 'beats', 'pints', 'envy', 'toss', 'undergone', 'competitiveness', 's', 'thinking', 'plea', 'bunker', 'sodomy', 'past', 'swaddled', 'chevy', 'gathered', 'though', 'crystal', 'indictment', 'proudest', 'bulb', 'edged', 'malnutrition', 'mormon', 'quinoa', 'implied', 'smuggling', 'teaching', 'thriddy', 'pranks', 'merging', 'handing', 'la', 'grapes', 'tent', 'backstabbing', 'dick', 'guaranteeing', 'kutcher', 'products', 'pinpointed', 'trying', 'infested', 'itunes', 'pippa', 'hummus', 'hasbro', 'medium', 'bodyguards', 'complaint', 'stealth', 'combover', 'comedian', 'dudes', 'declaration', 'jerusalem', 'surprised', 'room', 'belieb', 'lettuce', 'touchdown', 'cross', 'origin', 'hush', 'consisted', 'ma', 'fashioned', 'luring', 'bourne', 'jeb', 'mall', 'jets', 'michele', 'can', 'swimsuit', 'asthma', 'acted', 'tuscany', 'biological', 'cowell', 'beat', 'eats', 'flint', 'dada', 'wan', 'hunnam', 'gear', 'automatic', 'kelly', 'schlepp', 'sniffing', 'clump', 'kardashians', 'murder', 'net', 'overshadowed', 'snack', 'doll', 'whitson', 'transit', 'failures', 'cincinnati', 'option', 'graduates', 'puzzler', 'assets', 'lover', 'pedicab', 'committing', 'shagging', 'duty', 'depending', 'coveted', 'drove', 'iggy', 'imagine', 'capable', 'alpine', 'newscorp', 'stockholders', 'plagiarizing', 'porno', 'marley', 'taboos', 'hear', 'holiday', 'tomato', 'thin', 'write', 'magical', 'closing', 'iraq', 'gryffindor', 'greedy', 'fifty', 'support', 'frozen', 'manti', 'invented', 'clear', 'rifles', 'blatter', 'til', 'classy', 'mistake', 'reno', 'widescreen', 'sanford', 'storyline', 'review', 'heavily', 'corolla', 'hire', 'asshooooooooal', 'montage', 'hepatitis', 'attack', 'wobbles', 'housing', 'warn', 'tarts', 'christianity', 'maple', 'relatively', 'tadpoles', 'acute', 'doomsday', 'rain', 'eclairs', 'beagle', 'hedges', 'spears', 'exceeds', 'cinco', 'satisfied', 'winnie', 'unrealistic', 'girlfriend', 'having', 'stood', 'optimists', 'wu', 'evened', 'also', 'repeated', 'targeting', 'cop', 'traitor', 'suite', 'goldfinger', 'casting', 'hos', 'scanner', 'mudslides', 'replicates', 'mermaids', 'shoving', 'terrifying', 'safely', 'moms', 'committed', 'ufo', 'giveaway', 'restrictions', 'ion', 'cashed', 'massachusetts', 'casino', 'retracted', 'sharpest', 'runs', 'sassoon', 'portraits', 'coretta', 'debacle', 'fiber', 'heads', 'closed', 'versions', 'motorcycle', 'pack', 'palm', 'hid', 'explode', 'tomorrow', 'opotamus', 'relieved', 'pacquiao', 'promoter', 'expand', 'suggest', 'earthquakes', 'willing', 'fossils', 'design', 'binges', 'turf', 'ranks', 'semen', 'trashed', 'continuing', 'escalator', 'lashed', 'using', 'groceries', 'centerfold', 'reminding', 'thinner', 'khalifa', 'smog', 'nazis', 'madonna', 'seawater', 'confronted', 'gentlemen', 'kwame', 'yours', 'millon', 'on', 'horsepower', 'force', 'hopping', 'portrait', 'implementing', 'widow', 'hotly', 'highway', 'damn', 'baseless', 'skywalker', 'uncontrollably', 'saps', 'panthers', 'saturn', 'heineken', 'christian', 'infomercials', 'ended', 'cleanliness', 'enhancing', 'used', 'katie', 'totally', 'dvd', 'yams', 'erratically', 'loved', 'dreidels', 'plane', 'older', 'existing', 'taking', 'abortion', 'tagline', 'hanukkah', 'squirtles', 'offender', 'frowny', 'simulcast', 'wap', 'redemption', 'embattled', 'thousand', 'bugs', 'showered', 'ronda', 'patient', 'canseco', 'conebone', 'caption', 'zaqistan', 'cialis', 'vatican', 'restaurants', 'freezing', 'figurehead', 'created', 'county', 'royalties', 'rented', 'sip', 'accuracy', 'murdering', 'skankmore', 'largest', 'message', 'assumed', 'condemned', 'coworkers', 'scariest', 'guiding', 'ambulance', 'clueless', 'winning', 'martha', 'vowels', 'buddha', 'garrison', 'macarena', 'declares', 'doz', 'activate', 'plot', 'cul', 'dine', 'barbara', 'kkk', 'little', 'consolable', 'eagerly', 'stuff', 'return', 'gronkowski', 'attracting', 'stabbing', 'disorderly', 'quiet', 'weisberg', 'server', 'blonde', 'denying', 'discusses', 'cairo', 'deployed', 'happens', 'candwich', 'informal', 'is', 'convinced', 'affected', 'switching', 'hygiene', 'lighting', 'hex', 'interstate', 'area', 'normandy', 'wallenda', 'normally', 'dickinson', 'muy', 'kravitz', 'paradise', 'conduct', 'funyons', 'robert', 'terrible', 'sweeping', 'woodhull', 'snl', 'generous', 'rubio', 'botox', 'jasmine', 'affirmed', 'ravens', 'to', 'vandals', 'sixteenth', 'recommended', 'justices', 'pale', 'remotely', 'rep', 'incapacitated', 'intoxication', 'conned', 'spend', 'lauren', 'classic', 'instantly', 'otherwise', '.e', 'ny', 'beforehand', 'novel', 'clingers', 'beautifulpeople', 'honored', 'divorcing', 'promotion', 'chasing', 'weight', 'cookies', 'releasing', 'beating', 'lumped', 'attacked', 'smarter', 'kinki', 'sheets', 'dmv', 'accusations', 'bass', 'dilate', 'candle', 'wiped', 'licenses', 'rooms', 'panther', 'threatening', 'babysitter', 'debates', 'greatly', 'bra', 'blown', 'bracelet', 'sends', 'cautiously', 'ambitions', 'garage', 'stirring', 'smart', 'mas', 'hertz', 'saddam', 'declared', 'quality', 'earl', 'ear', 'appears', 'cheat', 'passenger', 'contains', 'synthetic', 'frontal', 'steward', 'competitor', 'excellent', 'gge', 'opinion', 'tigers', 'venison', 'showtime', 'sundays', 'distress', 'comprehensive', 'rescue', 'wither', 'charge', 'restore', 'exploring', 'queens', 'mohammed', 'reader', 'employing', 'quarantine', 'evidence', 'mail', 'pastor', 'squats', 'winterfell', 'aide', 'bicurious', 'cafeteria', 'importance', 'biotechnology', 'desserts', 'uttered', 'per', 'imacreep', 'boo', 'belong', 'qualities', 'doctor', 'studios', 'mary', 'registry', 'arts', 'consumerism', 'distant', 'wingman', 'muslim', 'spoiler', 'oversee', 'gee', 'printer', 'gazongaterias', 'swimming', 'atmosphere', 'goblin', 'bassist', 'unprecedented', 'tailor', 'roses', 'fender', 'aged', 'blow', 'europeans', 'click', 'ward', 'racial', 'protein', 'reinvent', 'toad', 'fearsome', 'chipotle', 'nugent', 'yo', 'probe', 'fills', 'meet', 'bookies', 'rigid', 'concept', 'cruel', 'fats', 'narrowly', 'zurich', 'momentary', 'razor', 'punxutawney', 'richard', 'andrew', 'administration', 'axe', 'mistaking', 'advertising', 'rerun', 'bloods', 'mob', 'symbol', 'pulls', 'landing', 'spill', 'ebert', 'brag', 'payment', 'embroiled', 'guaranteed', 'greenlighting', 'harlem', 'ponchos', 'mulled', 'overeating', 'lands', 'ice', 'manufacturing', 'estimates', 'lotion', 'kellyanne', 'marissa', 'erotikaland', 'primary', 'fans', 'minutes', 'awful', 'sprint', 'towed', 'abbreviated', 'ronald', 'melanomapalooza', 'capabilities', 'mountains', 'sequel', 'hide', 'fiscal', 'azalea', 'ac', 'lowest', 'pbs', 'degenerates', 'orca', 'expectancy', 'campaign', 'discretion', 'asleep', 'musicians', 'salt', 'injury', 'stoning', 'poison', 'whale', 'crane', 'suspended', 'register', 'layers', 'nationwide', 'emotion', 'hospital', 'oxygen', 'homocon', 'scaring', 'advocated', 'styles', 'wastebasket', 'romanian', 'giant', 'metrodome', 'wholesome', 'chipwrecked', 'latino', 'manhattan', 'inventing', 'gaywad', 'betty', 'hardcover', 'carpenter', 'puzzled', 'abused', 'dreary', 'class', 'kept', 'advisory', 'dwayne', 'screwed', 'forgetting', 'pacers', 'gerald', 'widened', 'vulcan', 'hydra', 'kettlebells', 'magnet', 'intent', 'hellos', 'fred', 'tents', 'dollars', 'widespread', 'cries', 'obese', 'excessive', 'pocket', 'newly', 'wired', 'achievement', 'squirt', 'arnold', 'fecal', 'chilling', 'nov', 'website', 'youcallthatadick', 'reassured', 'cells', 'beings', 'bean', 'horrifying', 'crocodile', 'catcon', 'wyclef', 'prayer', 'accident', 'constantly', 'provider', 'screwing', 'tennis', 'leaning', 'leaned', 'faraway', 'feeding', 'sharks', 'surrounded', 'waterparks', 'crotch', 'associated', 'driverless', 'platinum', 'protection', 'bottled', 'pessimistic', 'gaming', 'equipment', 'examined', 'secede', 'blaming', 'rollerblades', 'sodas', 'extremism', 'grew', 'crusade', 'visitor', 'mugger', 'psycho', 'awesome', 'circle', 'extortion', 'character', 'venue', 'cost', '.and', 'brownstone', 'aa', 'reba', 'wheels', 'specific', 'essential', 'seder', 'specializes', 'engagement', 'dysfunction', 'liked', 'kellen', 'hefty', 'ob', 'squabbling', 'giants', 'rudy', '!', 'recollection', 'bow', 'overeat', 'sets', 'portman', 'unicorn', 'mouth', 'steve', 'suggestive', 'hinkle', 'supposedly', 'pretend', 'playing', 'elon', 'brand', 'enemies', 'responses', 'critters', 'sync', 'gambia', 'damaging', 'wink', 'acronymies', 'outspoken', 'curb', 'revenue', 'due', 'pencil', 'rotting', 'catchphrase', 'triathlon', 'wearable', 'travolta', 'bleeped', 'upsets', 'mails', 'turkey', 'pornsylvania', 'sir', 'marilyn', 'fell', 'janitor', 'incision', 'romeo', 'pointless', 'excedrin', 'transplant', 'opioid', 'arrive', 'went', 'cases', 'births', 'follows', 'mangy', 'minesweeper', 'album', 'rigged', 'bode', 'mamma', 'assassinate', 'braves', 'tickets', 'tic', 'initially', 'crusty', 'marshal', 'drunkenboinkin', 'duplicates', 'develop', 'leakage', 'm', 'vaginal', 'attic', 'bayou', 'instagrams', 'johns', 'jokes', 'reduction', 'legally', 'waters', 'void', 'restricts', 'baldy', 'runners', 'robbers', 'appeals', 'willy', 'rajiv', 'amex', 'sundance', 'crucifixion', 'uterus', 'oral', 'biographer', 'volleyball', 'nordstrom', 'geographic', 'misrepresented', 'where', 'filters', 'bikini', 'sermons', 'norris', 'anxiously', 'concluded', 'visited', 'creepy', 'grandkids', 'marine', 'jetski', 'effective', 'supercomputer', 'sopranos', 'vma', 'spreading', 'build', 'excused', 'troupes', 'hampshire', 'best', 'ruler', 'asians', 'reporter', 'cw', 'race', 'petitioned', 'giza', 'mountaindew', 'accounts', 'powerball', 'virile', 'denied', 'immature', 'vibrate', 'species', 'topics', 'citing', 'alcoholic', 'full', 'unions', 'dozen', 'spa', 'booths', 'mood', 'brett', 'stark', 'laws', 'richter', 'betting', 'biggie', 'caught', 'subway', 'tile', 'ersary', 'charitable', 'increased', 'tampa', 'pledging', 'uninvited', 'child', 'cornered', 'wrongfully', 'prostate', 'stedman', 'traveling', 'production', 'anesthesiologist', 'bumper', 'variety', 'tightrope', 'fetty', 'fire', 'ikea', 'hofstra', 'consider', 'accord', 'teats', 'stalker', 'assistant', 'use', 'collected', 'legalized', 'matthew', 'root', 'dust', 'stole', 'disclose', 'communicate', 'reprimanded', 'qaeda', 'zynga', 'bonding', 'trout', 'every', 'uma', 'highness', 'slammed', 'shape', 'clambucket', 'benefits', 'amusing', 'mcribbed', 'syphilis', 'dying', 'talks', 'tac', 'wristband', 'medical', 'inventor', 'dung', 'contender', 'calculator', 'scab', 'four', 'manager', 'sneak', 'begin', 'deli', 'babysit', 'microphones', 'panini', 'prayed', 'breaky', 'arriving', 'despise', 'system', 'gladwell', 'shuffle', 'accurately', 'wartime', 'closer', 'haunt', 'padded', 'fruit', 'sock', 'laurent', 'host', 'loss', 'greener', 'deforestation', 'sophistication', 'accessories', 'death', 'australia', 'cancelled', 'jaguars', 'home', 'card', 'klingons', 'nominations', 'swan', 'wondering', 'clothed', 'bernardino', 'etsy', 'retail', 'sink', 'conversational', 'slams', 'plumber', 'collapse', 'linkedin', 'foreskin', 'pros', 'brick', 'goonies', 'back', 'gosling', 'neighborhoods', 'crossing', 'sad', 'dreamed', 'tens', 'dealings', 'dialogue', 'rotation', 'doubled', 'davis', 'supergroup', 'robbing', 'hoax', 'expressed', 'body', 'hi', 'labeling', 'nonexistent', 'mythbusters', 'underweight', 'multinational', 'elves', 'letter', 'instead', 'impromptu', 'joints', 'economists', 'promised', 'worried', 'pussies', 'kosher', 'borders', 'pinkett', 'perry', 'banging', 'xvi', 'brady', 'liars', 'handouts', 'colorado', 'zune', 'officials', 'deck', 'alienating', 'superman', 'dressing', 'wrestlers', 'bottle', 'escorted', 'secretaries', 'twerk', 'mexico', 'latin', 'downgraded', 'discovery', 'podcast', 'bartender', 'trading', 'grounded', 'waterproof', 'assemble', 'reaper', 'terrific', 'wwii', 'dramatic', 'worth', 'pink', 'headline', 'johansson', 'impose', 'diners', 'theoretically', 'european', 'mainly', 'sand', 'hamburgers', 'peoples', 'belgian', 'blaring', 'artest', 'calling', 'labels', 'desire', 'infallible', 'experience', 'included', 'appearing', 'stanley', 'crappy', 'transportation', 'half', 'democrats', 'pipeline', 'talkin', 'reilly', 'dicks', 'sepia', 'wristwatch', 'plotted', 'erased', 'hebrew', 'survivalist', 'nightclubbing', 'tore', 'liberal', 'attendance', 'portland', 'lester', 'sniff', 'analyzing', 'couple', 'viability', 'scottie', 'ca', 'killed', 'culprits', 'tunes', 'pregnancies', 'singles', 'catfight', 'helen', 'jumper', 'crispy', 'verbally', 'santaclaustrophobia', 'mexican', 'bonin', 'shoplifting', 'labradoodles', 'disneyworld', 'profits', 'right', 'welcomed', 'stays', 'erase', 'unearthed', 'champion', 'fiddler', 'loans', 'ocular', 'gonzales', 'iowa', 'dmz', 'funkytown', 'release', 'simply', 'hijack', 'voldemort', 'vasectomy', 'mittler', 'considered', 'commissioned', 'their', 'illusion', 'beads', 'lube', 'documents', 'malley', 'begun', 'revelation', 'reservations', 'man', 'overprice', 'rivers', 'delivery', 'obsession', 'snakes', 'spokane', 'trainwreck', 'mampon', 'overthrow', 'shitty', 'hearing', 'enables', 'beergoggles', 'disrespects', 'feast', 'crocs', 'upgraded', 'attaching', 'underwent', 'hallucinates', 'muscular', 'dynasty', 'baron', 'hilarious', 'watches', 'colossal', 'author', 'handpicked', 'guidelines', 'bones', 'rubber', 'somali', 'tattoo', 'facing', 'democratic', 'grave', 'refuge', 'hulu', 'waterloo', 'accessible', 'form', 'hyping', 'judy', 'locations', 'laker', 'ashes', 'ineffective', 'luxury', 'stupidity', 'mwa', 'abolish', 'bcs', 'pushups', 'tostitos', 'noodle', 'striking', 'filled', 'chillaxing', 'better', 'clerks', 'license', 'pools', 'swept', 'urban', 'altaba', 'takes', 'chief', 'corn', 'smirking', 'jamaicans', 'indoors', 'presidential', 'sentence', 'hotter', 'roethlisberger', 'fu', 'offend', 'movie', 'pottering', 'melissa', 'theeeeeeey', 'iphones', 'overkill', 'admired', 'prices', 'aggressively', 'enlargements', 'told', 'cameras', 'lewis', 'dank', 'old', 'olds', 'organizer', 'dipping', 'similarity', 'whipped', 'hoagie', 'blindspot', 'academy', 'norms', 'petco', 'profile', 'palestinians', 'pipe', 'weekends', 'taco', 'perception', 'incident', 'informant', 'interesting', 'stoop', 'tracks', 'speeches', 'inconsolable', 'cheeseburger', 'farms', 'pirated', 'smiled', 'insider', 'large', 'wellesley', 'approving', 'finishing', 'persons', 'creeping', 'cripple', 'syrian', 'radio', 'clitoris', 'raised', 'messed', 'undercover', 'tastier', 'dwarfs', 'hoping', 'ryan', 'mcnuggets', 'dinosaurs', 'bottling', 'alimony', 'lottery', 'blankets', 'digital', 'hearted', 'shatter', 'suleman', 'lifestyle', 'tweak', 'seat', 'bankruptcy', 'paralyzed', 'crowned', 'professional', 'roberts', 'adonis', 'meghan', 'asteroid', 'apartment', 'satisfy', 'chick', 'overnight', 'tower', 'tape', 'reworking', 'sees', 'casa', 'nader', 'tgi', 'wide', 'testifying', 'linked', 'likened', 'competition', 'unpolished', 'sadistic', 'radcliffe', 'selma', 'lick', 'vacationing', 'leap', 'fabric', 'descent', 'oncoming', 'farts', 'rubbing', 'returned', 'triglyceride', 'graham', 'ling', 'style', 'clocks', 'athletes', 'tends', 'ticker', 'x', 'teeth', 'bluetooth', 'toro', 'spy', 'ruling', 'friggin', 'pronounced', 'urinal', 'broads', 'nominating', 'perp', 'archive', 'different', 'pricewaterhousecoopers', 'kirk', 'mom', 'swimmers', 'salsa', 'lasted', 'neighborhood', 'smokey', 'distracted', 'cooties', 'hombre', 'blows', 'eronomy', 'awesomeness', 'strict', 'pill', 'hairpieces', 'naan', 'legged', 'unsanitary', 'boardwalk', 'edition', 'conducted', 'dislike', 'willie', 'took', 'winter', 'madness', 'poem', 'chimps', 'poo', 'drill', 'fifa', 'weightlessness', 'awkward', 'fatberg', 'rot', 'insisting', 'efforts', 'dealers', 'romo', 'jack', 'client', 'mayhem', 'twerking', 'deal', 'hotchinesebackdooraction', 'bragged', 'ordained', 'sponsor', 'debuting', 'pressure', 'commandments', 'she', 'bobblehead', 'kidney', 'skipping', 'ukraine', 'womb', 'perot', 'operating', 'imax', 'vacation', 'determine', 'sentences', 'clerk', 'baton', 'daycare', 'accent', 'ganja', 'stuck', 'pre', 'statement', 'jamaica', 'reach', 'purposes', 'eve', 'famously', 'beer', 'mis', 'zeros', 'llama', 'emissions', 'blowing', 'tail', 'yearly', 'coats', 'move', 'meets', 'gates', 'backed', 'crib', 'cork', 'tbs', 'safest', 'overwhelmingly', 'evict', 'gringo', 'veterinarians', 'ray', 'pyramid', 'receipt', 'year', 'med', 'reality', 'annoying', 'boat', 'dreams', 'structure', 'fakes', 'unethical', 'emoticon', 'vacationland', 'ferb', 'earn', 'wingin', 'kiev', 'seen', 'jk', 'invasive', 'youse', 'sharknado', 'toys', 'ejaculation', 'breakup', 'didn', 'motorboat', 'average', 'objectified', 'twi', 'economics', 'professor', 'actress', 'isaac', 'bounce', 'short', 'owners', 'trebek', 'abercrombie', 'recover', 'lumia', 'complains', 'coverage', 'oblivion', 'mailing', 'watching', 'landlines', 'does', 'amendments', 'sober', 'yorker', 'kansas', 'spilled', 'heritage', 'minecraft', 'colleges', 'depression', 'articles', 'anchors', 'roosevelt', 'homophobia', 'pippen', 'jada', 'juno', 'drai', 'driving', 'stretches', 'helps', 'memoir', 'prisons', 'disagrees', 'steven', 'african', 'broadway', 'coordinate', 'participants', 'obamacare', 'lethal', 'may', 'incredible', 'landed', 'beans', 'announcement', 'los', 'meddling', 'whoa', 'environmentalists', 'radiation', 'invasion', 'debating', 'creep', 'reasoned', 'lecture', 'outlets', 'duis', 'alive', 'spaghettios', 'chex', 'triplets', 'bites', 'finished', 'dausage', 'seniors', 'curvy', 'eliminated', 'pussy', 'bus', 'rolls', 'agreed', 'zone', 'rule', 'cancer', 'shampoos', 'papa', 'trail', 'adequate', 'medal', 'berating', 'partnered', 'cliche', 'ozone', 'denny', 'advanced', 'strongly', 'kryptonite', 'it', 'treaters', 'infects', 'dd', 'suffering', 'stained', 'human', 'pompeo', 'finale', 'juggling', 'tolerate', 'bizarre', 'passion', 'statue', 'colon', 'byu', 'sleepovers', 'swallowed', 'wax', 'murderer', 'selling', 'fairness', 'ambitious', 'lap', 'madison', 'animatronic', 'beaumont', 'official', 'slashed', 'reince', 'stone', 'predict', 'gastric', 'popularity', 'campbells', 'kindle', 'lesser', 'remarried', 'aired', 'bucket', 'bartz', 'explosion', 'priests', 'luke', 'playoffs', 'uncomfortably', 'wi', 'struggle', 'influence', 'press', 'dumpster', 'witness', 'nypd', 'sheep', 'chase', 'argued', 'bee', 'appointment', 'drunkest', 'tv', 'jell', 'touchy', 'surgeon', 'bathtub', 'experienced', 'extend', 'snowmobile', 'laugh', 'forfeit', 'maniacs', 'cream', 'bobby', 'nomination', 'everything', 'cheesecake', 'malala', 'project', 'pounds', 'daytime', 'brawl', 'sodium', 'ulysses', 'bonnaroo', 'equally', 'monica', 'currency', 'overcharged', 'puppies', 'stay', 'trouble', 'unchained', '.healthcare', 'innocent', 'aol', 'electronics', 'siri', 'tuesday', 'warning', 'deliberation', 'higher', 'seventh', 'okcupid', 'spoilers', 'hackers', 'buble', 'emailed', 'poop', 'updated', 'defrauding', 'hovering', 'commute', 'rikers', 'amendment', 'competes', 'interactive', 'upstate', 'success', 'blatant', 'supposed', 'busch', 'bottles', 'pulse', 'muttering', 'undamaged', 'abuse', 'increase', 'rode', 'azkaban', 'orleans', 'combo', 'blindfolded', 'hats', 'dough', 'maine', 'lubricant', 'parkinson', 'distanced', 'pageant', 'lookin', 'definition', 'segment', 'fox', 'tying', 'missed', 'pouch', 'massage', 'permitted', 'episodes', 'suppress', 'represented', 'breathable', 'tvs', 'surgeons', 'gratitude', 'odom', 'bondage', 'unhappy', 'experimenting', 'activists', 'landings', 'really', 'oats', 'zayn', 'toddlers', 'violinist', 'cargill', 'noses', 'carpeting', 'broadcast', 'by', 'digging', 'fidel', 'attraction', 'lightsaber', 'abdullah', 'katniss', 'dreamt', 'turlington', 'driver', 'translated', 'stating', 'of', 'cameron', 'nd', 'staunch', 'mattress', 'bets', 'key', 'scalped', 'championships', 'post', 'decisions', 'singapore', 'arkansas', 'dealing', 'presses', 'celtics', 'row', 'good', 'forever', 'politician', 'gang', 'consumed', 'kroft', 'tops', 'conceived', 'biblical', 'obviously', 'recapping', 'reese', 'egyptian', 'inheriting', 'tito', 'potentially', 'zip', 'capitol', 'g', 'proves', 'gives', 'transparency', 'contrary', 'pilots', 'guillermo', 'unexpected', 'dance', 'shipment', 'promises', 'geese', 'discuss', 'venezuela', 'sanctuary', 'harming', 'voyage', 'demonstration', 'satellite', 'delivered', 'marty', 'restructure', 'presenter', 'footage', 'gunpoint', 'wasps', 'applauded', 'rapping', 'indian', 'playmate', 'ohshitatruck', 'dory', 'waited', 'ouchies', 'bombed', 'busted', 'brawling', 'poll', 'reaffirmed', 'unhook', 'patriot', 'cannibalism', 'infidel', 'will', 'applebees', 'hazard', 'bonus', 'seizing', 'trial', 'neo', 'faa', 'dive', 'attempted', 'switzerland', 'sleepy', 'bingo', 'melanie', 'digitally', 'lifetime', 'mayonnaise', 'keith', 'lateral', 'weinsteins', 'extinguished', 'orlando', 'musical', 'incomprehensible', 'rally', 'inhabitable', 'senor', 'respecting', 'eligible', 'impotence', 'contract', 'ovation', 'furiously', 'gibsons', 'fundraiser', 'grape', 'brainchild', 'globe', 'fossil', 'scarlett', 'pooh', 'handmaid', 'teacher', 'lucas', 'rest', 'famed', 'military', 'invading', 'tongue', 'hong', 'swore', 'seclusion', 'recommendation', 'pennsylvania', 'uganda', 'novels', 'hormone', 'brands', 'diagnosed', 'did', 'punches', 'father', 'recession', 'grain', 'contestant', 'humanity', 'kfg', 'advocates', 'favorable', 'bloggers', 'testified', 'editorial', 'diddy', 'fraudulent', 'chlamydia', 'damning', 'august', 'lindsey', 'installer', 'physics', 'diaper', 'u', 'newsroom', 'focuses', 'circuits', 'sale', 'browser', 'demonstrated', 'lmao', 'accused', 'vortex', 'sauce', 'charming', 'problems', 'supply', 'jelly', 'productive', 'grantham', 'unlimited', 'lb', 'dvds', 'terrorist', 'patting', 'surveillance', 'vegans', 'bipartisan', 'mchear', 'punched', 'flavor', 'jwoww', 'matt', 'reached', 'val', 'reversals', 'elton', 'presented', 'extremist', 'allowed', 'japanese', 'innovation', 'investing', 'cola', 'holdouts', 'maid', 'lawyer', 'inmates', 'approve', 'haitians', 'safe', 'ethnicity', 'batali', 'pooped', 'hasn', 'hunter', 'partners', 'takeout', 'steps', 'brody', 'discontinue', 'usual', 'piles', 'adults', 'chiller', 'exist', 'reckless', 'mystery', 'jean', 'bail', 'thigh', 'admission', 'maker', 'imposed', 'needs', 'catches', 'significantly', 'considering', 'boulevard', 'yankee', 'upscale', 'potatoes', 'bonded', 'hundreds', 'inspiring', 'anybody', 'civilians', 'sluts', 'maul', 'catalogue', 'relay', 'became', 'faces', 'shall', 'december', 'idol', 'drunkenness', 'waste', 'value', 'bedrock', 'center', 'downstairs', 'carrying', 'donut', 'closes', 'reportedly', 'claiming', 'masculine', 'shameful', 'denouncing', 'fined', 'peas', 'dumbest', 'installing', 'frightening', 'west', 'sake', 'possessions', 'maron', 'responding', 'egg', 'merry', 'bummed', 'hypocrisy', 'ali', 'truly', 'questions', 'picking', 'commenting', 'color', 'solving', 'pringles', 'sell', 'rahm', 'bold', 'mundo', 'psas', 'skeleton', 'combined', 'seven', 'centuries', 'baddest', 'spanked', 'exhaustion', 'scientology', 'alec', 'freshly', 'values', 'blizzard', 'teddy', 'upper', 'celebrates', '.xxx', 'bred', 'thanksgiving', 'tired', 'fulfilled', 'provocative', 'minions', 'grower', 'lawrence', 'travels', 'subtitled', 'chases', 'crop', 'legroom', 'rename', 'newton', 'presence', 'vegetables', 'hall', 'surgical', 'spilling', 'disasters', 'ii', 'winner', 'windfall', 'smokes', 'assassination', 'fragrance', 'satanic', 'mandela', 'ourselves', 'comptroller', 'whoops', 'turncoat', 'umped', 'companies', 'foreword', 'victoria', 'maintenance', 'cooper', 'resulting', 'repeatedly', 'audiences', 'notable', 'adopted', 'storm', 'historically', 'lightning', 'fruitcake', 'sentimental', 'coughing', 'plagiarism', 'reclaimed', 'ol', 'coming', 'james', 'sacrament', 'ranchers', 'myth', 'outed', 'sources', 'speculation', 'heroes', 'reappeared', 'poster', 'grabbed', 'converts', 'whites', 'opener', 'donna', 'climbed', 'klan', 'saggy', 'huffington', 'haunted', 'britney', 'green', 'identify', 'kidnapper', 'mcconaughey', 'oldsmobile', 'need', 'horseman', 'technologies', 'weeping', 'laborers', 'audio', 'hershey', 'spalding', 'lightyear', 'returning', 'waits', 'negatively', 'ideological', 'mildly', 'rail', 'misunderstoodinated', 'stupor', 'ten', 'sacagawea', 'predicting', 'researcher', 'pence', 'cheek', 'elk', 'headquarters', 'investment', 'darfur', 'there', 'teleprompters', 'colin', 'mat', 'dollar', 'slip', 'demise', 'disassociate', 'cinnamon', 'reggae', 'blower', 'courts', 'comet', 'removing', 'ronnie', 'honors', 'leak', 'salad', 'clay', 'vaccines', 'peasants', 'poker', 'obi', 'unable', 'son', 'googles', 'engine', 'damper', 'han', 'brothel', 'leadership', 'suddenly', 'infinity', 'mulling', 'substantial', 'ripping', 'flights', 'joins', 'india', 'renovations', 'cinnabon', 'fedora', 'ditka', 'cameraman', 'gabbana', 'familiar', 'verbal', 'ts', 'screensaver', 'spacex', 'royals', 'conrad', 'benghazi', 'rental', 'employed', 'bracket', 'nathan', 'that', 'hasselbeck', 'smackdown', 'mcwhopper', 'recruit', 'glass', 'fictional', 'shelves', 'snoop', 'marquee', 'beheaded', 'safer', 'hotels', 'sides', 'bundchen', 'relatives', 'intact', 'motivated', 'beethoven', 'survivors', 'revolves', 'predicts', 'for', 'albright', 'eloquent', 'rsvps', 'gorgeous', 'fence', 'entertainment', 'emmy', 'deception', 'wishes', 'shutting', 'zealand', 'encrusted', 'oxide', 'drops', 'excommunicated', 'thinks', 'honorary', 'lost', 'owed', 'boots', 'kinfolk', 'grammar', 'smaller', 'immoral', 'titanic', 'cubans', 'tuned', 'counting', 'ty', 'likes', 'designing', 'clears', 'joking', 'nole', 'tall', 'mathematical', 'tribal', 'myself', 'chants', 'houston', 'abandoning', 'rooting', 'cannoli', 'poultry', 'frosting', 'answered', 'talented', 'certificate', 'hairstyle', 'apprehended', 'increments', 'rhetoric', 'bounty', 'sensations', 'misogynist', 'question', 'viagra', 'arrival', 'kidnapped', 'mapping', 'grail', 'always', 'homosexuals', 'nazi', 'daily', 'supercommittee', 'syndrome', 'whatsoever', 'meandering', 'rigorous', 'twin', 'showdown', 'rev', 'expects', 'pregnant', 'solar', 'bruise', 'skyscrapers', 'foam', 'artifact', 'musketeers', 'occupy', 'branch', 'disruption', 'purell', 'shirtlessconan', 'tied', 'strap', 'drizzle', 'stein', 'chime', 'fiennes', 'thursdays', 'throw', 'lining', 'shepherd', 'sweden', 'napkins', 'schweddy', 'orcas', 'attached', 'game', 'cred', 'paroled', 'ritual', 'swelling', 'jimmy', 'gap', 'performers', 'richards', 'moustache', 'blockage', 'treated', 'mailbox', 'sa', 'ale', 'ted', 'medals', 'spells', 'admissions', 'rules', 'felony', 'iranian', 'hop', 'pork', 'footballs', 'publicly', 'kings', 'kittens', 'smile', 'provocatively', 'limb', 'sandwiches', 'manually', 'knee', 'chernobyl', 'improve', 'violate', 'menswear', 'boys', 'santas', 'bailed', 'effects', 'paris', 'together', 'trumps', 'bragging', 'gif', 'diagnoses', 'instances', 'flipped', 'ineffectual', 'tropicana', 'fitting', 'shareholder', 'given', 'reggie', 'bozeman', 'police', 'chauffeur', 'costume', 'saying', 'say', 'organic', 'dermatologists', 'masturbation', 'honest', 'remarkable', 'manson', 'mathematicians', 'acting', 'dougie', 'filtered', 'becomes', 'autopsy', 'downloaded', 'pounded', 'ballistic', 'brian', 'coke', 'commonly', 'cinqo', 'noises', 'evils', 'disputes', 'snowman', 'battle', 'mid', 'harris', 'homicides', 'northern', 'muncher', 'lawsuit', 'branches', 'cherry', 'jumping', 'pins', 'saves', 'mills', 'allegory', 'window', 'smelly', 'accents', 'free', 'gym', 'address', 'screeners', 'brosurance', 'marble', 'mansion', 'recreational', 'jam', 'suggesting', 'clip', 'territorial', 'permanent', 'pamela', 'confederate', 'don', 'bills', 'minorities', 'jenga', 'satan', 'plummer', 'reduces', 'patterson', 'classics', 'own', 'grandma', 'scarf', 'myanus', 'machine', 'pathological', 'cancelling', 'arby', 'mobile', 'bum', 'theodore', 'historian', 'strangers', 'mcbite', 'golfers', 'unpaid', 'weekly', 'hanging', 'busy', 'unanimously', 'monroe', 'after', 'stds', 'ingredients', 'fetus', 'toronto', 'deserving', 'bi', 'insulin', 'sociopaths', 'musk', 'manafort', 'vest', 'whistle', 'pleased', 'uruguayan', 'std', 'blocking', 'horseback', 'appealing', 'kicker', 'zoo', 'ashton', 'speechwriters', 'baboon', 'eroding', 'disc', 'gonorrhea', 'threats', 'atop', 'momma', 'pioneer', 'prehistoric', 'feelgood', 'pleasant', 'confusion', 'sister', 'improved', 'bedtime', 'sex', 'fainted', 'trucks', 'led', 'hieroglyphic', 'katherine', 'redesigned', 'trafficking', 'cdc', 'finest', 'sadly', 'exciting', 'ranch', 'elderly', 'videos', 'theme', 'lighter', 'work', 'sue', 'soccer', 'rails', 'wizards', 'juicy', 'ancestors', 'vinny', 'triumph', 'decades', 'radical', 'acne', 'behavioral', 'sexier', 'opening', 'ferraris', 'agriculture', 'mockingbird', 'arms', 'airstrikes', 'mobster', 'relaxing', 'luxurious', 'line', 'kevin', 'kidnapping', 'mario', 'notoriety', 'douchier', 'thong', 'grab', 'covering', 'provided', 'parliament', 'film', 'sexy', 'caterers', 'envelope', 'chanukah', 'burbank', 'explicit', 'genius', 'felonies', 'destroying', 'jefferson', 'mandatory', 'leftist', 'yanked', 'take', 'hookups', 'multiple', 'rude', 'coals', 'confederacy', 'feared', 'blah', 'fertility', 'letters', 'luck', 'adorable', 'lonely', 'foreigners', 'brewers', 'clearly', 'blackberry', 'outages', 'functions', 'fought', 'telephone', 'freakin', 'yelp', 'downton', 'hitler', 'roomba', 'assembling', 'vidal', 'threatened', 'kamala', 'p', 'wwe', 'sandwich', 'mice', 'lemon', 'emphasizes', 'primates', 'throat', 'employs', 'critic', 'urinate', 'soundtrack', 'halftime', 'boasts', 'decline', 'tap', 'walk', 'healthier', 'lineup', 'imitatus', 'tae', 'bodybuilders', 'keeping', 'axl', 'tons', 'pretends', 'set', 'alcoholism', 'territory', 'squeeze', 'birthplaces', 'spelling', 'toes', 'ronny', 'program', 'undisclosed', 'shushy', 'spanx', 'boyfriend', 'pornos', 'solved', 'dwarves', 'kraft', 'subtle', 'reconstructed', 'health', 'pattinson', 'minor', 'victories', 'signed', 'featuring', 'istan', 'moto', 'jerky', 'valley', 'delegates', 'skateboard', 'policeman', 'impair', 'parenthood', 'bully', 'stance', 'patch', 'delivers', 'excessively', 'wet', 'quarterback', 'osama', 'scandrick', 'walt', 'entourage', 'picks', 'nearest', 'coen', 'diapers', 'trans', 'journey', 'hosts', 'hannity', 'alone', 'mountain', 'fingered', 'warm', 'nutribullets', 'backlash', 'sized', 'princess', 'bastard', 'hurry', 'eggnog', 'moderated', 'flirted', 'holistic', 'malcolm', 'ousting', 'cleanse', 'expression', 'mocking', 'manhunt', 'expands', 'leads', 'lutheran', 'cow', 'struck', 'shakira', 'agnus', 'distractions', 'reagans', 'cornell', 'itis', 'hung', 'morocco', 'years', 'surging', 'inspire', 'nanny', 'psychological', 'explosive', 'presenting', 'dumped', 'explore', 'wonderbra', 'lasting', 'ways', 'garmin', 'relations', 'arranged', 'fahrvergnugen', 'barista', 'postage', 'shriver', 'holyfield', 'miami', 'elizabeth', 'awareness', 'hamid', 'correction', 'chapter', 'risque', 'proactive', 'lax', 'favorite', 'first', 'amazonian', 'angelou', 'insulting', 'lifting', 'golfing', 'kris', 'belts', 'anticipation', 'vader', 'divert', 'jon', 'gretzky', 'adding', 'refudiate', 'benefit', 'boundary', 'cabinet', 'regarded', 'arbys', 'recruiting', 'learjet', 'harriet', 'guessed', 'lyrics', 'tampering', 'compares', 'sunshine', 'clingin', 'nicholson', 'yahoo', 'outgrow', 'authoritative', 'scammed', 'corpse', 'holly', 'remind', 'volkswagen', 'roman', 'marred', 'margin', 'qualified', 'ayatollah', 'graphic', 'english', 'genetically', 'rescued', 'pardon', 'harassing', 'vodka', 'kindergarten', 'isis', 'psy', 'beanie', 'simulates', 'keeps', 'eminem', 'supportive', 'simulating', 'song', 'whiteness', 'sudden', 'smelled', 'flown', 'nintendo', 'mostly', 'stabbed', 'reabsorbed', 'utterly', 'gere', 'getting', 'pacifier', 'oregon', 'tlc', 'bachelor', 'apps', 'berger', 'homosexual', 'commencement', 'organizers', 'papyrus', 'movies', 'drunken', 'kickler', 'vet', 'challenged', 'clinton', 'eggs', 'concentrate', 'exhibition', 'chile', 'populations', 'humor', 'custom', 'severe', 'microsoft', 'data', 'resettling', 'exercise', 'losing', 'immigrants', 'lady', 'unused', 'turner', 'ncaa', 'heartbeat', 'choose', 'immigrate', 'ferris', 'spared', 'lawyers', 'teaming', 'marches', 'rhode', 'managed', 'dissolved', 'stamp', 'babies', 'produces', 'doctorate', 'marital', 'psychologist', 'easterners', 'groups', 'blood', 'mma', 'beneath', 'responded', 'shortstop', 'napolitano', 'interstellar', 'peacock', 'chair', 'utah', 'witnesses', 'nerdy', 'spoiled', 'joke', 'strawberry', 'skyler', 'spinoff', 'snyderman', 'shoots', 'racism', 'format', 'padres', 'paul', 'candidate', 'barker', 'rangers', 'bedazzler', 'wife', 'joker', 'dead', 'repeating', 'bionic', 'typos', 'equality', 'emojis', 'sakes', 'cherrywood', 'flirtation', 'powers', 'holdin', 'cardiology', 'bros', 'meetings', 'rivals', 'freed', 'blackout', 'justin', 'forearm', 'moses', 'speeding', 'election', 'fort', 'ratings', 'settle', 'whopperrito', 'stripes', 'whocaresville', 'stage', 'default', 'shy', 'coast', 'lodging', 'felt', 'footsteps', 'wisdom', 'yards', 'barefoot', 'anytime', 'consensus', 'funding', 'spider', 'again', 'manning', 'cried', 'weeks', 'bastards', 'zuckerberg', 'watercolor', 'bibles', 'trapping', 'smartphones', 'eat', 'talkers', 'brings', 'condoms', 'dutch', 'crack', 'depiction', 'bombs', 'flirting', 'percent', 'intercepted', 'robin', 'propaganda', 'bathrooms', 'reveal', 'bmw', 'quite', 'writes', 'poked', 'excrement', 'austin', 'planting', 'artificial', 'permanently', 'faster', 'overpriced', 'chargers', 'proper', 'syria', 'fend', 'blaine', 'armstrong', 'despite', 'seagal', 'lenscrafters', 'preparing', 'spacecraft', 'possession', 'slower', 'attitudes', 'allergies', 'wolf', 'shortly', 'catchphrases', 'boasted', 'award', 'descend', 'trials', 'ombra', 'yoga', 'prankster', 'private', 'consoled', 'mispronouncing', 'delayed', 'organizations', 'secured', 'partly', 'filming', 'auditioning', 'cowboys', 'reelected', 'chokehold', 'holes', 'compared', 'larry', 'pole', 'papam', 'dolphin', 'directors', 'technically', 'primarily', 'murray', 'menzel', 'offers', 'fellowship', 'beam', 'unfavorable', 'hired', 'squirmish', 'bachelorette', 'ew', 'waitress', 'ross', 'fensen', 'catcher', 'migraine', 'winds', 'usda', 'paraguay', 'much', 'rapture', 'vitamins', 'django', 'argo', 'beliebers', 'sights', 'rained', 'passages', 'mcpettingzoo', 'albert', 'presided', 'groundwork', 'receiver', 'decided', 'rebels', 'typed', 'singing', 'char', 'rates', 'pelley', 'birthplace', 'giggling', 'horsemeat', 'episode', 'festival', 'beers', 'indefinitely', 'dazs', 'nra', 'balls', 'pods', 'so', 'jason', 'aid', 'forty', 'continuity', 'sam', 'ho', 'proctologist', 'kennedys', 'bursting', 'lithium', 'index', 'startup', 'yells', 'basketball', 'connection', 'identifying', 'stockbroker', 'star', 'treatments', 'feinstein', 'mclachlan', 'las', 'surrounding', 'coerce', 'hungry', 'nissan', 'stilettos', 'varmint', 'knowingly', 'reiterate', 'bamba', 'statues', 'comparable', 'interviews', 'truck', 'anchor', 'rampage', 'clarence', 'sportsman', 'emmanuel', 'actor', 'mocked', 'vape', 'eternal', 'purgatory', 'crowe', 'marrisa', 'trader', 'break', 'assholes', 'personals', 'vegetable', 'customs', 'fuel', 'phineas', 'mashup', 'portrayed', 'hood', 'china', 'easton', 'ouch', 'caesar', 'other', 'antarctica', 'minaj', 'mitt', 'freeway', 'pancreas', 'pub', 'goat', 'rallies', 'yardsale', 'petite', 'math', 'sexual', 'asks', 'exactly', 'dating', 'trampoline', 'scrolling', 'hunt', 'erect', 'pizzeria', 'big', 'mass', 'yellowstone', 'arguments', 'teleprompter', 'bipolar', 'equated', 'fiancee', 'yes', 'offer', 'polls', 'lunatic', 'ordering', 'aging', 'niece', 'failing', 'washed', 'danica', 'humboldt', 'octagon', 'effectively', 'mansplaining', 'staying', 'burglary', 'brush', 'birthday', 'intended', 'life', 'madeleine', 'culture', 'urge', 'sri', 'bring', 'blessing', 'girdle', 'depp', 'scaled', 'messing', 'tune', 'threw', 'executives', 'running', 'johnston', 'watson', 'zuccotti', 'biography', 'commentators', 'not', 'college', 'malarkey', 'eleven', 'twain', 'pizza', 'fhm', 'gearing', 'outsourcing', 'diddler', 'chen', 'foxnews', 'dominatrix', 'empire', 'aquarium', 'courtroom', 'cement', 'clifford', 'nosed', 'personalized', 'least', 'modest', 'janice', 'trap', 'collided', 'pepperoni', 'overlooked', 'mistress', 'freely', 'vocal', 'ipo', 'infections', 'winfrey', 'anyway', 'perks', 'prominent', 'attend', 'carefully', 'rama', 'productivity', 'greg', 'asiatic', 'speaker', 'niall', 'destination', 'ginger', 'richest', 'wait', 'producer', 'deschanel', 'bury', 'savannah', 'reasonable', 'fights', 'please', 'rican', 'spots', 'topless', 'texts', 'jail', 'crying', 'lied', 'leper', 'united', 'impersonators', 'heartbreaker', 'st', 'doping', 'maddow', 'aristocratic', 'nik', 'marriages', 'awards', 'peach', 'leona', 'terra', 'officer', 'how', 'bock', 'door', 'journal', 'cosmopolitan', 'lions', 'exchange', 'ordered', 'brewer', 'antique', 'mutated', 'inspiration', 'nitrogen', 'shaft', 'trick', 'oval', 'jackpot', 'talked', 'tradition', 'undergoes', 'surf', 'uncomfortable', 'mythology', 'ebay', 'em', 'epic', 'early', 'thrus', 'bye', 'transparent', 'flesh', 'phasing', 'strange', 'discover', 'ancestral', 'nightclub', 'denmark', 'somewhere', 'vietnam', 'social', 'wireless', 'jill', 'janet', 'crown', 'toplessness', 'cans', 'convinces', 'dinners', 'descended', 'exact', 'simple', 'endurance', 'reporters', 'hostage', 'dion', 'glee', 'milf', 'fisher', 'trend', 'rambling', 'undecided', 'tension', 'built', 'aaa', 'gangnam', 'cancel', 'shoot', 'ozeem', 'produce', 'pictures', 'photographs', 'bagged', 'bib', 'theatergoers', 'corporate', 'eliminate', 'nicole', 'pass', 'noah', 'comfortably', 'turn', 'retain', 'wildlife', 'oops', 'locales', 'crops', 'canadians', 'bootylicious', 'accuse', 'typically', 'hypnotized', 'prosecutors', 'guatemala', 'shares', 'ringwald', 'effing', 'applicant', 'employees', 'unhelpful', 'darvish', 'feels', 'neurosurgeon', 'evelyn', 'rupaul', 'nah', 'finish', 'alright', 'poking', 'chilean', 'stretching', 'du', 'wiring', 'figures', 'sack', 'courteous', 'shakes', 'snubbed', 'kicking', 'pot', 'treating', 'glimpse', 'pushed', 'bankrupt', 'troll', 'vowing', 'telling', 'ios', 'punks', 'cyberweapons', 'waving', 'raped', 'tiaras', 'watchers', 'session', 'jonathan', 'corker', 'boring', 'actors', 'afghanistan', 'ticket', 'senator', 'learnin', 'cattle', 'knockoffs', 'giggles', 'suge', 'peggy', 'skeptical', 'hailed', 'illegals', 'crushed', 'presidenciary', 'automation', 'screen', 'app', 'bruce', 'poopoo', 'ghost', 'buyers', 'taxidermy', 'octomom', 'albuquerque', 'felon', 'prank', 'motel', 'operators', 'vladimir', 'cleaner', 'loneliness', 'moves', 'hezbollah', 'censorship', 'brackets', 'hmmm', 'zeus', 'scientifically', 'booked', 'vi', 'cutting', 'bras', 'report', 'micronesia', 'jesus', 'frightened', 'coolidge', 'scared', 'sotomayor', 'illustrated', 'mumford', '.t', 'mgm', 'vertical', 'hillary', 'put', 'israeli', 'greek', 'minnesota', 'impressed', 'blamed', 'fine', 'improvements', 'thankful', 'famous', 'assault', 'attackers', 'jazz', 'unitard', 'upgrade', 'pump', 'completed', 'shed', 'kampf', 'eclipse', 'violates', 'someday', 'into', 'sentra', 'spraying', 'salacious', 'sadtronics', 'standard', 'manned', 'dictators', 'delta', 'nearly', 'liberals', 'active', 'lewandowski', 'slimdown', 'conjugal', 'huts', 'hallmark', 'cd', 'yield', 'keillor', 'read', 'firearms', 'navigator', 'wolverines', 'defriended', 'diary', 'overcome', 'ground', 'practically', 'embodiment', 'swinton', 'playfully', 'sued', 'fil', 'con', 'accurate', 'reminder', 'healthcare', 'orchestra', 'punk', 'chunk', 'korean', 'main', 'moonlit', 'hated', 'distinct', 'bin', 'bison', 'national', 'brutal', 'airbrushed', 'focusing', 'hopefuls', 'partnering', 'valet', 'shadowy', 'skater', 'pinocchio', 'tantrums', 'dildo', 'expected', 'antiques', 'boos', 'piece', 'noticing', 'cameramen', 'raging', 'stable', 'setting', 'means', 'dimes', 'slippers', 'aiken', 'bernie', 'orangutans', 'supremacists', 'carrot', 'concrete', 'bucks', 'gingerbread', 'rose', 'plantation', 'receivers', 'till', 'placing', 'understand', 'egyptair', 'dealt', 'recently', 'bloomberg', 'charms', 'unrest', 'crepe', 'god', 'cheering', 'ensemble', 'tank', 'poured', 'trample', 'kors', 'spark', 'encountered', 'holder', 'goodman', 'technician', 'recommends', 'strategy', 'pyramids', 'grandpa', 'drafting', 'lochte', 'solo', 'pantyhose', 'backfired', 'curved', 'between', 'hazing', 'indicates', 'violation', 'dealer', 'satellites', 'grocery', 'includes', 'replica', 'claims', 'authority', 'bengal', 'thor', 'esperanza', 'rex', 'regardless', 'rat', 'cigarette', 'onslaught', 'mecca', 'symbolic', 'surprisingly', 'studies', 'tier', 'artery', 'retaliation', 'sailors', 'building', 'griffin', 'grammys', 'immortal', 'cellmate', 'cut', 'les', 'featured', 'intern', 'cee', 'earliest', 'racketeering', 'catch', 'fujitsu', 'brothers', 'legalization', 'daddy', 'abusive', 'manual', 'decorations', 'pandering', 'sport', 'nigeria', 'estimate', 'grenada', 'omnivores', 'jarod', 'trimming', 'fatigue', 'minivan', 'beach', 'george', 'exams', 'nashville', 'tornadoes', 'martian', 'argentina', 'apologizes', 'mordor', 'cook', 'pat', 'classroom', 'realized', 'future', 'hastings', 'colonoscopy', 'ducks', 'capacity', 'fears', 'drinks', 'cia', 'redwood', 'blunder', 'rattlesnake', 'prediction', 'defined', 'cuban', 'democracy', 'resting', 'pointing', 'fidget', 'driven', 'ruin', 'ripped', 'dropping', 'ceos', 'integrating', 'goggles', 'ah', 'singer', 'listens', 'conservatives', 'bangalore', 'questioning', 'ernie', 'desert', 'johnny', 'consultants', 'model', 'lassen', 'skynyrd', 'frisked', 'attractiveness', 'drills', 'her', 'cord', 'moneybags', 'disappeared', 'attorney', 'hedge', 'tiny', 'losers', 'aircrafts', 'changed', 'solve', 'camera', 'convincing', 'thicke', 'waldo', 'bud', 'den', 'cigarettes', 'announce', 'maria', 'discarded', 'dominance', 'campuses', 'shortest', 'blouse', 'woke', 'shade', 'extended', 'gig', 'diets', 'dalai', 'rotating', 'rc', 'oppression', 'time', 'fossilized', 'xl', 'ninjas', 'recent', 'warrant', 'coastline', 'hatin', 'sounds', 'kenyan', 'hotness', 'empowered', 'anchorage', 'megadeth', 'residency', 'bio', 'quotations', 'donors', 'afterwards', 'salon', 'delays', 'samsung', 'zingers', 'sushi', 'username', 'himself', 'arch', 'bienvenidos', 'bobbleheads', 'advertised', 'shovel', 'anthropologists', 'parrot', 'cab', 'suspects', 'apu', 'buoy', 'oil', 'plus', 'jails', 'legos', 'pontiff', 'verse', 'protests', 'implying', 'defend', 'paparazzi', 'decapitated', 'certain', 'blunt', 'holy', 'events', 'audi', 'capitalized', 'starting', 'combines', 'thriller', 'taunt', 'mailman', 'tebow', 'admiration', 'owl', 'twister', 'tissue', 'night', 'delegation', 'impregnate', 'bbq', 'fascinating', 'clowns', 'cemetery', 'unplug', 'logged', 'rice', 'celibacy', 'nationally', 'lamas', 'whole', 'chewbacca', 'fixed', 'strengthened', 'croatia', 'aww', 'cryogenically', 'ants', 'personality', 'winding', 'lapd', 'warned', 'resisting', 'settlement', 'applesauce', 'insult', 'crunches', 'sense', 'monologue', 'mints', 'plump', 'pics', 'fashionable', 'seek', 'controls', 'hobbits', 'burt', 'arab', 'combination', 'moderator', 'tool', 'involve', 'blume', 'skinny', 'dried', 'guitar', 'moons', 'deathly', 'learns', 'huckabee', 'founded', 'stit', 'grandmother', 'sterilized', 'thorium', 'jingling', 'lift', 'sexuality', 'prii', 'chapo', 'titbit', 'briss', 'throwing', 'birthers', 'knocking', 'beret', 'slamming', 'recommend', 'ahh', 'unloaded', 'hawaiian', 'tenth', 'rascal', 'trends', 'narcissist', 'confirmation', 'hugh', 'suburb', 'breathe', 'vehicle', 'titillating', 'sizzle', 'badminton', 'amid', 'insane', 'telemundo', 'cycles', 'quebec', 'prius', 'beloved', 'cumberb', 'scoreboard', 'homes', 'picture', 'goodest', 'kippur', 'hilton', 'crashing', 'owning', 'keller', 'budget', 'burial', 'carpal', 'ican', 'paychecks', 'sipping', 'savings', 'determined', 'recognition', 'trudeau', 'change', 'designed', 'mouse', 'nasty', 'vigorously', 'pilgrims', 'slaw', 'rafalca', 'nyad', 'violations', '.f', 'cruz', 'consult', 'malibu', 'majors', 'sergeant', 'fieri', 'camden', 'kushner', 'plants', 'pleasing', 'kidneys', 'twice', 'concealed', 'exhibit', 'soup', 'zebra', 'jewelry', 'prejudice', 'storming', 'appreciation', 'socialist', 'train', 'naturalists', 'shoppers', 'vow', 'fractured', 'toxic', 'job', 'stalkers', 'chicken', 'effort', 'venus', 'froze', 'chap', 'lists', 'sickly', 'flea', 'welcome', 'revamped', 'rna', 'samanthas', 'misconduct', 'hoarders', 'tangible', 'flo', 'captured', 'te', 'auntie', 'calculating', 'laughing', 'denture', 'halls', 'waxes', 'sarcastic', 'panic', 'disgraced', 'jewels', 'puppet', 'government', 'let', 'bulbs', 'iq', 'stormer', 'pendejo', 'gaze', 'emanuel', 'exodus', 'miserable', 'bynes', 'miracle', 'timer', 'skeets', 'conducting', 'haram', 'olson', 'history', 'valuables', 'lawmaker', 'mirrorless', 'smother', 'glaring', 'bout', 'investigation', 'director', 'shortage', 'lock', 'element', 'fascism', 'stephen', 'seahawks', 'orrin', 'bird', 'get', 'allegedly', 'dirt', 'awesomesauce', 'executive', 'ungracefully', 'emergency', 'norwegian', 'enroll', 'congratulated', 'defended', 'folk', 'voucher', 'brute', 'cyanide', 'touting', 'iranians', 'verb', 'roads', 'cashing', 'sy', 'america', 'covert', 'pope', 'jumpsuits', 'administrator', 'simmons', 'scenes', 'freak', 'unfriended', 'excel', 'invited', 'popeye', 'nsync', 'ripened', 'peace', 'details', 'over', 'imprisonment', 'italian', 'sustain', 'fortunately', 'slur', 'workplace', 'stallion', 'staging', 'intro', 'pose', 'ha', 'tend', 'essay', 'student', 'christmastime', 'emily', 'deadly', 'rudolph', 'emailing', 'sits', 'gown', 'unusual', 'rock', 'cheated', 'sketchy', 'hydroponic', 'disturbing', 'workday', 'amounts', 'barney', 'headphones', 'insist', 'dow', 'divas', 'biopic', 'diplomatic', 'schieffer', 'borat', 'gorge', 'buffalo', 'corey', 'pa', 'birthdays', 'among', 'holley', 'fry', 'found', 'blackest', 'raven', 'hollywood', 'acrobatic', 'skipped', 'brewery', 'communion', 'thicker', 'displayed', 'remembering', 'pockets', 'run', 'binge', 'buddhist', 'baltimore', 'warren', 'hesitated', 'ignored', 'cronut', 'hundred', 'chances', 'degeneres', 'bale', 'advisers', 'illness', 'licking', 'travelling', 'filth', 'stumbled', 'newt', 'benjamin', 'prohibit', 'bon', 'face', 'le', 'entryway', 'cartoon', 'mccain', 'paranoia', 'covers', 'burger', 'climax', 'speculating', 'reid', 'helicopter', 'homophobe', 'r', 'peta', 'understandable', 'syphillina', 'happier', 'shorten', 'zeppelin', 'sign', 'franco', 'crippled', 'ageist', 'beefed', 'vests', 'federation', 'cane', 'bids', 'philosophy', 'launched', 'council', 'realtor', 'dancing', 'advises', 'believers', 'serious', 'bothered', 'southeast', 'ideas', 'insists', 'silicon', 'shack', 'dammit', 'started', 'splashes', 'activity', 'groove', 'behalf', 'homophobic', 'sats', 'gout', 'reunion', 'blurry', 'dogtv', 'headset', 'contractors', 'organizing', 'bestiality', 'expansion', 'impact', 'combat', 'panning', 'founding', 'continents', 'serves', 'perfectly', 'know', 'jars', 'implant', 'hola', 'stalin', 'rare', 'chef', 'find', 'tasty', 'extra', 'thrones', 'commissioner', 'spike', 'mailboxes', 'surfing', 'barred', 'gotta', 'boyardee', 'homemade', 'coachella', 'fail', 'walked', 'pierced', 'pendleton', 'wikileaks', 'candy', 'disrupted', 'log', 'disresprite', 'camping', 'rio', 'vague', 'chad', 'lever', 'rejections', 'backpacking', 'tomatillos', 'translator', 'leftover', 'attendant', 'basement', 'nipple', 'brittle', 'contamination', 'typecast', 'jagermeister', 'urging', 'eff', 'computer', 'settings', 'neptune', 'cher', 'praises', 'insect', 'broderick', 'bolton', 'theories', 'rocketship', 'escapes', 'spat', 'occurred', 'ihop', 'amusement', 'transformed', 'abby', 'accidentally', 'fullback', 'expanding', 'comes', 'barack', 'promise', 'nutritionists', 'caucasian', 'ozzy', 'un', 'control', 'finding', 'sensors', 'shark', 'organ', 'reclining', 'usc', 'nots', 'somehow', 'bikinis', 'paper', 'coded', 'copy', 'classified', 'rung', 'resuscitate', 'intense', 'six', 'internment', 'technical', 'until', 'couriers', 'semitic', 'reddit', 'surprise', 'hourly', 'heart', 'corporation', 'monkey', 'devout', 'styx', 'detect', 'claws', 'overseas', 'clusterf', 'rise', 'praying', 'corral', 'lookout', 'hispanics', 'pointy', 'sally', 'griffith', 'enjoyable', 'user', 'funerals', 'historic', 'parks', 'restraining', 'javelin', 'narnia', 'minivans', 'stairway', 'titcomb', 'womens', 'liz', 'easiest', 'treater', 'vagina', 'sluttier', 'ding', 'survey', 'swift', 'suitable', 'shouts', 'implanted', 'senate', 'larger', 'thing', 'wake', 'updating', 'stream', 'cam', '.n', 'liquor', 'parts', 'lord', 'pounder', 'imposing', 'feminists', 'longingly', 'crabs', 'corsages', 'cruises', 'stormtrooper', 'island', 'fatter', 'nonetheless', 'pastors', 'commentary', 'jeans', 'studying', 'swim', 'aerobics', 'treaty', 'menu', 'badge', 'times', 'propecia', 'illnesses', 'triangle', 'dialects', 'applause', 'batteries', 'astronaut', 'blingh', 'strategize', 'seems', 'protesting', 'broad', 'england', 'donuts', 'prefer', 'manufacture', 'geek', 'aircraft', 'reappearing', 'opposite', 'scrotums', 'crap', 'channel', 'irresistible', '.r', 'disappointed', 'newscaster', 'lamar', 'stripped', 'kongs', 'save', 'boitano', 'defense', 'black', 'goodwill', 'available', 'bedonkadonk', 'scout', 'immigrated', 'rosh', 'freshman', 'sexualize', 'whopper', 'both', 'installed', 'jerseys', 'beeville', 'fended', 'head', 'subscribers', 'spicer', 'medication', 'was', 'blowouts', 'publish', 'typewriters', 'appointed', 'frehley', 'abandoned', 'gated', 'memorial', 'injuries', 'directly', 'elle', 'argue', 'iron', 'sympathize', 'infection', 'lincoln', 'scurvy', 'sessions', 'modern', 'honey', 'gateway', 'lasagna', 'forwards', 'decreased', 'called', 'soda', 'demeans', 'kissing', 'splotch', 'dyson', 'protestor', 'mondays', 'anna', 'nuns', 'fetuses', 'ashleymadison', 'fists', 'furred', 'tuchus', 'sylvia', 'samples', 'revolutionary', 'indicated', 'airline', 'cellulite', 'mexicans', 'pro', 'boredom', 'trackers', 'photobomb', 'cereal', 'swallow', 'flow', 'waiter', 'lit', 'crows', 'greenwich', 'interest', 'overs', 'hunny', 'sided', 'hump', 'militia', 'cheney', 'genie', 'bedrooms', 'versatile', 'blimp', 'looking', 'taxing', 'calculate', 'tampons', 'theory', 'crisis', 'mormons', 'hole', 'paintings', 'disinfect', 'barroom', 'cited', 'type', 'pitch', 'cedars', 'protecting', 'nap', 'herpes', 'shasta', 'east', 'uteruses', 'douchebag', 'lifter', 'ringed', 'sitcom', 'pepsi', 'arya', 'cooler', 'suv', 'californias', 'crucial', 'decency', 'reputable', 'randy', 'dictator', 'whichever', 'march', 'apes', 'rihanna', 'tuckabee', 'pentagon', 'darkness', 'vmas', 'usb', 'brit', 'enter'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.index2word.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bad36f1a40b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mweights_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mwords_found\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
     ]
    }
   ],
   "source": [
    "matrix_len = len(voc.index2word)\n",
    "weights_matrix = np.zeros((matrix_len, 50))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(voc.index2word.values()):\n",
    "    try: \n",
    "        weights_matrix[i] = glove[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(50, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_matrix[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dccbaad806e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "weights_matrix['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d3d6dce287f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "weights_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14403, 50)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-24c518c537a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combination'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
     ]
    }
   ],
   "source": [
    "glove['combination']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for Models\n",
    "-----------------------\n",
    "\n",
    "Although we have put a great deal of effort into preparing and massaging our\n",
    "data into a nice vocabulary object and list of sentence pairs, our models\n",
    "will ultimately expect numerical torch tensors as inputs. One way to\n",
    "prepare the processed data for the models can be found in the `seq2seq\n",
    "translation\n",
    "tutorial <https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html>`__.\n",
    "In that tutorial, we use a batch size of 1, meaning that all we have to\n",
    "do is convert the words in our sentence pairs to their corresponding\n",
    "indexes from the vocabulary and feed this to the models.\n",
    "\n",
    "However, if you’re interested in speeding up training and/or would like\n",
    "to leverage GPU parallelization capabilities, you will need to train\n",
    "with mini-batches.\n",
    "\n",
    "Using mini-batches also means that we must be mindful of the variation\n",
    "of sentence length in our batches. To accomodate sentences of different\n",
    "sizes in the same batch, we will make our batched input tensor of shape\n",
    "*(max_length, batch_size)*, where sentences shorter than the\n",
    "*max_length* are zero padded after an *EOS_token*.\n",
    "\n",
    "If we simply convert our English sentences to tensors by converting\n",
    "words to their indexes(\\ ``indexesFromSentence``) and zero-pad, our\n",
    "tensor would have shape *(batch_size, max_length)* and indexing the\n",
    "first dimension would return a full sequence across all time-steps.\n",
    "However, we need to be able to index our batch along time, and across\n",
    "all sequences in the batch. Therefore, we transpose our input batch\n",
    "shape to *(max_length, batch_size)*, so that indexing across the first\n",
    "dimension returns a time step across all sentences in the batch. We\n",
    "handle this transpose implicitly in the ``zeroPadding`` function.\n",
    "\n",
    ".. figure:: /_static/img/chatbot/seq2seq_batches.png\n",
    "   :align: center\n",
    "   :alt: batches\n",
    "\n",
    "The ``inputVar`` function handles the process of converting sentences to\n",
    "tensor, ultimately creating a correctly shaped zero-padded tensor. It\n",
    "also returns a tensor of ``lengths`` for each of the sequences in the\n",
    "batch which will be passed to our decoder later.\n",
    "\n",
    "The ``outputVar`` function performs a similar function to ``inputVar``,\n",
    "but instead of returning a ``lengths`` tensor, it returns a binary mask\n",
    "tensor and a maximum target sentence length. The binary mask tensor has\n",
    "the same shape as the output target tensor, but every element that is a\n",
    "*PAD_token* is 0 and all others are 1.\n",
    "\n",
    "``batch2TrainData`` simply takes a bunch of pairs and returns the input\n",
    "and target tensors using the aforementioned functions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[ 6271,   128,  9205,  5800, 12915],\n",
      "        [ 6307,  5800,  5361,  7094,  2342],\n",
      "        [ 8353,  6618,  1976, 11569,  6681],\n",
      "        [ 2485,  1348, 12042, 11765,  9857],\n",
      "        [11569,  2143,  6307,  5046,  2465],\n",
      "        [ 6307, 12758,  3838,  4389,  8283],\n",
      "        [12762,  4681, 11031, 10100,  7591],\n",
      "        [ 7911,  3773, 14288,  5800,  6307],\n",
      "        [12674,  5800, 13046,  4231, 11693],\n",
      "        [ 6445,  5535,  2791,   726,     3],\n",
      "        [11339,  9791, 12064,  9857,     2],\n",
      "        [ 7591,  8336, 10643,  4002,     0],\n",
      "        [ 5800, 10042,   714,  5458,     0],\n",
      "        [ 2067,  8968, 13758,     3,     0],\n",
      "        [ 1460, 10479,     3,     2,     0],\n",
      "        [   92,     3,     2,     0,     0],\n",
      "        [11388,     2,     0,     0,     0],\n",
      "        [ 9791,     0,     0,     0,     0],\n",
      "        [ 6307,     0,     0,     0,     0],\n",
      "        [  545,     0,     0,     0,     0],\n",
      "        [14206,     0,     0,     0,     0],\n",
      "        [ 7591,     0,     0,     0,     0],\n",
      "        [ 6307,     0,     0,     0,     0],\n",
      "        [ 6558,     0,     0,     0,     0],\n",
      "        [    3,     0,     0,     0,     0],\n",
      "        [    2,     0,     0,     0,     0]])\n",
      "lengths: tensor([26, 17, 16, 15, 11])\n",
      "target_variable: tensor([[11388,  7591, 11388,  6307,  1467],\n",
      "        [ 9791,  5800,  9791,  4231,  7162],\n",
      "        [ 5658,  8731,  4124, 10151,  8068],\n",
      "        [ 8827,  8999,  3292, 12915, 10180],\n",
      "        [11569, 12758,   417,  7718,  4236],\n",
      "        [ 7911,  4681,   726,  9205,  2410],\n",
      "        [ 9791, 10151,  1314, 11765, 10539],\n",
      "        [10401,  2342,  6519,  8507,  6232],\n",
      "        [13046,  7591, 11388,  7267,  6307],\n",
      "        [ 1224,  6143,  6307,  2386,  6558],\n",
      "        [ 1865,  4522, 11053,   434, 10180],\n",
      "        [ 3466,  7591,  4389,  6962, 13316],\n",
      "        [    2,  6307,  5800, 10944,  4981],\n",
      "        [    0,  1703,  3276, 12351, 10944],\n",
      "        [    0,  7786, 13141,  6807, 12386],\n",
      "        [    0,   245, 11569,  3466,  3292],\n",
      "        [    0,  7342,  8980,     2,    83],\n",
      "        [    0, 10648,  2728,     0, 11647],\n",
      "        [    0,  3466,  1302,     0,  2763],\n",
      "        [    0,     2,  6962,     0,  5800],\n",
      "        [    0,     0,  9920,     0,  4604],\n",
      "        [    0,     0, 11817,     0,  3466],\n",
      "        [    0,     0,  3466,     0,     2],\n",
      "        [    0,     0,     2,     0,     0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 24\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    \n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        #print(pair[0])\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Models\n",
    "-------------\n",
    "\n",
    "Seq2Seq Model\n",
    "~~~~~~~~~~~~~\n",
    "\n",
    "The brains of our chatbot is a sequence-to-sequence (seq2seq) model. The\n",
    "goal of a seq2seq model is to take a variable-length sequence as an\n",
    "input, and return a variable-length sequence as an output using a\n",
    "fixed-sized model.\n",
    "\n",
    "`Sutskever et al. <https://arxiv.org/abs/1409.3215>`__ discovered that\n",
    "by using two separate recurrent neural nets together, we can accomplish\n",
    "this task. One RNN acts as an **encoder**, which encodes a variable\n",
    "length input sequence to a fixed-length context vector. In theory, this\n",
    "context vector (the final hidden layer of the RNN) will contain semantic\n",
    "information about the query sentence that is input to the bot. The\n",
    "second RNN is a **decoder**, which takes an input word and the context\n",
    "vector, and returns a guess for the next word in the sequence and a\n",
    "hidden state to use in the next iteration.\n",
    "\n",
    ".. figure:: /_static/img/chatbot/seq2seq_ts.png\n",
    "   :align: center\n",
    "   :alt: model\n",
    "\n",
    "Image source:\n",
    "https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder\n",
    "~~~~~~~\n",
    "\n",
    "The encoder RNN iterates through the input sentence one token\n",
    "(e.g. word) at a time, at each time step outputting an “output” vector\n",
    "and a “hidden state” vector. The hidden state vector is then passed to\n",
    "the next time step, while the output vector is recorded. The encoder\n",
    "transforms the context it saw at each point in the sequence into a set\n",
    "of points in a high-dimensional space, which the decoder will use to\n",
    "generate a meaningful output for the given task.\n",
    "\n",
    "At the heart of our encoder is a multi-layered Gated Recurrent Unit,\n",
    "invented by `Cho et al. <https://arxiv.org/pdf/1406.1078v3.pdf>`__ in\n",
    "2014. We will use a bidirectional variant of the GRU, meaning that there\n",
    "are essentially two independent RNNs: one that is fed the input sequence\n",
    "in normal sequential order, and one that is fed the input sequence in\n",
    "reverse order. The outputs of each network are summed at each time step.\n",
    "Using a bidirectional GRU will give us the advantage of encoding both\n",
    "past and future context.\n",
    "\n",
    "Bidirectional RNN:\n",
    "\n",
    ".. figure:: /_static/img/chatbot/RNN-bidirectional.png\n",
    "   :width: 70%\n",
    "   :align: center\n",
    "   :alt: rnn_bidir\n",
    "\n",
    "Image source: https://colah.github.io/posts/2015-09-NN-Types-FP/\n",
    "\n",
    "Note that an ``embedding`` layer is used to encode our word indices in\n",
    "an arbitrarily sized feature space. For our models, this layer will map\n",
    "each word to a feature space of size *hidden_size*. When trained, these\n",
    "values should encode semantic similarity between similar meaning words.\n",
    "\n",
    "Finally, if passing a padded batch of sequences to an RNN module, we\n",
    "must pack and unpack padding around the RNN pass using\n",
    "``nn.utils.rnn.pack_padded_sequence`` and\n",
    "``nn.utils.rnn.pad_packed_sequence`` respectively.\n",
    "\n",
    "**Computation Graph:**\n",
    "\n",
    "   1) Convert word indexes to embeddings.\n",
    "   2) Pack padded batch of sequences for RNN module.\n",
    "   3) Forward pass through GRU.\n",
    "   4) Unpack padding.\n",
    "   5) Sum bidirectional GRU outputs.\n",
    "   6) Return output and final hidden state.\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "-  ``input_seq``: batch of input sentences; shape=\\ *(max_length,\n",
    "   batch_size)*\n",
    "-  ``input_lengths``: list of sentence lengths corresponding to each\n",
    "   sentence in the batch; shape=\\ *(batch_size)*\n",
    "-  ``hidden``: hidden state; shape=\\ *(n_layers x num_directions,\n",
    "   batch_size, hidden_size)*\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "-  ``outputs``: output features from the last hidden layer of the GRU\n",
    "   (sum of bidirectional outputs); shape=\\ *(max_length, batch_size,\n",
    "   hidden_size)*\n",
    "-  ``hidden``: updated hidden state from GRU; shape=\\ *(n_layers x\n",
    "   num_directions, batch_size, hidden_size)*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder\n",
    "~~~~~~~\n",
    "\n",
    "The decoder RNN generates the response sentence in a token-by-token\n",
    "fashion. It uses the encoder’s context vectors, and internal hidden\n",
    "states to generate the next word in the sequence. It continues\n",
    "generating words until it outputs an *EOS_token*, representing the end\n",
    "of the sentence. A common problem with a vanilla seq2seq decoder is that\n",
    "if we rely soley on the context vector to encode the entire input\n",
    "sequence’s meaning, it is likely that we will have information loss.\n",
    "This is especially the case when dealing with long input sequences,\n",
    "greatly limiting the capability of our decoder.\n",
    "\n",
    "To combat this, `Bahdanau et al. <https://arxiv.org/abs/1409.0473>`__\n",
    "created an “attention mechanism” that allows the decoder to pay\n",
    "attention to certain parts of the input sequence, rather than using the\n",
    "entire fixed context at every step.\n",
    "\n",
    "At a high level, attention is calculated using the decoder’s current\n",
    "hidden state and the encoder’s outputs. The output attention weights\n",
    "have the same shape as the input sequence, allowing us to multiply them\n",
    "by the encoder outputs, giving us a weighted sum which indicates the\n",
    "parts of encoder output to pay attention to. `Sean\n",
    "Robertson’s <https://github.com/spro>`__ figure describes this very\n",
    "well:\n",
    "\n",
    ".. figure:: /_static/img/chatbot/attn2.png\n",
    "   :align: center\n",
    "   :alt: attn2\n",
    "\n",
    "`Luong et al. <https://arxiv.org/abs/1508.04025>`__ improved upon\n",
    "Bahdanau et al.’s groundwork by creating “Global attention”. The key\n",
    "difference is that with “Global attention”, we consider all of the\n",
    "encoder’s hidden states, as opposed to Bahdanau et al.’s “Local\n",
    "attention”, which only considers the encoder’s hidden state from the\n",
    "current time step. Another difference is that with “Global attention”,\n",
    "we calculate attention weights, or energies, using the hidden state of\n",
    "the decoder from the current time step only. Bahdanau et al.’s attention\n",
    "calculation requires knowledge of the decoder’s state from the previous\n",
    "time step. Also, Luong et al. provides various methods to calculate the\n",
    "attention energies between the encoder output and decoder output which\n",
    "are called “score functions”:\n",
    "\n",
    ".. figure:: /_static/img/chatbot/scores.png\n",
    "   :width: 60%\n",
    "   :align: center\n",
    "   :alt: scores\n",
    "\n",
    "where $h_t$ = current target decoder state and $\\bar{h}_s$ =\n",
    "all encoder states.\n",
    "\n",
    "Overall, the Global attention mechanism can be summarized by the\n",
    "following figure. Note that we will implement the “Attention Layer” as a\n",
    "separate ``nn.Module`` called ``Attn``. The output of this module is a\n",
    "softmax normalized weights tensor of shape *(batch_size, 1,\n",
    "max_length)*.\n",
    "\n",
    ".. figure:: /_static/img/chatbot/global_attn.png\n",
    "   :align: center\n",
    "   :width: 60%\n",
    "   :alt: global_attn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our attention submodule, we can implement the\n",
    "actual decoder model. For the decoder, we will manually feed our batch\n",
    "one time step at a time. This means that our embedded word tensor and\n",
    "GRU output will both have shape *(1, batch_size, hidden_size)*.\n",
    "\n",
    "**Computation Graph:**\n",
    "\n",
    "   1) Get embedding of current input word.\n",
    "   2) Forward through unidirectional GRU.\n",
    "   3) Calculate attention weights from the current GRU output from (2).\n",
    "   4) Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector.\n",
    "   5) Concatenate weighted context vector and GRU output using Luong eq. 5.\n",
    "   6) Predict next word using Luong eq. 6 (without softmax).\n",
    "   7) Return output and final hidden state.\n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "-  ``input_step``: one time step (one word) of input sequence batch;\n",
    "   shape=\\ *(1, batch_size)*\n",
    "-  ``last_hidden``: final hidden layer of GRU; shape=\\ *(n_layers x\n",
    "   num_directions, batch_size, hidden_size)*\n",
    "-  ``encoder_outputs``: encoder model’s output; shape=\\ *(max_length,\n",
    "   batch_size, hidden_size)*\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "-  ``output``: softmax normalized tensor giving probabilities of each\n",
    "   word being the correct next word in the decoded sequence;\n",
    "   shape=\\ *(batch_size, voc.num_words)*\n",
    "-  ``hidden``: final hidden state of GRU; shape=\\ *(n_layers x\n",
    "   num_directions, batch_size, hidden_size)*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Training Procedure\n",
    "-------------------------\n",
    "\n",
    "Masked loss\n",
    "~~~~~~~~~~~\n",
    "\n",
    "Since we are dealing with batches of padded sequences, we cannot simply\n",
    "consider all elements of the tensor when calculating loss. We define\n",
    "``maskNLLLoss`` to calculate our loss based on our decoder’s output\n",
    "tensor, the target tensor, and a binary mask tensor describing the\n",
    "padding of the target tensor. This loss function calculates the average\n",
    "negative log likelihood of the elements that correspond to a *1* in the\n",
    "mask tensor.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single training iteration\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "The ``train`` function contains the algorithm for a single training\n",
    "iteration (a single batch of inputs).\n",
    "\n",
    "We will use a couple of clever tricks to aid in convergence:\n",
    "\n",
    "-  The first trick is using **teacher forcing**. This means that at some\n",
    "   probability, set by ``teacher_forcing_ratio``, we use the current\n",
    "   target word as the decoder’s next input rather than using the\n",
    "   decoder’s current guess. This technique acts as training wheels for\n",
    "   the decoder, aiding in more efficient training. However, teacher\n",
    "   forcing can lead to model instability during inference, as the\n",
    "   decoder may not have a sufficient chance to truly craft its own\n",
    "   output sequences during training. Thus, we must be mindful of how we\n",
    "   are setting the ``teacher_forcing_ratio``, and not be fooled by fast\n",
    "   convergence.\n",
    "\n",
    "-  The second trick that we implement is **gradient clipping**. This is\n",
    "   a commonly used technique for countering the “exploding gradient”\n",
    "   problem. In essence, by clipping or thresholding gradients to a\n",
    "   maximum value, we prevent the gradients from growing exponentially\n",
    "   and either overflow (NaN), or overshoot steep cliffs in the cost\n",
    "   function.\n",
    "\n",
    ".. figure:: /_static/img/chatbot/grad_clip.png\n",
    "   :align: center\n",
    "   :width: 60%\n",
    "   :alt: grad_clip\n",
    "\n",
    "Image source: Goodfellow et al. *Deep Learning*. 2016. https://www.deeplearningbook.org/\n",
    "\n",
    "**Sequence of Operations:**\n",
    "\n",
    "   1) Forward pass entire input batch through encoder.\n",
    "   2) Initialize decoder inputs as SOS_token, and hidden state as the encoder's final hidden state.\n",
    "   3) Forward input batch sequence through decoder one time step at a time.\n",
    "   4) If teacher forcing: set next decoder input as the current target; else: set next decoder input as current decoder output.\n",
    "   5) Calculate and accumulate loss.\n",
    "   6) Perform backpropagation.\n",
    "   7) Clip gradients.\n",
    "   8) Update encoder and decoder model parameters.\n",
    "\n",
    "\n",
    ".. Note ::\n",
    "\n",
    "  PyTorch’s RNN modules (``RNN``, ``LSTM``, ``GRU``) can be used like any\n",
    "  other non-recurrent layers by simply passing them the entire input\n",
    "  sequence (or batch of sequences). We use the ``GRU`` layer like this in\n",
    "  the ``encoder``. The reality is that under the hood, there is an\n",
    "  iterative process looping over each time step calculating hidden states.\n",
    "  Alternatively, you ran run these modules one time-step at a time. In\n",
    "  this case, we manually loop over the sequences during the training\n",
    "  process like we must do for the ``decoder`` model. As long as you\n",
    "  maintain the correct conceptual model of these modules, implementing\n",
    "  sequential models can be very straightforward.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training iterations\n",
    "~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "It is finally time to tie the full training procedure together with the\n",
    "data. The ``trainIters`` function is responsible for running\n",
    "``n_iterations`` of training given the passed models, optimizers, data,\n",
    "etc. This function is quite self explanatory, as we have done the heavy\n",
    "lifting with the ``train`` function.\n",
    "\n",
    "One thing to note is that when we save our model, we save a tarball\n",
    "containing the encoder and decoder state_dicts (parameters), the\n",
    "optimizers’ state_dicts, the loss, the iteration, etc. Saving the model\n",
    "in this way will give us the ultimate flexibility with the checkpoint.\n",
    "After loading a checkpoint, we will be able to use the model parameters\n",
    "to run inference, or we can continue training right where we left off.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            \n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f} Perplexity: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg, np.exp(print_loss_avg)) )\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Evaluation\n",
    "-----------------\n",
    "\n",
    "After training a model, we want to be able to talk to the bot ourselves.\n",
    "First, we must define how we want the model to decode the encoded input.\n",
    "\n",
    "Greedy decoding\n",
    "~~~~~~~~~~~~~~~\n",
    "\n",
    "Greedy decoding is the decoding method that we use during training when\n",
    "we are **NOT** using teacher forcing. In other words, for each time\n",
    "step, we simply choose the word from ``decoder_output`` with the highest\n",
    "softmax value. This decoding method is optimal on a single time-step\n",
    "level.\n",
    "\n",
    "To facilite the greedy decoding operation, we define a\n",
    "``GreedySearchDecoder`` class. When run, an object of this class takes\n",
    "an input sequence (``input_seq``) of shape *(input_seq length, 1)*, a\n",
    "scalar input length (``input_length``) tensor, and a ``max_length`` to\n",
    "bound the response sentence length. The input sentence is evaluated\n",
    "using the following computational graph:\n",
    "\n",
    "**Computation Graph:**\n",
    "\n",
    "   1) Forward input through encoder model.\n",
    "   2) Prepare encoder's final hidden layer to be first hidden input to the decoder.\n",
    "   3) Initialize decoder's first input as SOS_token.\n",
    "   4) Initialize tensors to append decoded words to.\n",
    "   5) Iteratively decode one word token at a time:\n",
    "       a) Forward pass through decoder.\n",
    "       b) Obtain most likely word token and its softmax score.\n",
    "       c) Record token and score.\n",
    "       d) Prepare current token to be next decoder input.\n",
    "   6) Return collections of word tokens and scores.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "            #if decoder_input \n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate my text\n",
    "~~~~~~~~~~~~~~~~\n",
    "\n",
    "Now that we have our decoding method defined, we can write functions for\n",
    "evaluating a string input sentence. The ``evaluate`` function manages\n",
    "the low-level process of handling the input sentence. We first format\n",
    "the sentence as an input batch of word indexes with *batch_size==1*. We\n",
    "do this by converting the words of the sentence to their corresponding\n",
    "indexes, and transposing the dimensions to prepare the tensor for our\n",
    "models. We also create a ``lengths`` tensor which contains the length of\n",
    "our input sentence. In this case, ``lengths`` is scalar because we are\n",
    "only evaluating one sentence at a time (batch_size==1). Next, we obtain\n",
    "the decoded response sentence tensor using our ``GreedySearchDecoder``\n",
    "object (``searcher``). Finally, we convert the response’s indexes to\n",
    "words and return the list of decoded words.\n",
    "\n",
    "``evaluateInput`` acts as the user interface for our chatbot. When\n",
    "called, an input text field will spawn in which we can enter our query\n",
    "sentence. After typing our input sentence and pressing *Enter*, our text\n",
    "is normalized in the same way as our training data, and is ultimately\n",
    "fed to the ``evaluate`` function to obtain a decoded output sentence. We\n",
    "loop this process, so we can keep chatting with our bot until we enter\n",
    "either “q” or “quit”.\n",
    "\n",
    "Finally, if a sentence is entered that contains a word that is not in\n",
    "the vocabulary, we handle this gracefully by printing an error message\n",
    "and prompting the user to enter another sentence.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            final_output = []\n",
    "            for x in output_words:\n",
    "                if not (x == 'EOS' or x == 'PAD'):\n",
    "                    final_output.append(x)\n",
    "                elif (x == 'EOS'):\n",
    "                    break;\n",
    "            output_sentence = ' '.join(final_output)\n",
    "            print('Bot:', ' '.join(output_sentence))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Model\n",
    "---------\n",
    "\n",
    "Finally, it is time to run our model!\n",
    "\n",
    "Regardless of whether we want to train or test the chatbot model, we\n",
    "must initialize the individual encoder and decoder models. In the\n",
    "following block, we set our desired configurations, choose to start from\n",
    "scratch or set a checkpoint to load from, and build and initialize the\n",
    "models. Feel free to play with different model configurations to\n",
    "optimize performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    #print(num_embeddings)\n",
    "    pre_trained = torch.FloatTensor(weights_matrix)\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    #print(emb_layer)\n",
    "    emb_layer.load_state_dict({'weight': pre_trained})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14403"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14403"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 300\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 16\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "#loadFilename = None\n",
    "checkpoint_iter = 2100\n",
    "loadFilename = os.path.join(save_dir, model_name, \"story\",\n",
    "                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "#print(weights_matrix[3])\n",
    "\n",
    "#input = torch.LongTensor([3])\n",
    "#print(emb_layer(input))\n",
    "\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "#else:\n",
    "#    embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Training\n",
    "~~~~~~~~~~~~\n",
    "\n",
    "Run the following block if you want to train the model.\n",
    "\n",
    "First we set training parameters, then we initialize our optimizers, and\n",
    "finally we call the ``trainIters`` function to run our training\n",
    "iterations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 2101; Percent complete: 42.0%; Average loss: 4.6139 Perplexity: 100.8755\n",
      "Iteration: 2102; Percent complete: 42.0%; Average loss: 3.9206 Perplexity: 50.4310\n",
      "Iteration: 2103; Percent complete: 42.1%; Average loss: 4.5169 Perplexity: 91.5535\n",
      "Iteration: 2104; Percent complete: 42.1%; Average loss: 4.2467 Perplexity: 69.8737\n",
      "Iteration: 2105; Percent complete: 42.1%; Average loss: 4.0924 Perplexity: 59.8813\n",
      "Iteration: 2106; Percent complete: 42.1%; Average loss: 4.1306 Perplexity: 62.2142\n",
      "Iteration: 2107; Percent complete: 42.1%; Average loss: 4.2827 Perplexity: 72.4382\n",
      "Iteration: 2108; Percent complete: 42.2%; Average loss: 4.4472 Perplexity: 85.3886\n",
      "Iteration: 2109; Percent complete: 42.2%; Average loss: 4.3505 Perplexity: 77.5166\n",
      "Iteration: 2110; Percent complete: 42.2%; Average loss: 4.0283 Perplexity: 56.1673\n",
      "Iteration: 2111; Percent complete: 42.2%; Average loss: 4.0538 Perplexity: 57.6143\n",
      "Iteration: 2112; Percent complete: 42.2%; Average loss: 4.6543 Perplexity: 105.0363\n",
      "Iteration: 2113; Percent complete: 42.3%; Average loss: 4.2993 Perplexity: 73.6510\n",
      "Iteration: 2114; Percent complete: 42.3%; Average loss: 4.1886 Perplexity: 65.9286\n",
      "Iteration: 2115; Percent complete: 42.3%; Average loss: 4.0440 Perplexity: 57.0550\n",
      "Iteration: 2116; Percent complete: 42.3%; Average loss: 4.3988 Perplexity: 81.3546\n",
      "Iteration: 2117; Percent complete: 42.3%; Average loss: 4.2326 Perplexity: 68.8934\n",
      "Iteration: 2118; Percent complete: 42.4%; Average loss: 4.0764 Perplexity: 58.9356\n",
      "Iteration: 2119; Percent complete: 42.4%; Average loss: 4.1973 Perplexity: 66.5033\n",
      "Iteration: 2120; Percent complete: 42.4%; Average loss: 4.2988 Perplexity: 73.6132\n",
      "Iteration: 2121; Percent complete: 42.4%; Average loss: 3.9846 Perplexity: 53.7620\n",
      "Iteration: 2122; Percent complete: 42.4%; Average loss: 4.3589 Perplexity: 78.1706\n",
      "Iteration: 2123; Percent complete: 42.5%; Average loss: 4.2025 Perplexity: 66.8551\n",
      "Iteration: 2124; Percent complete: 42.5%; Average loss: 4.8021 Perplexity: 121.7705\n",
      "Iteration: 2125; Percent complete: 42.5%; Average loss: 4.4086 Perplexity: 82.1563\n",
      "Iteration: 2126; Percent complete: 42.5%; Average loss: 4.3976 Perplexity: 81.2537\n",
      "Iteration: 2127; Percent complete: 42.5%; Average loss: 4.3927 Perplexity: 80.8604\n",
      "Iteration: 2128; Percent complete: 42.6%; Average loss: 4.2722 Perplexity: 71.6769\n",
      "Iteration: 2129; Percent complete: 42.6%; Average loss: 4.2392 Perplexity: 69.3538\n",
      "Iteration: 2130; Percent complete: 42.6%; Average loss: 4.1719 Perplexity: 64.8370\n",
      "Iteration: 2131; Percent complete: 42.6%; Average loss: 4.0937 Perplexity: 59.9624\n",
      "Iteration: 2132; Percent complete: 42.6%; Average loss: 4.1938 Perplexity: 66.2732\n",
      "Iteration: 2133; Percent complete: 42.7%; Average loss: 3.9946 Perplexity: 54.3061\n",
      "Iteration: 2134; Percent complete: 42.7%; Average loss: 4.3546 Perplexity: 77.8334\n",
      "Iteration: 2135; Percent complete: 42.7%; Average loss: 4.1287 Perplexity: 62.0985\n",
      "Iteration: 2136; Percent complete: 42.7%; Average loss: 4.0427 Perplexity: 56.9795\n",
      "Iteration: 2137; Percent complete: 42.7%; Average loss: 4.1256 Perplexity: 61.9018\n",
      "Iteration: 2138; Percent complete: 42.8%; Average loss: 4.2775 Perplexity: 72.0570\n",
      "Iteration: 2139; Percent complete: 42.8%; Average loss: 4.0771 Perplexity: 58.9771\n",
      "Iteration: 2140; Percent complete: 42.8%; Average loss: 4.7047 Perplexity: 110.4682\n",
      "Iteration: 2141; Percent complete: 42.8%; Average loss: 4.6028 Perplexity: 99.7630\n",
      "Iteration: 2142; Percent complete: 42.8%; Average loss: 4.2026 Perplexity: 66.8586\n",
      "Iteration: 2143; Percent complete: 42.9%; Average loss: 4.0460 Perplexity: 57.1707\n",
      "Iteration: 2144; Percent complete: 42.9%; Average loss: 4.0529 Perplexity: 57.5624\n",
      "Iteration: 2145; Percent complete: 42.9%; Average loss: 4.2899 Perplexity: 72.9559\n",
      "Iteration: 2146; Percent complete: 42.9%; Average loss: 4.1279 Perplexity: 62.0479\n",
      "Iteration: 2147; Percent complete: 42.9%; Average loss: 4.1157 Perplexity: 61.2981\n",
      "Iteration: 2148; Percent complete: 43.0%; Average loss: 3.8915 Perplexity: 48.9823\n",
      "Iteration: 2149; Percent complete: 43.0%; Average loss: 4.2886 Perplexity: 72.8677\n",
      "Iteration: 2150; Percent complete: 43.0%; Average loss: 4.4564 Perplexity: 86.1782\n",
      "Iteration: 2151; Percent complete: 43.0%; Average loss: 4.1974 Perplexity: 66.5140\n",
      "Iteration: 2152; Percent complete: 43.0%; Average loss: 4.1357 Perplexity: 62.5321\n",
      "Iteration: 2153; Percent complete: 43.1%; Average loss: 4.4960 Perplexity: 89.6554\n",
      "Iteration: 2154; Percent complete: 43.1%; Average loss: 4.3166 Perplexity: 74.9333\n",
      "Iteration: 2155; Percent complete: 43.1%; Average loss: 4.2667 Perplexity: 71.2840\n",
      "Iteration: 2156; Percent complete: 43.1%; Average loss: 3.9680 Perplexity: 52.8764\n",
      "Iteration: 2157; Percent complete: 43.1%; Average loss: 3.9896 Perplexity: 54.0324\n",
      "Iteration: 2158; Percent complete: 43.2%; Average loss: 4.6648 Perplexity: 106.1496\n",
      "Iteration: 2159; Percent complete: 43.2%; Average loss: 4.7895 Perplexity: 120.2430\n",
      "Iteration: 2160; Percent complete: 43.2%; Average loss: 4.2459 Perplexity: 69.8180\n",
      "Iteration: 2161; Percent complete: 43.2%; Average loss: 4.2839 Perplexity: 72.5196\n",
      "Iteration: 2162; Percent complete: 43.2%; Average loss: 4.3204 Perplexity: 75.2214\n",
      "Iteration: 2163; Percent complete: 43.3%; Average loss: 4.1707 Perplexity: 64.7611\n",
      "Iteration: 2164; Percent complete: 43.3%; Average loss: 4.0504 Perplexity: 57.4206\n",
      "Iteration: 2165; Percent complete: 43.3%; Average loss: 3.9587 Perplexity: 52.3869\n",
      "Iteration: 2166; Percent complete: 43.3%; Average loss: 4.4588 Perplexity: 86.3872\n",
      "Iteration: 2167; Percent complete: 43.3%; Average loss: 3.9941 Perplexity: 54.2781\n",
      "Iteration: 2168; Percent complete: 43.4%; Average loss: 3.9704 Perplexity: 53.0061\n",
      "Iteration: 2169; Percent complete: 43.4%; Average loss: 4.2901 Perplexity: 72.9753\n",
      "Iteration: 2170; Percent complete: 43.4%; Average loss: 4.5210 Perplexity: 91.9254\n",
      "Iteration: 2171; Percent complete: 43.4%; Average loss: 4.3000 Perplexity: 73.7017\n",
      "Iteration: 2172; Percent complete: 43.4%; Average loss: 4.1578 Perplexity: 63.9327\n",
      "Iteration: 2173; Percent complete: 43.5%; Average loss: 4.0501 Perplexity: 57.4034\n",
      "Iteration: 2174; Percent complete: 43.5%; Average loss: 4.7910 Perplexity: 120.4222\n",
      "Iteration: 2175; Percent complete: 43.5%; Average loss: 3.7737 Perplexity: 43.5392\n",
      "Iteration: 2176; Percent complete: 43.5%; Average loss: 4.0374 Perplexity: 56.6764\n",
      "Iteration: 2177; Percent complete: 43.5%; Average loss: 3.9631 Perplexity: 52.6221\n",
      "Iteration: 2178; Percent complete: 43.6%; Average loss: 4.1805 Perplexity: 65.4010\n",
      "Iteration: 2179; Percent complete: 43.6%; Average loss: 3.8657 Perplexity: 47.7364\n",
      "Iteration: 2180; Percent complete: 43.6%; Average loss: 3.9693 Perplexity: 52.9480\n",
      "Iteration: 2181; Percent complete: 43.6%; Average loss: 4.0294 Perplexity: 56.2247\n",
      "Iteration: 2182; Percent complete: 43.6%; Average loss: 4.5210 Perplexity: 91.9254\n",
      "Iteration: 2183; Percent complete: 43.7%; Average loss: 3.9414 Perplexity: 51.4915\n",
      "Iteration: 2184; Percent complete: 43.7%; Average loss: 4.3311 Perplexity: 76.0266\n",
      "Iteration: 2185; Percent complete: 43.7%; Average loss: 4.4720 Perplexity: 87.5322\n",
      "Iteration: 2186; Percent complete: 43.7%; Average loss: 4.1260 Perplexity: 61.9299\n",
      "Iteration: 2187; Percent complete: 43.7%; Average loss: 4.0923 Perplexity: 59.8760\n",
      "Iteration: 2188; Percent complete: 43.8%; Average loss: 4.0523 Perplexity: 57.5283\n",
      "Iteration: 2189; Percent complete: 43.8%; Average loss: 4.0825 Perplexity: 59.2955\n",
      "Iteration: 2190; Percent complete: 43.8%; Average loss: 3.8904 Perplexity: 48.9325\n",
      "Iteration: 2191; Percent complete: 43.8%; Average loss: 3.9846 Perplexity: 53.7613\n",
      "Iteration: 2192; Percent complete: 43.8%; Average loss: 3.9333 Perplexity: 51.0778\n",
      "Iteration: 2193; Percent complete: 43.9%; Average loss: 4.1764 Perplexity: 65.1329\n",
      "Iteration: 2194; Percent complete: 43.9%; Average loss: 4.3583 Perplexity: 78.1272\n",
      "Iteration: 2195; Percent complete: 43.9%; Average loss: 4.4121 Perplexity: 82.4442\n",
      "Iteration: 2196; Percent complete: 43.9%; Average loss: 4.2279 Perplexity: 68.5700\n",
      "Iteration: 2197; Percent complete: 43.9%; Average loss: 4.2561 Perplexity: 70.5343\n",
      "Iteration: 2198; Percent complete: 44.0%; Average loss: 4.5394 Perplexity: 93.6383\n",
      "Iteration: 2199; Percent complete: 44.0%; Average loss: 4.1770 Perplexity: 65.1726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2200; Percent complete: 44.0%; Average loss: 4.2335 Perplexity: 68.9551\n",
      "Iteration: 2201; Percent complete: 44.0%; Average loss: 4.3623 Perplexity: 78.4389\n",
      "Iteration: 2202; Percent complete: 44.0%; Average loss: 4.3868 Perplexity: 80.3849\n",
      "Iteration: 2203; Percent complete: 44.1%; Average loss: 4.3859 Perplexity: 80.3081\n",
      "Iteration: 2204; Percent complete: 44.1%; Average loss: 4.3219 Perplexity: 75.3298\n",
      "Iteration: 2205; Percent complete: 44.1%; Average loss: 4.3382 Perplexity: 76.5706\n",
      "Iteration: 2206; Percent complete: 44.1%; Average loss: 3.8638 Perplexity: 47.6479\n",
      "Iteration: 2207; Percent complete: 44.1%; Average loss: 4.2834 Perplexity: 72.4895\n",
      "Iteration: 2208; Percent complete: 44.2%; Average loss: 3.9995 Perplexity: 54.5699\n",
      "Iteration: 2209; Percent complete: 44.2%; Average loss: 4.7305 Perplexity: 113.3566\n",
      "Iteration: 2210; Percent complete: 44.2%; Average loss: 4.1685 Perplexity: 64.6192\n",
      "Iteration: 2211; Percent complete: 44.2%; Average loss: 4.2941 Perplexity: 73.2636\n",
      "Iteration: 2212; Percent complete: 44.2%; Average loss: 3.4994 Perplexity: 33.0954\n",
      "Iteration: 2213; Percent complete: 44.3%; Average loss: 4.1873 Perplexity: 65.8420\n",
      "Iteration: 2214; Percent complete: 44.3%; Average loss: 3.9714 Perplexity: 53.0566\n",
      "Iteration: 2215; Percent complete: 44.3%; Average loss: 3.9904 Perplexity: 54.0751\n",
      "Iteration: 2216; Percent complete: 44.3%; Average loss: 4.2574 Perplexity: 70.6280\n",
      "Iteration: 2217; Percent complete: 44.3%; Average loss: 4.2024 Perplexity: 66.8440\n",
      "Iteration: 2218; Percent complete: 44.4%; Average loss: 4.1861 Perplexity: 65.7627\n",
      "Iteration: 2219; Percent complete: 44.4%; Average loss: 4.7753 Perplexity: 118.5457\n",
      "Iteration: 2220; Percent complete: 44.4%; Average loss: 4.4581 Perplexity: 86.3249\n",
      "Iteration: 2221; Percent complete: 44.4%; Average loss: 3.9833 Perplexity: 53.6936\n",
      "Iteration: 2222; Percent complete: 44.4%; Average loss: 4.0047 Perplexity: 54.8532\n",
      "Iteration: 2223; Percent complete: 44.5%; Average loss: 4.0503 Perplexity: 57.4156\n",
      "Iteration: 2224; Percent complete: 44.5%; Average loss: 4.0877 Perplexity: 59.6041\n",
      "Iteration: 2225; Percent complete: 44.5%; Average loss: 4.0281 Perplexity: 56.1524\n",
      "Iteration: 2226; Percent complete: 44.5%; Average loss: 4.3799 Perplexity: 79.8305\n",
      "Iteration: 2227; Percent complete: 44.5%; Average loss: 4.0869 Perplexity: 59.5570\n",
      "Iteration: 2228; Percent complete: 44.6%; Average loss: 4.2398 Perplexity: 69.3964\n",
      "Iteration: 2229; Percent complete: 44.6%; Average loss: 3.6793 Perplexity: 39.6174\n",
      "Iteration: 2230; Percent complete: 44.6%; Average loss: 3.9132 Perplexity: 50.0611\n",
      "Iteration: 2231; Percent complete: 44.6%; Average loss: 4.2613 Perplexity: 70.9053\n",
      "Iteration: 2232; Percent complete: 44.6%; Average loss: 4.6864 Perplexity: 108.4616\n",
      "Iteration: 2233; Percent complete: 44.7%; Average loss: 4.0763 Perplexity: 58.9288\n",
      "Iteration: 2234; Percent complete: 44.7%; Average loss: 4.2830 Perplexity: 72.4555\n",
      "Iteration: 2235; Percent complete: 44.7%; Average loss: 4.1001 Perplexity: 60.3442\n",
      "Iteration: 2236; Percent complete: 44.7%; Average loss: 4.3164 Perplexity: 74.9176\n",
      "Iteration: 2237; Percent complete: 44.7%; Average loss: 4.3607 Perplexity: 78.3148\n",
      "Iteration: 2238; Percent complete: 44.8%; Average loss: 4.2326 Perplexity: 68.8987\n",
      "Iteration: 2239; Percent complete: 44.8%; Average loss: 4.3266 Perplexity: 75.6834\n",
      "Iteration: 2240; Percent complete: 44.8%; Average loss: 4.3059 Perplexity: 74.1376\n",
      "Iteration: 2241; Percent complete: 44.8%; Average loss: 4.0669 Perplexity: 58.3785\n",
      "Iteration: 2242; Percent complete: 44.8%; Average loss: 4.2249 Perplexity: 68.3708\n",
      "Iteration: 2243; Percent complete: 44.9%; Average loss: 4.0413 Perplexity: 56.9028\n",
      "Iteration: 2244; Percent complete: 44.9%; Average loss: 4.4220 Perplexity: 83.2644\n",
      "Iteration: 2245; Percent complete: 44.9%; Average loss: 3.9466 Perplexity: 51.7607\n",
      "Iteration: 2246; Percent complete: 44.9%; Average loss: 3.9929 Perplexity: 54.2134\n",
      "Iteration: 2247; Percent complete: 44.9%; Average loss: 4.3096 Perplexity: 74.4128\n",
      "Iteration: 2248; Percent complete: 45.0%; Average loss: 4.3861 Perplexity: 80.3228\n",
      "Iteration: 2249; Percent complete: 45.0%; Average loss: 4.3720 Perplexity: 79.2034\n",
      "Iteration: 2250; Percent complete: 45.0%; Average loss: 4.3747 Perplexity: 79.4144\n",
      "Iteration: 2251; Percent complete: 45.0%; Average loss: 4.3282 Perplexity: 75.8073\n",
      "Iteration: 2252; Percent complete: 45.0%; Average loss: 4.0798 Perplexity: 59.1346\n",
      "Iteration: 2253; Percent complete: 45.1%; Average loss: 4.0717 Perplexity: 58.6582\n",
      "Iteration: 2254; Percent complete: 45.1%; Average loss: 3.9633 Perplexity: 52.6319\n",
      "Iteration: 2255; Percent complete: 45.1%; Average loss: 4.2352 Perplexity: 69.0744\n",
      "Iteration: 2256; Percent complete: 45.1%; Average loss: 4.0080 Perplexity: 55.0347\n",
      "Iteration: 2257; Percent complete: 45.1%; Average loss: 4.0220 Perplexity: 55.8113\n",
      "Iteration: 2258; Percent complete: 45.2%; Average loss: 4.1183 Perplexity: 61.4554\n",
      "Iteration: 2259; Percent complete: 45.2%; Average loss: 3.6231 Perplexity: 37.4541\n",
      "Iteration: 2260; Percent complete: 45.2%; Average loss: 4.0577 Perplexity: 57.8387\n",
      "Iteration: 2261; Percent complete: 45.2%; Average loss: 4.1426 Perplexity: 62.9678\n",
      "Iteration: 2262; Percent complete: 45.2%; Average loss: 4.3053 Perplexity: 74.0926\n",
      "Iteration: 2263; Percent complete: 45.3%; Average loss: 4.4471 Perplexity: 85.3800\n",
      "Iteration: 2264; Percent complete: 45.3%; Average loss: 4.2536 Perplexity: 70.3571\n",
      "Iteration: 2265; Percent complete: 45.3%; Average loss: 4.4499 Perplexity: 85.6205\n",
      "Iteration: 2266; Percent complete: 45.3%; Average loss: 3.7742 Perplexity: 43.5625\n",
      "Iteration: 2267; Percent complete: 45.3%; Average loss: 4.2646 Perplexity: 71.1380\n",
      "Iteration: 2268; Percent complete: 45.4%; Average loss: 4.2103 Perplexity: 67.3771\n",
      "Iteration: 2269; Percent complete: 45.4%; Average loss: 4.2479 Perplexity: 69.9570\n",
      "Iteration: 2270; Percent complete: 45.4%; Average loss: 4.0776 Perplexity: 59.0022\n",
      "Iteration: 2271; Percent complete: 45.4%; Average loss: 4.4165 Perplexity: 82.8097\n",
      "Iteration: 2272; Percent complete: 45.4%; Average loss: 3.7626 Perplexity: 43.0605\n",
      "Iteration: 2273; Percent complete: 45.5%; Average loss: 4.4044 Perplexity: 81.8101\n",
      "Iteration: 2274; Percent complete: 45.5%; Average loss: 3.9364 Perplexity: 51.2318\n",
      "Iteration: 2275; Percent complete: 45.5%; Average loss: 4.3820 Perplexity: 80.0002\n",
      "Iteration: 2276; Percent complete: 45.5%; Average loss: 4.4151 Perplexity: 82.6918\n",
      "Iteration: 2277; Percent complete: 45.5%; Average loss: 4.2417 Perplexity: 69.5288\n",
      "Iteration: 2278; Percent complete: 45.6%; Average loss: 4.4317 Perplexity: 84.0701\n",
      "Iteration: 2279; Percent complete: 45.6%; Average loss: 4.2554 Perplexity: 70.4876\n",
      "Iteration: 2280; Percent complete: 45.6%; Average loss: 3.9666 Perplexity: 52.8059\n",
      "Iteration: 2281; Percent complete: 45.6%; Average loss: 4.4156 Perplexity: 82.7346\n",
      "Iteration: 2282; Percent complete: 45.6%; Average loss: 4.3385 Perplexity: 76.5913\n",
      "Iteration: 2283; Percent complete: 45.7%; Average loss: 3.6793 Perplexity: 39.6186\n",
      "Iteration: 2284; Percent complete: 45.7%; Average loss: 4.0471 Perplexity: 57.2317\n",
      "Iteration: 2285; Percent complete: 45.7%; Average loss: 3.9407 Perplexity: 51.4568\n",
      "Iteration: 2286; Percent complete: 45.7%; Average loss: 4.1629 Perplexity: 64.2607\n",
      "Iteration: 2287; Percent complete: 45.7%; Average loss: 4.0153 Perplexity: 55.4377\n",
      "Iteration: 2288; Percent complete: 45.8%; Average loss: 4.0217 Perplexity: 55.7971\n",
      "Iteration: 2289; Percent complete: 45.8%; Average loss: 4.1906 Perplexity: 66.0657\n",
      "Iteration: 2290; Percent complete: 45.8%; Average loss: 4.1057 Perplexity: 60.6830\n",
      "Iteration: 2291; Percent complete: 45.8%; Average loss: 4.1516 Perplexity: 63.5384\n",
      "Iteration: 2292; Percent complete: 45.8%; Average loss: 4.3225 Perplexity: 75.3767\n",
      "Iteration: 2293; Percent complete: 45.9%; Average loss: 3.9878 Perplexity: 53.9350\n",
      "Iteration: 2294; Percent complete: 45.9%; Average loss: 4.3327 Perplexity: 76.1486\n",
      "Iteration: 2295; Percent complete: 45.9%; Average loss: 4.3876 Perplexity: 80.4491\n",
      "Iteration: 2296; Percent complete: 45.9%; Average loss: 4.3176 Perplexity: 75.0088\n",
      "Iteration: 2297; Percent complete: 45.9%; Average loss: 4.1366 Perplexity: 62.5868\n",
      "Iteration: 2298; Percent complete: 46.0%; Average loss: 4.2091 Perplexity: 67.2971\n",
      "Iteration: 2299; Percent complete: 46.0%; Average loss: 4.3209 Perplexity: 75.2579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2300; Percent complete: 46.0%; Average loss: 4.3931 Perplexity: 80.8946\n",
      "Iteration: 2301; Percent complete: 46.0%; Average loss: 4.5816 Perplexity: 97.6729\n",
      "Iteration: 2302; Percent complete: 46.0%; Average loss: 3.8930 Perplexity: 49.0593\n",
      "Iteration: 2303; Percent complete: 46.1%; Average loss: 4.0570 Perplexity: 57.7984\n",
      "Iteration: 2304; Percent complete: 46.1%; Average loss: 4.3138 Perplexity: 74.7212\n",
      "Iteration: 2305; Percent complete: 46.1%; Average loss: 4.1170 Perplexity: 61.3759\n",
      "Iteration: 2306; Percent complete: 46.1%; Average loss: 3.6816 Perplexity: 39.7097\n",
      "Iteration: 2307; Percent complete: 46.1%; Average loss: 4.4826 Perplexity: 88.4641\n",
      "Iteration: 2308; Percent complete: 46.2%; Average loss: 3.8087 Perplexity: 45.0937\n",
      "Iteration: 2309; Percent complete: 46.2%; Average loss: 4.1330 Perplexity: 62.3658\n",
      "Iteration: 2310; Percent complete: 46.2%; Average loss: 3.8442 Perplexity: 46.7198\n",
      "Iteration: 2311; Percent complete: 46.2%; Average loss: 4.3496 Perplexity: 77.4455\n",
      "Iteration: 2312; Percent complete: 46.2%; Average loss: 3.9932 Perplexity: 54.2261\n",
      "Iteration: 2313; Percent complete: 46.3%; Average loss: 4.3575 Perplexity: 78.0602\n",
      "Iteration: 2314; Percent complete: 46.3%; Average loss: 4.2633 Perplexity: 71.0451\n",
      "Iteration: 2315; Percent complete: 46.3%; Average loss: 4.0478 Perplexity: 57.2690\n",
      "Iteration: 2316; Percent complete: 46.3%; Average loss: 4.1161 Perplexity: 61.3220\n",
      "Iteration: 2317; Percent complete: 46.3%; Average loss: 4.0854 Perplexity: 59.4645\n",
      "Iteration: 2318; Percent complete: 46.4%; Average loss: 4.0388 Perplexity: 56.7597\n",
      "Iteration: 2319; Percent complete: 46.4%; Average loss: 4.3689 Perplexity: 78.9599\n",
      "Iteration: 2320; Percent complete: 46.4%; Average loss: 4.0492 Perplexity: 57.3514\n",
      "Iteration: 2321; Percent complete: 46.4%; Average loss: 4.2885 Perplexity: 72.8576\n",
      "Iteration: 2322; Percent complete: 46.4%; Average loss: 3.7123 Perplexity: 40.9475\n",
      "Iteration: 2323; Percent complete: 46.5%; Average loss: 3.9687 Perplexity: 52.9145\n",
      "Iteration: 2324; Percent complete: 46.5%; Average loss: 3.9712 Perplexity: 53.0486\n",
      "Iteration: 2325; Percent complete: 46.5%; Average loss: 4.1966 Perplexity: 66.4585\n",
      "Iteration: 2326; Percent complete: 46.5%; Average loss: 3.8018 Perplexity: 44.7826\n",
      "Iteration: 2327; Percent complete: 46.5%; Average loss: 4.0831 Perplexity: 59.3305\n",
      "Iteration: 2328; Percent complete: 46.6%; Average loss: 4.3715 Perplexity: 79.1629\n",
      "Iteration: 2329; Percent complete: 46.6%; Average loss: 4.0069 Perplexity: 54.9774\n",
      "Iteration: 2330; Percent complete: 46.6%; Average loss: 3.9904 Perplexity: 54.0781\n",
      "Iteration: 2331; Percent complete: 46.6%; Average loss: 4.2776 Perplexity: 72.0662\n",
      "Iteration: 2332; Percent complete: 46.6%; Average loss: 4.0680 Perplexity: 58.4416\n",
      "Iteration: 2333; Percent complete: 46.7%; Average loss: 4.4314 Perplexity: 84.0520\n",
      "Iteration: 2334; Percent complete: 46.7%; Average loss: 4.2885 Perplexity: 72.8562\n",
      "Iteration: 2335; Percent complete: 46.7%; Average loss: 4.0768 Perplexity: 58.9550\n",
      "Iteration: 2336; Percent complete: 46.7%; Average loss: 3.6552 Perplexity: 38.6737\n",
      "Iteration: 2337; Percent complete: 46.7%; Average loss: 3.9835 Perplexity: 53.7047\n",
      "Iteration: 2338; Percent complete: 46.8%; Average loss: 4.1790 Perplexity: 65.3030\n",
      "Iteration: 2339; Percent complete: 46.8%; Average loss: 4.4873 Perplexity: 88.8776\n",
      "Iteration: 2340; Percent complete: 46.8%; Average loss: 4.2358 Perplexity: 69.1199\n",
      "Iteration: 2341; Percent complete: 46.8%; Average loss: 4.4218 Perplexity: 83.2448\n",
      "Iteration: 2342; Percent complete: 46.8%; Average loss: 4.6279 Perplexity: 102.2967\n",
      "Iteration: 2343; Percent complete: 46.9%; Average loss: 4.0098 Perplexity: 55.1372\n",
      "Iteration: 2344; Percent complete: 46.9%; Average loss: 3.8880 Perplexity: 48.8115\n",
      "Iteration: 2345; Percent complete: 46.9%; Average loss: 4.2062 Perplexity: 67.0999\n",
      "Iteration: 2346; Percent complete: 46.9%; Average loss: 4.3330 Perplexity: 76.1699\n",
      "Iteration: 2347; Percent complete: 46.9%; Average loss: 4.5531 Perplexity: 94.9307\n",
      "Iteration: 2348; Percent complete: 47.0%; Average loss: 4.0202 Perplexity: 55.7098\n",
      "Iteration: 2349; Percent complete: 47.0%; Average loss: 4.2711 Perplexity: 71.6003\n",
      "Iteration: 2350; Percent complete: 47.0%; Average loss: 4.5734 Perplexity: 96.8681\n",
      "Iteration: 2351; Percent complete: 47.0%; Average loss: 4.3033 Perplexity: 73.9442\n",
      "Iteration: 2352; Percent complete: 47.0%; Average loss: 4.1269 Perplexity: 61.9839\n",
      "Iteration: 2353; Percent complete: 47.1%; Average loss: 4.5002 Perplexity: 90.0391\n",
      "Iteration: 2354; Percent complete: 47.1%; Average loss: 4.1885 Perplexity: 65.9216\n",
      "Iteration: 2355; Percent complete: 47.1%; Average loss: 4.2110 Perplexity: 67.4258\n",
      "Iteration: 2356; Percent complete: 47.1%; Average loss: 4.1797 Perplexity: 65.3455\n",
      "Iteration: 2357; Percent complete: 47.1%; Average loss: 4.3668 Perplexity: 78.7881\n",
      "Iteration: 2358; Percent complete: 47.2%; Average loss: 4.2157 Perplexity: 67.7387\n",
      "Iteration: 2359; Percent complete: 47.2%; Average loss: 3.9165 Perplexity: 50.2247\n",
      "Iteration: 2360; Percent complete: 47.2%; Average loss: 3.8565 Perplexity: 47.2977\n",
      "Iteration: 2361; Percent complete: 47.2%; Average loss: 4.2914 Perplexity: 73.0662\n",
      "Iteration: 2362; Percent complete: 47.2%; Average loss: 4.0418 Perplexity: 56.9314\n",
      "Iteration: 2363; Percent complete: 47.3%; Average loss: 4.0417 Perplexity: 56.9241\n",
      "Iteration: 2364; Percent complete: 47.3%; Average loss: 4.0423 Perplexity: 56.9570\n",
      "Iteration: 2365; Percent complete: 47.3%; Average loss: 3.9871 Perplexity: 53.8966\n",
      "Iteration: 2366; Percent complete: 47.3%; Average loss: 4.3438 Perplexity: 76.9981\n",
      "Iteration: 2367; Percent complete: 47.3%; Average loss: 4.8120 Perplexity: 122.9744\n",
      "Iteration: 2368; Percent complete: 47.4%; Average loss: 3.9302 Perplexity: 50.9192\n",
      "Iteration: 2369; Percent complete: 47.4%; Average loss: 4.2079 Perplexity: 67.2119\n",
      "Iteration: 2370; Percent complete: 47.4%; Average loss: 4.1022 Perplexity: 60.4712\n",
      "Iteration: 2371; Percent complete: 47.4%; Average loss: 4.1518 Perplexity: 63.5484\n",
      "Iteration: 2372; Percent complete: 47.4%; Average loss: 4.2470 Perplexity: 69.8976\n",
      "Iteration: 2373; Percent complete: 47.5%; Average loss: 4.1747 Perplexity: 65.0225\n",
      "Iteration: 2374; Percent complete: 47.5%; Average loss: 4.3733 Perplexity: 79.3069\n",
      "Iteration: 2375; Percent complete: 47.5%; Average loss: 3.9956 Perplexity: 54.3605\n",
      "Iteration: 2376; Percent complete: 47.5%; Average loss: 4.1062 Perplexity: 60.7176\n",
      "Iteration: 2377; Percent complete: 47.5%; Average loss: 4.1696 Perplexity: 64.6909\n",
      "Iteration: 2378; Percent complete: 47.6%; Average loss: 4.0868 Perplexity: 59.5478\n",
      "Iteration: 2379; Percent complete: 47.6%; Average loss: 4.1129 Perplexity: 61.1214\n",
      "Iteration: 2380; Percent complete: 47.6%; Average loss: 4.3555 Perplexity: 77.9090\n",
      "Iteration: 2381; Percent complete: 47.6%; Average loss: 4.0124 Perplexity: 55.2782\n",
      "Iteration: 2382; Percent complete: 47.6%; Average loss: 4.3150 Perplexity: 74.8121\n",
      "Iteration: 2383; Percent complete: 47.7%; Average loss: 4.1877 Perplexity: 65.8690\n",
      "Iteration: 2384; Percent complete: 47.7%; Average loss: 4.1120 Perplexity: 61.0716\n",
      "Iteration: 2385; Percent complete: 47.7%; Average loss: 4.1568 Perplexity: 63.8649\n",
      "Iteration: 2386; Percent complete: 47.7%; Average loss: 3.9155 Perplexity: 50.1764\n",
      "Iteration: 2387; Percent complete: 47.7%; Average loss: 4.2315 Perplexity: 68.8226\n",
      "Iteration: 2388; Percent complete: 47.8%; Average loss: 4.0992 Perplexity: 60.2950\n",
      "Iteration: 2389; Percent complete: 47.8%; Average loss: 4.0170 Perplexity: 55.5324\n",
      "Iteration: 2390; Percent complete: 47.8%; Average loss: 4.5846 Perplexity: 97.9632\n",
      "Iteration: 2391; Percent complete: 47.8%; Average loss: 4.0151 Perplexity: 55.4287\n",
      "Iteration: 2392; Percent complete: 47.8%; Average loss: 4.2094 Perplexity: 67.3155\n",
      "Iteration: 2393; Percent complete: 47.9%; Average loss: 3.7672 Perplexity: 43.2600\n",
      "Iteration: 2394; Percent complete: 47.9%; Average loss: 4.4092 Perplexity: 82.1996\n",
      "Iteration: 2395; Percent complete: 47.9%; Average loss: 4.3891 Perplexity: 80.5715\n",
      "Iteration: 2396; Percent complete: 47.9%; Average loss: 4.2973 Perplexity: 73.5042\n",
      "Iteration: 2397; Percent complete: 47.9%; Average loss: 3.9354 Perplexity: 51.1827\n",
      "Iteration: 2398; Percent complete: 48.0%; Average loss: 4.3195 Perplexity: 75.1479\n",
      "Iteration: 2399; Percent complete: 48.0%; Average loss: 4.0896 Perplexity: 59.7142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2400; Percent complete: 48.0%; Average loss: 4.2904 Perplexity: 72.9930\n",
      "Iteration: 2401; Percent complete: 48.0%; Average loss: 4.2855 Perplexity: 72.6386\n",
      "Iteration: 2402; Percent complete: 48.0%; Average loss: 4.1375 Perplexity: 62.6483\n",
      "Iteration: 2403; Percent complete: 48.1%; Average loss: 3.8070 Perplexity: 45.0162\n",
      "Iteration: 2404; Percent complete: 48.1%; Average loss: 4.5511 Perplexity: 94.7400\n",
      "Iteration: 2405; Percent complete: 48.1%; Average loss: 4.2540 Perplexity: 70.3891\n",
      "Iteration: 2406; Percent complete: 48.1%; Average loss: 4.2899 Perplexity: 72.9604\n",
      "Iteration: 2407; Percent complete: 48.1%; Average loss: 4.2413 Perplexity: 69.4951\n",
      "Iteration: 2408; Percent complete: 48.2%; Average loss: 4.0610 Perplexity: 58.0348\n",
      "Iteration: 2409; Percent complete: 48.2%; Average loss: 4.1283 Perplexity: 62.0746\n",
      "Iteration: 2410; Percent complete: 48.2%; Average loss: 4.0058 Perplexity: 54.9164\n",
      "Iteration: 2411; Percent complete: 48.2%; Average loss: 3.8142 Perplexity: 45.3423\n",
      "Iteration: 2412; Percent complete: 48.2%; Average loss: 4.0861 Perplexity: 59.5072\n",
      "Iteration: 2413; Percent complete: 48.3%; Average loss: 4.1476 Perplexity: 63.2793\n",
      "Iteration: 2414; Percent complete: 48.3%; Average loss: 4.0257 Perplexity: 56.0214\n",
      "Iteration: 2415; Percent complete: 48.3%; Average loss: 4.0308 Perplexity: 56.3056\n",
      "Iteration: 2416; Percent complete: 48.3%; Average loss: 3.9617 Perplexity: 52.5468\n",
      "Iteration: 2417; Percent complete: 48.3%; Average loss: 3.8472 Perplexity: 46.8635\n",
      "Iteration: 2418; Percent complete: 48.4%; Average loss: 3.9594 Perplexity: 52.4284\n",
      "Iteration: 2419; Percent complete: 48.4%; Average loss: 4.2905 Perplexity: 73.0006\n",
      "Iteration: 2420; Percent complete: 48.4%; Average loss: 3.9788 Perplexity: 53.4547\n",
      "Iteration: 2421; Percent complete: 48.4%; Average loss: 3.9150 Perplexity: 50.1508\n",
      "Iteration: 2422; Percent complete: 48.4%; Average loss: 4.5381 Perplexity: 93.5141\n",
      "Iteration: 2423; Percent complete: 48.5%; Average loss: 3.8744 Perplexity: 48.1558\n",
      "Iteration: 2424; Percent complete: 48.5%; Average loss: 4.1294 Perplexity: 62.1406\n",
      "Iteration: 2425; Percent complete: 48.5%; Average loss: 3.8809 Perplexity: 48.4655\n",
      "Iteration: 2426; Percent complete: 48.5%; Average loss: 4.5583 Perplexity: 95.4240\n",
      "Iteration: 2427; Percent complete: 48.5%; Average loss: 3.7547 Perplexity: 42.7232\n",
      "Iteration: 2428; Percent complete: 48.6%; Average loss: 3.8266 Perplexity: 45.9081\n",
      "Iteration: 2429; Percent complete: 48.6%; Average loss: 4.1495 Perplexity: 63.4001\n",
      "Iteration: 2430; Percent complete: 48.6%; Average loss: 3.7684 Perplexity: 43.3118\n",
      "Iteration: 2431; Percent complete: 48.6%; Average loss: 4.2515 Perplexity: 70.2111\n",
      "Iteration: 2432; Percent complete: 48.6%; Average loss: 3.9278 Perplexity: 50.7941\n",
      "Iteration: 2433; Percent complete: 48.7%; Average loss: 3.9870 Perplexity: 53.8945\n",
      "Iteration: 2434; Percent complete: 48.7%; Average loss: 4.4605 Perplexity: 86.5295\n",
      "Iteration: 2435; Percent complete: 48.7%; Average loss: 3.9937 Perplexity: 54.2545\n",
      "Iteration: 2436; Percent complete: 48.7%; Average loss: 4.0720 Perplexity: 58.6760\n",
      "Iteration: 2437; Percent complete: 48.7%; Average loss: 3.8874 Perplexity: 48.7847\n",
      "Iteration: 2438; Percent complete: 48.8%; Average loss: 3.8883 Perplexity: 48.8255\n",
      "Iteration: 2439; Percent complete: 48.8%; Average loss: 4.0177 Perplexity: 55.5711\n",
      "Iteration: 2440; Percent complete: 48.8%; Average loss: 4.3105 Perplexity: 74.4800\n",
      "Iteration: 2441; Percent complete: 48.8%; Average loss: 3.9459 Perplexity: 51.7215\n",
      "Iteration: 2442; Percent complete: 48.8%; Average loss: 3.6962 Perplexity: 40.2943\n",
      "Iteration: 2443; Percent complete: 48.9%; Average loss: 4.1249 Perplexity: 61.8609\n",
      "Iteration: 2444; Percent complete: 48.9%; Average loss: 4.4669 Perplexity: 87.0903\n",
      "Iteration: 2445; Percent complete: 48.9%; Average loss: 3.7627 Perplexity: 43.0646\n",
      "Iteration: 2446; Percent complete: 48.9%; Average loss: 4.0872 Perplexity: 59.5718\n",
      "Iteration: 2447; Percent complete: 48.9%; Average loss: 4.3360 Perplexity: 76.4017\n",
      "Iteration: 2448; Percent complete: 49.0%; Average loss: 4.2747 Perplexity: 71.8615\n",
      "Iteration: 2449; Percent complete: 49.0%; Average loss: 4.1290 Perplexity: 62.1175\n",
      "Iteration: 2450; Percent complete: 49.0%; Average loss: 3.8575 Perplexity: 47.3446\n",
      "Iteration: 2451; Percent complete: 49.0%; Average loss: 4.1210 Perplexity: 61.6180\n",
      "Iteration: 2452; Percent complete: 49.0%; Average loss: 3.9461 Perplexity: 51.7335\n",
      "Iteration: 2453; Percent complete: 49.1%; Average loss: 3.9649 Perplexity: 52.7162\n",
      "Iteration: 2454; Percent complete: 49.1%; Average loss: 4.2919 Perplexity: 73.1028\n",
      "Iteration: 2455; Percent complete: 49.1%; Average loss: 3.9606 Perplexity: 52.4876\n",
      "Iteration: 2456; Percent complete: 49.1%; Average loss: 4.1269 Perplexity: 61.9858\n",
      "Iteration: 2457; Percent complete: 49.1%; Average loss: 4.2094 Perplexity: 67.3133\n",
      "Iteration: 2458; Percent complete: 49.2%; Average loss: 3.8793 Perplexity: 48.3896\n",
      "Iteration: 2459; Percent complete: 49.2%; Average loss: 4.1331 Perplexity: 62.3726\n",
      "Iteration: 2460; Percent complete: 49.2%; Average loss: 3.9092 Perplexity: 49.8596\n",
      "Iteration: 2461; Percent complete: 49.2%; Average loss: 3.9268 Perplexity: 50.7423\n",
      "Iteration: 2462; Percent complete: 49.2%; Average loss: 4.0076 Perplexity: 55.0129\n",
      "Iteration: 2463; Percent complete: 49.3%; Average loss: 4.0759 Perplexity: 58.9012\n",
      "Iteration: 2464; Percent complete: 49.3%; Average loss: 4.0655 Perplexity: 58.2948\n",
      "Iteration: 2465; Percent complete: 49.3%; Average loss: 4.3244 Perplexity: 75.5202\n",
      "Iteration: 2466; Percent complete: 49.3%; Average loss: 4.0706 Perplexity: 58.5928\n",
      "Iteration: 2467; Percent complete: 49.3%; Average loss: 3.9303 Perplexity: 50.9247\n",
      "Iteration: 2468; Percent complete: 49.4%; Average loss: 4.3369 Perplexity: 76.4736\n",
      "Iteration: 2469; Percent complete: 49.4%; Average loss: 4.1578 Perplexity: 63.9298\n",
      "Iteration: 2470; Percent complete: 49.4%; Average loss: 3.8310 Perplexity: 46.1071\n",
      "Iteration: 2471; Percent complete: 49.4%; Average loss: 4.1567 Perplexity: 63.8575\n",
      "Iteration: 2472; Percent complete: 49.4%; Average loss: 4.0977 Perplexity: 60.2016\n",
      "Iteration: 2473; Percent complete: 49.5%; Average loss: 4.2992 Perplexity: 73.6421\n",
      "Iteration: 2474; Percent complete: 49.5%; Average loss: 4.5994 Perplexity: 99.4201\n",
      "Iteration: 2475; Percent complete: 49.5%; Average loss: 4.1760 Perplexity: 65.1019\n",
      "Iteration: 2476; Percent complete: 49.5%; Average loss: 3.9777 Perplexity: 53.3920\n",
      "Iteration: 2477; Percent complete: 49.5%; Average loss: 4.0828 Perplexity: 59.3125\n",
      "Iteration: 2478; Percent complete: 49.6%; Average loss: 4.5140 Perplexity: 91.2851\n",
      "Iteration: 2479; Percent complete: 49.6%; Average loss: 3.7857 Perplexity: 44.0647\n",
      "Iteration: 2480; Percent complete: 49.6%; Average loss: 4.0638 Perplexity: 58.1940\n",
      "Iteration: 2481; Percent complete: 49.6%; Average loss: 4.3909 Perplexity: 80.7091\n",
      "Iteration: 2482; Percent complete: 49.6%; Average loss: 4.0677 Perplexity: 58.4247\n",
      "Iteration: 2483; Percent complete: 49.7%; Average loss: 4.0734 Perplexity: 58.7542\n",
      "Iteration: 2484; Percent complete: 49.7%; Average loss: 3.9301 Perplexity: 50.9144\n",
      "Iteration: 2485; Percent complete: 49.7%; Average loss: 3.6451 Perplexity: 38.2865\n",
      "Iteration: 2486; Percent complete: 49.7%; Average loss: 3.8667 Perplexity: 47.7847\n",
      "Iteration: 2487; Percent complete: 49.7%; Average loss: 3.9684 Perplexity: 52.9005\n",
      "Iteration: 2488; Percent complete: 49.8%; Average loss: 4.1227 Perplexity: 61.7238\n",
      "Iteration: 2489; Percent complete: 49.8%; Average loss: 4.4601 Perplexity: 86.4972\n",
      "Iteration: 2490; Percent complete: 49.8%; Average loss: 4.0136 Perplexity: 55.3479\n",
      "Iteration: 2491; Percent complete: 49.8%; Average loss: 4.0475 Perplexity: 57.2521\n",
      "Iteration: 2492; Percent complete: 49.8%; Average loss: 4.2936 Perplexity: 73.2307\n",
      "Iteration: 2493; Percent complete: 49.9%; Average loss: 3.7947 Perplexity: 44.4666\n",
      "Iteration: 2494; Percent complete: 49.9%; Average loss: 4.2511 Perplexity: 70.1833\n",
      "Iteration: 2495; Percent complete: 49.9%; Average loss: 3.9765 Perplexity: 53.3291\n",
      "Iteration: 2496; Percent complete: 49.9%; Average loss: 4.1983 Perplexity: 66.5742\n",
      "Iteration: 2497; Percent complete: 49.9%; Average loss: 4.3407 Perplexity: 76.7586\n",
      "Iteration: 2498; Percent complete: 50.0%; Average loss: 3.8172 Perplexity: 45.4768\n",
      "Iteration: 2499; Percent complete: 50.0%; Average loss: 4.3042 Perplexity: 74.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2500; Percent complete: 50.0%; Average loss: 3.9143 Perplexity: 50.1149\n",
      "Iteration: 2501; Percent complete: 50.0%; Average loss: 4.1739 Perplexity: 64.9670\n",
      "Iteration: 2502; Percent complete: 50.0%; Average loss: 3.8470 Perplexity: 46.8535\n",
      "Iteration: 2503; Percent complete: 50.1%; Average loss: 4.6012 Perplexity: 99.6012\n",
      "Iteration: 2504; Percent complete: 50.1%; Average loss: 3.6830 Perplexity: 39.7664\n",
      "Iteration: 2505; Percent complete: 50.1%; Average loss: 4.5936 Perplexity: 98.8514\n",
      "Iteration: 2506; Percent complete: 50.1%; Average loss: 3.8748 Perplexity: 48.1713\n",
      "Iteration: 2507; Percent complete: 50.1%; Average loss: 4.1788 Perplexity: 65.2884\n",
      "Iteration: 2508; Percent complete: 50.2%; Average loss: 3.4364 Perplexity: 31.0749\n",
      "Iteration: 2509; Percent complete: 50.2%; Average loss: 4.1257 Perplexity: 61.9085\n",
      "Iteration: 2510; Percent complete: 50.2%; Average loss: 4.2109 Perplexity: 67.4158\n",
      "Iteration: 2511; Percent complete: 50.2%; Average loss: 4.1982 Perplexity: 66.5640\n",
      "Iteration: 2512; Percent complete: 50.2%; Average loss: 4.1043 Perplexity: 60.6023\n",
      "Iteration: 2513; Percent complete: 50.3%; Average loss: 4.1502 Perplexity: 63.4481\n",
      "Iteration: 2514; Percent complete: 50.3%; Average loss: 3.6579 Perplexity: 38.7805\n",
      "Iteration: 2515; Percent complete: 50.3%; Average loss: 4.1064 Perplexity: 60.7285\n",
      "Iteration: 2516; Percent complete: 50.3%; Average loss: 4.1561 Perplexity: 63.8252\n",
      "Iteration: 2517; Percent complete: 50.3%; Average loss: 3.8867 Perplexity: 48.7496\n",
      "Iteration: 2518; Percent complete: 50.4%; Average loss: 3.8410 Perplexity: 46.5724\n",
      "Iteration: 2519; Percent complete: 50.4%; Average loss: 4.1969 Perplexity: 66.4831\n",
      "Iteration: 2520; Percent complete: 50.4%; Average loss: 3.8775 Perplexity: 48.3023\n",
      "Iteration: 2521; Percent complete: 50.4%; Average loss: 4.0735 Perplexity: 58.7636\n",
      "Iteration: 2522; Percent complete: 50.4%; Average loss: 3.8707 Perplexity: 47.9766\n",
      "Iteration: 2523; Percent complete: 50.5%; Average loss: 4.1332 Perplexity: 62.3775\n",
      "Iteration: 2524; Percent complete: 50.5%; Average loss: 3.8469 Perplexity: 46.8499\n",
      "Iteration: 2525; Percent complete: 50.5%; Average loss: 4.1727 Perplexity: 64.8890\n",
      "Iteration: 2526; Percent complete: 50.5%; Average loss: 3.8876 Perplexity: 48.7940\n",
      "Iteration: 2527; Percent complete: 50.5%; Average loss: 3.7529 Perplexity: 42.6435\n",
      "Iteration: 2528; Percent complete: 50.6%; Average loss: 4.2873 Perplexity: 72.7717\n",
      "Iteration: 2529; Percent complete: 50.6%; Average loss: 3.7598 Perplexity: 42.9418\n",
      "Iteration: 2530; Percent complete: 50.6%; Average loss: 4.2832 Perplexity: 72.4733\n",
      "Iteration: 2531; Percent complete: 50.6%; Average loss: 4.1332 Perplexity: 62.3798\n",
      "Iteration: 2532; Percent complete: 50.6%; Average loss: 4.0516 Perplexity: 57.4886\n",
      "Iteration: 2533; Percent complete: 50.7%; Average loss: 3.8669 Perplexity: 47.7962\n",
      "Iteration: 2534; Percent complete: 50.7%; Average loss: 3.9213 Perplexity: 50.4658\n",
      "Iteration: 2535; Percent complete: 50.7%; Average loss: 3.9832 Perplexity: 53.6886\n",
      "Iteration: 2536; Percent complete: 50.7%; Average loss: 4.2596 Perplexity: 70.7819\n",
      "Iteration: 2537; Percent complete: 50.7%; Average loss: 3.9850 Perplexity: 53.7866\n",
      "Iteration: 2538; Percent complete: 50.8%; Average loss: 4.0716 Perplexity: 58.6501\n",
      "Iteration: 2539; Percent complete: 50.8%; Average loss: 4.0556 Perplexity: 57.7210\n",
      "Iteration: 2540; Percent complete: 50.8%; Average loss: 3.7629 Perplexity: 43.0728\n",
      "Iteration: 2541; Percent complete: 50.8%; Average loss: 4.0563 Perplexity: 57.7599\n",
      "Iteration: 2542; Percent complete: 50.8%; Average loss: 4.0412 Perplexity: 56.8957\n",
      "Iteration: 2543; Percent complete: 50.9%; Average loss: 4.1922 Perplexity: 66.1650\n",
      "Iteration: 2544; Percent complete: 50.9%; Average loss: 3.9941 Perplexity: 54.2779\n",
      "Iteration: 2545; Percent complete: 50.9%; Average loss: 3.7661 Perplexity: 43.2131\n",
      "Iteration: 2546; Percent complete: 50.9%; Average loss: 3.8798 Perplexity: 48.4138\n",
      "Iteration: 2547; Percent complete: 50.9%; Average loss: 4.0516 Perplexity: 57.4884\n",
      "Iteration: 2548; Percent complete: 51.0%; Average loss: 4.1798 Perplexity: 65.3551\n",
      "Iteration: 2549; Percent complete: 51.0%; Average loss: 4.1462 Perplexity: 63.1913\n",
      "Iteration: 2550; Percent complete: 51.0%; Average loss: 4.0405 Perplexity: 56.8528\n",
      "Iteration: 2551; Percent complete: 51.0%; Average loss: 4.0985 Perplexity: 60.2500\n",
      "Iteration: 2552; Percent complete: 51.0%; Average loss: 3.8409 Perplexity: 46.5681\n",
      "Iteration: 2553; Percent complete: 51.1%; Average loss: 3.9065 Perplexity: 49.7223\n",
      "Iteration: 2554; Percent complete: 51.1%; Average loss: 3.9772 Perplexity: 53.3698\n",
      "Iteration: 2555; Percent complete: 51.1%; Average loss: 4.1887 Perplexity: 65.9385\n",
      "Iteration: 2556; Percent complete: 51.1%; Average loss: 4.8192 Perplexity: 123.8641\n",
      "Iteration: 2557; Percent complete: 51.1%; Average loss: 4.2246 Perplexity: 68.3503\n",
      "Iteration: 2558; Percent complete: 51.2%; Average loss: 4.4380 Perplexity: 84.6088\n",
      "Iteration: 2559; Percent complete: 51.2%; Average loss: 3.9857 Perplexity: 53.8236\n",
      "Iteration: 2560; Percent complete: 51.2%; Average loss: 4.1526 Perplexity: 63.5976\n",
      "Iteration: 2561; Percent complete: 51.2%; Average loss: 3.6953 Perplexity: 40.2559\n",
      "Iteration: 2562; Percent complete: 51.2%; Average loss: 3.7464 Perplexity: 42.3704\n",
      "Iteration: 2563; Percent complete: 51.3%; Average loss: 4.0784 Perplexity: 59.0493\n",
      "Iteration: 2564; Percent complete: 51.3%; Average loss: 4.3836 Perplexity: 80.1299\n",
      "Iteration: 2565; Percent complete: 51.3%; Average loss: 4.2625 Perplexity: 70.9873\n",
      "Iteration: 2566; Percent complete: 51.3%; Average loss: 3.9497 Perplexity: 51.9216\n",
      "Iteration: 2567; Percent complete: 51.3%; Average loss: 4.1625 Perplexity: 64.2344\n",
      "Iteration: 2568; Percent complete: 51.4%; Average loss: 3.9640 Perplexity: 52.6665\n",
      "Iteration: 2569; Percent complete: 51.4%; Average loss: 3.9563 Perplexity: 52.2629\n",
      "Iteration: 2570; Percent complete: 51.4%; Average loss: 3.8563 Perplexity: 47.2923\n",
      "Iteration: 2571; Percent complete: 51.4%; Average loss: 3.8058 Perplexity: 44.9609\n",
      "Iteration: 2572; Percent complete: 51.4%; Average loss: 3.7462 Perplexity: 42.3613\n",
      "Iteration: 2573; Percent complete: 51.5%; Average loss: 3.6876 Perplexity: 39.9475\n",
      "Iteration: 2574; Percent complete: 51.5%; Average loss: 4.1979 Perplexity: 66.5477\n",
      "Iteration: 2575; Percent complete: 51.5%; Average loss: 3.8522 Perplexity: 47.0969\n",
      "Iteration: 2576; Percent complete: 51.5%; Average loss: 4.2658 Perplexity: 71.2194\n",
      "Iteration: 2577; Percent complete: 51.5%; Average loss: 4.3192 Perplexity: 75.1249\n",
      "Iteration: 2578; Percent complete: 51.6%; Average loss: 4.2096 Perplexity: 67.3319\n",
      "Iteration: 2579; Percent complete: 51.6%; Average loss: 4.1009 Perplexity: 60.3931\n",
      "Iteration: 2580; Percent complete: 51.6%; Average loss: 4.1603 Perplexity: 64.0919\n",
      "Iteration: 2581; Percent complete: 51.6%; Average loss: 3.5534 Perplexity: 34.9327\n",
      "Iteration: 2582; Percent complete: 51.6%; Average loss: 3.9233 Perplexity: 50.5681\n",
      "Iteration: 2583; Percent complete: 51.7%; Average loss: 4.1296 Perplexity: 62.1503\n",
      "Iteration: 2584; Percent complete: 51.7%; Average loss: 3.8986 Perplexity: 49.3346\n",
      "Iteration: 2585; Percent complete: 51.7%; Average loss: 3.9722 Perplexity: 53.1026\n",
      "Iteration: 2586; Percent complete: 51.7%; Average loss: 4.1042 Perplexity: 60.5933\n",
      "Iteration: 2587; Percent complete: 51.7%; Average loss: 3.9196 Perplexity: 50.3803\n",
      "Iteration: 2588; Percent complete: 51.8%; Average loss: 4.3790 Perplexity: 79.7592\n",
      "Iteration: 2589; Percent complete: 51.8%; Average loss: 4.2636 Perplexity: 71.0675\n",
      "Iteration: 2590; Percent complete: 51.8%; Average loss: 4.3732 Perplexity: 79.2994\n",
      "Iteration: 2591; Percent complete: 51.8%; Average loss: 4.1848 Perplexity: 65.6836\n",
      "Iteration: 2592; Percent complete: 51.8%; Average loss: 4.0191 Perplexity: 55.6506\n",
      "Iteration: 2593; Percent complete: 51.9%; Average loss: 4.2289 Perplexity: 68.6451\n",
      "Iteration: 2594; Percent complete: 51.9%; Average loss: 3.6523 Perplexity: 38.5630\n",
      "Iteration: 2595; Percent complete: 51.9%; Average loss: 4.2047 Perplexity: 67.0034\n",
      "Iteration: 2596; Percent complete: 51.9%; Average loss: 3.9816 Perplexity: 53.6046\n",
      "Iteration: 2597; Percent complete: 51.9%; Average loss: 3.8265 Perplexity: 45.9008\n",
      "Iteration: 2598; Percent complete: 52.0%; Average loss: 4.3320 Perplexity: 76.0959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2599; Percent complete: 52.0%; Average loss: 3.7435 Perplexity: 42.2472\n",
      "Iteration: 2600; Percent complete: 52.0%; Average loss: 4.0145 Perplexity: 55.3937\n",
      "Iteration: 2601; Percent complete: 52.0%; Average loss: 4.0584 Perplexity: 57.8844\n",
      "Iteration: 2602; Percent complete: 52.0%; Average loss: 3.9258 Perplexity: 50.6920\n",
      "Iteration: 2603; Percent complete: 52.1%; Average loss: 4.1688 Perplexity: 64.6350\n",
      "Iteration: 2604; Percent complete: 52.1%; Average loss: 3.8380 Perplexity: 46.4323\n",
      "Iteration: 2605; Percent complete: 52.1%; Average loss: 4.0221 Perplexity: 55.8158\n",
      "Iteration: 2606; Percent complete: 52.1%; Average loss: 4.1046 Perplexity: 60.6200\n",
      "Iteration: 2607; Percent complete: 52.1%; Average loss: 4.0605 Perplexity: 58.0052\n",
      "Iteration: 2608; Percent complete: 52.2%; Average loss: 4.1105 Perplexity: 60.9758\n",
      "Iteration: 2609; Percent complete: 52.2%; Average loss: 4.3221 Perplexity: 75.3456\n",
      "Iteration: 2610; Percent complete: 52.2%; Average loss: 3.9749 Perplexity: 53.2433\n",
      "Iteration: 2611; Percent complete: 52.2%; Average loss: 4.1588 Perplexity: 63.9974\n",
      "Iteration: 2612; Percent complete: 52.2%; Average loss: 4.1944 Perplexity: 66.3120\n",
      "Iteration: 2613; Percent complete: 52.3%; Average loss: 4.3129 Perplexity: 74.6534\n",
      "Iteration: 2614; Percent complete: 52.3%; Average loss: 4.0433 Perplexity: 57.0156\n",
      "Iteration: 2615; Percent complete: 52.3%; Average loss: 4.0260 Perplexity: 56.0389\n",
      "Iteration: 2616; Percent complete: 52.3%; Average loss: 4.2964 Perplexity: 73.4354\n",
      "Iteration: 2617; Percent complete: 52.3%; Average loss: 3.5409 Perplexity: 34.4972\n",
      "Iteration: 2618; Percent complete: 52.4%; Average loss: 4.3397 Perplexity: 76.6810\n",
      "Iteration: 2619; Percent complete: 52.4%; Average loss: 4.1417 Perplexity: 62.9113\n",
      "Iteration: 2620; Percent complete: 52.4%; Average loss: 3.5726 Perplexity: 35.6080\n",
      "Iteration: 2621; Percent complete: 52.4%; Average loss: 3.7427 Perplexity: 42.2113\n",
      "Iteration: 2622; Percent complete: 52.4%; Average loss: 4.0092 Perplexity: 55.1046\n",
      "Iteration: 2623; Percent complete: 52.5%; Average loss: 4.0678 Perplexity: 58.4288\n",
      "Iteration: 2624; Percent complete: 52.5%; Average loss: 4.0686 Perplexity: 58.4772\n",
      "Iteration: 2625; Percent complete: 52.5%; Average loss: 3.8451 Perplexity: 46.7624\n",
      "Iteration: 2626; Percent complete: 52.5%; Average loss: 3.6964 Perplexity: 40.3011\n",
      "Iteration: 2627; Percent complete: 52.5%; Average loss: 3.8444 Perplexity: 46.7306\n",
      "Iteration: 2628; Percent complete: 52.6%; Average loss: 3.5473 Perplexity: 34.7177\n",
      "Iteration: 2629; Percent complete: 52.6%; Average loss: 3.7148 Perplexity: 41.0523\n",
      "Iteration: 2630; Percent complete: 52.6%; Average loss: 4.0610 Perplexity: 58.0350\n",
      "Iteration: 2631; Percent complete: 52.6%; Average loss: 4.2375 Perplexity: 69.2374\n",
      "Iteration: 2632; Percent complete: 52.6%; Average loss: 4.1559 Perplexity: 63.8074\n",
      "Iteration: 2633; Percent complete: 52.7%; Average loss: 3.9006 Perplexity: 49.4305\n",
      "Iteration: 2634; Percent complete: 52.7%; Average loss: 4.6662 Perplexity: 106.2962\n",
      "Iteration: 2635; Percent complete: 52.7%; Average loss: 4.0963 Perplexity: 60.1158\n",
      "Iteration: 2636; Percent complete: 52.7%; Average loss: 3.7775 Perplexity: 43.7070\n",
      "Iteration: 2637; Percent complete: 52.7%; Average loss: 4.0366 Perplexity: 56.6315\n",
      "Iteration: 2638; Percent complete: 52.8%; Average loss: 3.8255 Perplexity: 45.8554\n",
      "Iteration: 2639; Percent complete: 52.8%; Average loss: 3.8467 Perplexity: 46.8387\n",
      "Iteration: 2640; Percent complete: 52.8%; Average loss: 4.0254 Perplexity: 56.0012\n",
      "Iteration: 2641; Percent complete: 52.8%; Average loss: 3.8938 Perplexity: 49.0971\n",
      "Iteration: 2642; Percent complete: 52.8%; Average loss: 4.2053 Perplexity: 67.0403\n",
      "Iteration: 2643; Percent complete: 52.9%; Average loss: 4.2794 Perplexity: 72.1971\n",
      "Iteration: 2644; Percent complete: 52.9%; Average loss: 3.8902 Perplexity: 48.9191\n",
      "Iteration: 2645; Percent complete: 52.9%; Average loss: 4.0031 Perplexity: 54.7700\n",
      "Iteration: 2646; Percent complete: 52.9%; Average loss: 4.2765 Perplexity: 71.9884\n",
      "Iteration: 2647; Percent complete: 52.9%; Average loss: 4.4280 Perplexity: 83.7606\n",
      "Iteration: 2648; Percent complete: 53.0%; Average loss: 4.4318 Perplexity: 84.0810\n",
      "Iteration: 2649; Percent complete: 53.0%; Average loss: 4.0022 Perplexity: 54.7191\n",
      "Iteration: 2650; Percent complete: 53.0%; Average loss: 3.8367 Perplexity: 46.3712\n",
      "Iteration: 2651; Percent complete: 53.0%; Average loss: 4.1033 Perplexity: 60.5397\n",
      "Iteration: 2652; Percent complete: 53.0%; Average loss: 4.2456 Perplexity: 69.7992\n",
      "Iteration: 2653; Percent complete: 53.1%; Average loss: 4.1395 Perplexity: 62.7734\n",
      "Iteration: 2654; Percent complete: 53.1%; Average loss: 4.9777 Perplexity: 145.1352\n",
      "Iteration: 2655; Percent complete: 53.1%; Average loss: 4.1249 Perplexity: 61.8589\n",
      "Iteration: 2656; Percent complete: 53.1%; Average loss: 4.2224 Perplexity: 68.1956\n",
      "Iteration: 2657; Percent complete: 53.1%; Average loss: 3.6393 Perplexity: 38.0647\n",
      "Iteration: 2658; Percent complete: 53.2%; Average loss: 4.2943 Perplexity: 73.2814\n",
      "Iteration: 2659; Percent complete: 53.2%; Average loss: 4.2353 Perplexity: 69.0811\n",
      "Iteration: 2660; Percent complete: 53.2%; Average loss: 3.8958 Perplexity: 49.1969\n",
      "Iteration: 2661; Percent complete: 53.2%; Average loss: 4.0886 Perplexity: 59.6562\n",
      "Iteration: 2662; Percent complete: 53.2%; Average loss: 3.7490 Perplexity: 42.4768\n",
      "Iteration: 2663; Percent complete: 53.3%; Average loss: 4.1061 Perplexity: 60.7087\n",
      "Iteration: 2664; Percent complete: 53.3%; Average loss: 3.8312 Perplexity: 46.1195\n",
      "Iteration: 2665; Percent complete: 53.3%; Average loss: 4.0652 Perplexity: 58.2787\n",
      "Iteration: 2666; Percent complete: 53.3%; Average loss: 4.0597 Perplexity: 57.9552\n",
      "Iteration: 2667; Percent complete: 53.3%; Average loss: 4.3534 Perplexity: 77.7433\n",
      "Iteration: 2668; Percent complete: 53.4%; Average loss: 4.2509 Perplexity: 70.1676\n",
      "Iteration: 2669; Percent complete: 53.4%; Average loss: 4.2398 Perplexity: 69.3914\n",
      "Iteration: 2670; Percent complete: 53.4%; Average loss: 3.7970 Perplexity: 44.5657\n",
      "Iteration: 2671; Percent complete: 53.4%; Average loss: 3.6670 Perplexity: 39.1355\n",
      "Iteration: 2672; Percent complete: 53.4%; Average loss: 4.0826 Perplexity: 59.2975\n",
      "Iteration: 2673; Percent complete: 53.5%; Average loss: 3.7932 Perplexity: 44.4001\n",
      "Iteration: 2674; Percent complete: 53.5%; Average loss: 4.2276 Perplexity: 68.5553\n",
      "Iteration: 2675; Percent complete: 53.5%; Average loss: 3.9969 Perplexity: 54.4282\n",
      "Iteration: 2676; Percent complete: 53.5%; Average loss: 3.9319 Perplexity: 51.0040\n",
      "Iteration: 2677; Percent complete: 53.5%; Average loss: 4.0266 Perplexity: 56.0707\n",
      "Iteration: 2678; Percent complete: 53.6%; Average loss: 3.9947 Perplexity: 54.3113\n",
      "Iteration: 2679; Percent complete: 53.6%; Average loss: 3.9707 Perplexity: 53.0232\n",
      "Iteration: 2680; Percent complete: 53.6%; Average loss: 4.0194 Perplexity: 55.6672\n",
      "Iteration: 2681; Percent complete: 53.6%; Average loss: 3.6585 Perplexity: 38.8037\n",
      "Iteration: 2682; Percent complete: 53.6%; Average loss: 3.9806 Perplexity: 53.5492\n",
      "Iteration: 2683; Percent complete: 53.7%; Average loss: 3.4638 Perplexity: 31.9395\n",
      "Iteration: 2684; Percent complete: 53.7%; Average loss: 4.3157 Perplexity: 74.8636\n",
      "Iteration: 2685; Percent complete: 53.7%; Average loss: 3.9439 Perplexity: 51.6189\n",
      "Iteration: 2686; Percent complete: 53.7%; Average loss: 4.1514 Perplexity: 63.5206\n",
      "Iteration: 2687; Percent complete: 53.7%; Average loss: 4.3984 Perplexity: 81.3177\n",
      "Iteration: 2688; Percent complete: 53.8%; Average loss: 3.6223 Perplexity: 37.4232\n",
      "Iteration: 2689; Percent complete: 53.8%; Average loss: 4.0921 Perplexity: 59.8656\n",
      "Iteration: 2690; Percent complete: 53.8%; Average loss: 4.6983 Perplexity: 109.7620\n",
      "Iteration: 2691; Percent complete: 53.8%; Average loss: 4.0418 Perplexity: 56.9311\n",
      "Iteration: 2692; Percent complete: 53.8%; Average loss: 4.4977 Perplexity: 89.8102\n",
      "Iteration: 2693; Percent complete: 53.9%; Average loss: 3.9962 Perplexity: 54.3906\n",
      "Iteration: 2694; Percent complete: 53.9%; Average loss: 4.2064 Perplexity: 67.1119\n",
      "Iteration: 2695; Percent complete: 53.9%; Average loss: 4.1870 Perplexity: 65.8234\n",
      "Iteration: 2696; Percent complete: 53.9%; Average loss: 3.8883 Perplexity: 48.8256\n",
      "Iteration: 2697; Percent complete: 53.9%; Average loss: 4.1053 Perplexity: 60.6629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2698; Percent complete: 54.0%; Average loss: 3.8580 Perplexity: 47.3683\n",
      "Iteration: 2699; Percent complete: 54.0%; Average loss: 4.2224 Perplexity: 68.1985\n",
      "Iteration: 2700; Percent complete: 54.0%; Average loss: 4.0927 Perplexity: 59.9017\n",
      "Iteration: 2701; Percent complete: 54.0%; Average loss: 4.0646 Perplexity: 58.2395\n",
      "Iteration: 2702; Percent complete: 54.0%; Average loss: 3.8104 Perplexity: 45.1702\n",
      "Iteration: 2703; Percent complete: 54.1%; Average loss: 3.8064 Perplexity: 44.9865\n",
      "Iteration: 2704; Percent complete: 54.1%; Average loss: 4.1266 Perplexity: 61.9690\n",
      "Iteration: 2705; Percent complete: 54.1%; Average loss: 4.1319 Perplexity: 62.2954\n",
      "Iteration: 2706; Percent complete: 54.1%; Average loss: 3.9541 Perplexity: 52.1478\n",
      "Iteration: 2707; Percent complete: 54.1%; Average loss: 3.5916 Perplexity: 36.2921\n",
      "Iteration: 2708; Percent complete: 54.2%; Average loss: 4.2600 Perplexity: 70.8114\n",
      "Iteration: 2709; Percent complete: 54.2%; Average loss: 3.9381 Perplexity: 51.3203\n",
      "Iteration: 2710; Percent complete: 54.2%; Average loss: 4.2137 Perplexity: 67.6038\n",
      "Iteration: 2711; Percent complete: 54.2%; Average loss: 4.0154 Perplexity: 55.4429\n",
      "Iteration: 2712; Percent complete: 54.2%; Average loss: 3.9210 Perplexity: 50.4494\n",
      "Iteration: 2713; Percent complete: 54.3%; Average loss: 3.8611 Perplexity: 47.5189\n",
      "Iteration: 2714; Percent complete: 54.3%; Average loss: 4.1064 Perplexity: 60.7272\n",
      "Iteration: 2715; Percent complete: 54.3%; Average loss: 4.0031 Perplexity: 54.7665\n",
      "Iteration: 2716; Percent complete: 54.3%; Average loss: 3.5390 Perplexity: 34.4334\n",
      "Iteration: 2717; Percent complete: 54.3%; Average loss: 3.9572 Perplexity: 52.3115\n",
      "Iteration: 2718; Percent complete: 54.4%; Average loss: 3.6022 Perplexity: 36.6791\n",
      "Iteration: 2719; Percent complete: 54.4%; Average loss: 3.8906 Perplexity: 48.9421\n",
      "Iteration: 2720; Percent complete: 54.4%; Average loss: 4.0436 Perplexity: 57.0321\n",
      "Iteration: 2721; Percent complete: 54.4%; Average loss: 3.8556 Perplexity: 47.2591\n",
      "Iteration: 2722; Percent complete: 54.4%; Average loss: 4.1765 Perplexity: 65.1369\n",
      "Iteration: 2723; Percent complete: 54.5%; Average loss: 3.8511 Perplexity: 47.0461\n",
      "Iteration: 2724; Percent complete: 54.5%; Average loss: 4.0342 Perplexity: 56.4995\n",
      "Iteration: 2725; Percent complete: 54.5%; Average loss: 4.0139 Perplexity: 55.3643\n",
      "Iteration: 2726; Percent complete: 54.5%; Average loss: 3.8971 Perplexity: 49.2588\n",
      "Iteration: 2727; Percent complete: 54.5%; Average loss: 4.0512 Perplexity: 57.4648\n",
      "Iteration: 2728; Percent complete: 54.6%; Average loss: 4.0540 Perplexity: 57.6282\n",
      "Iteration: 2729; Percent complete: 54.6%; Average loss: 4.0740 Perplexity: 58.7941\n",
      "Iteration: 2730; Percent complete: 54.6%; Average loss: 4.3150 Perplexity: 74.8131\n",
      "Iteration: 2731; Percent complete: 54.6%; Average loss: 3.9905 Perplexity: 54.0840\n",
      "Iteration: 2732; Percent complete: 54.6%; Average loss: 3.9403 Perplexity: 51.4349\n",
      "Iteration: 2733; Percent complete: 54.7%; Average loss: 4.2425 Perplexity: 69.5793\n",
      "Iteration: 2734; Percent complete: 54.7%; Average loss: 4.0996 Perplexity: 60.3161\n",
      "Iteration: 2735; Percent complete: 54.7%; Average loss: 3.9891 Perplexity: 54.0062\n",
      "Iteration: 2736; Percent complete: 54.7%; Average loss: 3.9491 Perplexity: 51.8896\n",
      "Iteration: 2737; Percent complete: 54.7%; Average loss: 4.0902 Perplexity: 59.7492\n",
      "Iteration: 2738; Percent complete: 54.8%; Average loss: 3.9277 Perplexity: 50.7890\n",
      "Iteration: 2739; Percent complete: 54.8%; Average loss: 4.1260 Perplexity: 61.9301\n",
      "Iteration: 2740; Percent complete: 54.8%; Average loss: 3.6541 Perplexity: 38.6326\n",
      "Iteration: 2741; Percent complete: 54.8%; Average loss: 3.8763 Perplexity: 48.2467\n",
      "Iteration: 2742; Percent complete: 54.8%; Average loss: 3.6592 Perplexity: 38.8322\n",
      "Iteration: 2743; Percent complete: 54.9%; Average loss: 4.5981 Perplexity: 99.2986\n",
      "Iteration: 2744; Percent complete: 54.9%; Average loss: 3.6738 Perplexity: 39.4024\n",
      "Iteration: 2745; Percent complete: 54.9%; Average loss: 4.1848 Perplexity: 65.6792\n",
      "Iteration: 2746; Percent complete: 54.9%; Average loss: 3.8238 Perplexity: 45.7779\n",
      "Iteration: 2747; Percent complete: 54.9%; Average loss: 4.2767 Perplexity: 71.9993\n",
      "Iteration: 2748; Percent complete: 55.0%; Average loss: 4.2900 Perplexity: 72.9641\n",
      "Iteration: 2749; Percent complete: 55.0%; Average loss: 4.2551 Perplexity: 70.4657\n",
      "Iteration: 2750; Percent complete: 55.0%; Average loss: 3.8773 Perplexity: 48.2914\n",
      "Iteration: 2751; Percent complete: 55.0%; Average loss: 3.9198 Perplexity: 50.3879\n",
      "Iteration: 2752; Percent complete: 55.0%; Average loss: 3.9548 Perplexity: 52.1848\n",
      "Iteration: 2753; Percent complete: 55.1%; Average loss: 4.0947 Perplexity: 60.0209\n",
      "Iteration: 2754; Percent complete: 55.1%; Average loss: 4.0548 Perplexity: 57.6756\n",
      "Iteration: 2755; Percent complete: 55.1%; Average loss: 3.9494 Perplexity: 51.9030\n",
      "Iteration: 2756; Percent complete: 55.1%; Average loss: 4.1031 Perplexity: 60.5281\n",
      "Iteration: 2757; Percent complete: 55.1%; Average loss: 4.0399 Perplexity: 56.8214\n",
      "Iteration: 2758; Percent complete: 55.2%; Average loss: 3.7146 Perplexity: 41.0410\n",
      "Iteration: 2759; Percent complete: 55.2%; Average loss: 3.8917 Perplexity: 48.9957\n",
      "Iteration: 2760; Percent complete: 55.2%; Average loss: 4.1047 Perplexity: 60.6229\n",
      "Iteration: 2761; Percent complete: 55.2%; Average loss: 3.8829 Perplexity: 48.5628\n",
      "Iteration: 2762; Percent complete: 55.2%; Average loss: 4.2187 Perplexity: 67.9464\n",
      "Iteration: 2763; Percent complete: 55.3%; Average loss: 4.1436 Perplexity: 63.0267\n",
      "Iteration: 2764; Percent complete: 55.3%; Average loss: 3.9478 Perplexity: 51.8229\n",
      "Iteration: 2765; Percent complete: 55.3%; Average loss: 4.1151 Perplexity: 61.2589\n",
      "Iteration: 2766; Percent complete: 55.3%; Average loss: 4.3193 Perplexity: 75.1356\n",
      "Iteration: 2767; Percent complete: 55.3%; Average loss: 3.8820 Perplexity: 48.5205\n",
      "Iteration: 2768; Percent complete: 55.4%; Average loss: 4.0259 Perplexity: 56.0304\n",
      "Iteration: 2769; Percent complete: 55.4%; Average loss: 4.1504 Perplexity: 63.4571\n",
      "Iteration: 2770; Percent complete: 55.4%; Average loss: 3.9306 Perplexity: 50.9394\n",
      "Iteration: 2771; Percent complete: 55.4%; Average loss: 4.0890 Perplexity: 59.6782\n",
      "Iteration: 2772; Percent complete: 55.4%; Average loss: 3.7881 Perplexity: 44.1704\n",
      "Iteration: 2773; Percent complete: 55.5%; Average loss: 3.6958 Perplexity: 40.2781\n",
      "Iteration: 2774; Percent complete: 55.5%; Average loss: 4.1286 Perplexity: 62.0931\n",
      "Iteration: 2775; Percent complete: 55.5%; Average loss: 4.4082 Perplexity: 82.1195\n",
      "Iteration: 2776; Percent complete: 55.5%; Average loss: 3.7170 Perplexity: 41.1412\n",
      "Iteration: 2777; Percent complete: 55.5%; Average loss: 4.0682 Perplexity: 58.4493\n",
      "Iteration: 2778; Percent complete: 55.6%; Average loss: 3.9817 Perplexity: 53.6066\n",
      "Iteration: 2779; Percent complete: 55.6%; Average loss: 4.2486 Perplexity: 70.0046\n",
      "Iteration: 2780; Percent complete: 55.6%; Average loss: 4.0784 Perplexity: 59.0484\n",
      "Iteration: 2781; Percent complete: 55.6%; Average loss: 3.9132 Perplexity: 50.0602\n",
      "Iteration: 2782; Percent complete: 55.6%; Average loss: 4.3492 Perplexity: 77.4197\n",
      "Iteration: 2783; Percent complete: 55.7%; Average loss: 3.8154 Perplexity: 45.3943\n",
      "Iteration: 2784; Percent complete: 55.7%; Average loss: 3.9585 Perplexity: 52.3776\n",
      "Iteration: 2785; Percent complete: 55.7%; Average loss: 4.0636 Perplexity: 58.1806\n",
      "Iteration: 2786; Percent complete: 55.7%; Average loss: 4.6143 Perplexity: 100.9135\n",
      "Iteration: 2787; Percent complete: 55.7%; Average loss: 4.1337 Perplexity: 62.4085\n",
      "Iteration: 2788; Percent complete: 55.8%; Average loss: 3.6617 Perplexity: 38.9273\n",
      "Iteration: 2789; Percent complete: 55.8%; Average loss: 4.0970 Perplexity: 60.1606\n",
      "Iteration: 2790; Percent complete: 55.8%; Average loss: 3.9595 Perplexity: 52.4304\n",
      "Iteration: 2791; Percent complete: 55.8%; Average loss: 3.9371 Perplexity: 51.2694\n",
      "Iteration: 2792; Percent complete: 55.8%; Average loss: 4.0172 Perplexity: 55.5475\n",
      "Iteration: 2793; Percent complete: 55.9%; Average loss: 3.9523 Perplexity: 52.0557\n",
      "Iteration: 2794; Percent complete: 55.9%; Average loss: 3.9644 Perplexity: 52.6892\n",
      "Iteration: 2795; Percent complete: 55.9%; Average loss: 4.0329 Perplexity: 56.4221\n",
      "Iteration: 2796; Percent complete: 55.9%; Average loss: 4.3643 Perplexity: 78.5972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2797; Percent complete: 55.9%; Average loss: 3.9540 Perplexity: 52.1445\n",
      "Iteration: 2798; Percent complete: 56.0%; Average loss: 3.9838 Perplexity: 53.7211\n",
      "Iteration: 2799; Percent complete: 56.0%; Average loss: 4.2198 Perplexity: 68.0178\n",
      "Iteration: 2800; Percent complete: 56.0%; Average loss: 3.8688 Perplexity: 47.8861\n",
      "Iteration: 2801; Percent complete: 56.0%; Average loss: 3.8153 Perplexity: 45.3890\n",
      "Iteration: 2802; Percent complete: 56.0%; Average loss: 3.9797 Perplexity: 53.5025\n",
      "Iteration: 2803; Percent complete: 56.1%; Average loss: 3.9260 Perplexity: 50.7049\n",
      "Iteration: 2804; Percent complete: 56.1%; Average loss: 3.6211 Perplexity: 37.3804\n",
      "Iteration: 2805; Percent complete: 56.1%; Average loss: 3.8486 Perplexity: 46.9275\n",
      "Iteration: 2806; Percent complete: 56.1%; Average loss: 3.9392 Perplexity: 51.3753\n",
      "Iteration: 2807; Percent complete: 56.1%; Average loss: 4.0122 Perplexity: 55.2696\n",
      "Iteration: 2808; Percent complete: 56.2%; Average loss: 4.3830 Perplexity: 80.0782\n",
      "Iteration: 2809; Percent complete: 56.2%; Average loss: 4.0641 Perplexity: 58.2123\n",
      "Iteration: 2810; Percent complete: 56.2%; Average loss: 3.4777 Perplexity: 32.3851\n",
      "Iteration: 2811; Percent complete: 56.2%; Average loss: 3.8420 Perplexity: 46.6208\n",
      "Iteration: 2812; Percent complete: 56.2%; Average loss: 4.2715 Perplexity: 71.6256\n",
      "Iteration: 2813; Percent complete: 56.3%; Average loss: 3.7015 Perplexity: 40.5070\n",
      "Iteration: 2814; Percent complete: 56.3%; Average loss: 4.4455 Perplexity: 85.2388\n",
      "Iteration: 2815; Percent complete: 56.3%; Average loss: 3.8845 Perplexity: 48.6417\n",
      "Iteration: 2816; Percent complete: 56.3%; Average loss: 3.7258 Perplexity: 41.5039\n",
      "Iteration: 2817; Percent complete: 56.3%; Average loss: 3.9959 Perplexity: 54.3726\n",
      "Iteration: 2818; Percent complete: 56.4%; Average loss: 3.8745 Perplexity: 48.1578\n",
      "Iteration: 2819; Percent complete: 56.4%; Average loss: 3.8170 Perplexity: 45.4667\n",
      "Iteration: 2820; Percent complete: 56.4%; Average loss: 4.1083 Perplexity: 60.8422\n",
      "Iteration: 2821; Percent complete: 56.4%; Average loss: 4.0806 Perplexity: 59.1797\n",
      "Iteration: 2822; Percent complete: 56.4%; Average loss: 3.9974 Perplexity: 54.4556\n",
      "Iteration: 2823; Percent complete: 56.5%; Average loss: 4.1932 Perplexity: 66.2332\n",
      "Iteration: 2824; Percent complete: 56.5%; Average loss: 3.8061 Perplexity: 44.9726\n",
      "Iteration: 2825; Percent complete: 56.5%; Average loss: 3.5740 Perplexity: 35.6596\n",
      "Iteration: 2826; Percent complete: 56.5%; Average loss: 3.7635 Perplexity: 43.1000\n",
      "Iteration: 2827; Percent complete: 56.5%; Average loss: 3.8444 Perplexity: 46.7312\n",
      "Iteration: 2828; Percent complete: 56.6%; Average loss: 3.8775 Perplexity: 48.3011\n",
      "Iteration: 2829; Percent complete: 56.6%; Average loss: 3.5268 Perplexity: 34.0134\n",
      "Iteration: 2830; Percent complete: 56.6%; Average loss: 4.1040 Perplexity: 60.5810\n",
      "Iteration: 2831; Percent complete: 56.6%; Average loss: 3.9497 Perplexity: 51.9193\n",
      "Iteration: 2832; Percent complete: 56.6%; Average loss: 4.5306 Perplexity: 92.8187\n",
      "Iteration: 2833; Percent complete: 56.7%; Average loss: 3.9006 Perplexity: 49.4343\n",
      "Iteration: 2834; Percent complete: 56.7%; Average loss: 3.8906 Perplexity: 48.9404\n",
      "Iteration: 2835; Percent complete: 56.7%; Average loss: 3.8471 Perplexity: 46.8591\n",
      "Iteration: 2836; Percent complete: 56.7%; Average loss: 4.0457 Perplexity: 57.1514\n",
      "Iteration: 2837; Percent complete: 56.7%; Average loss: 3.6434 Perplexity: 38.2227\n",
      "Iteration: 2838; Percent complete: 56.8%; Average loss: 3.7608 Perplexity: 42.9829\n",
      "Iteration: 2839; Percent complete: 56.8%; Average loss: 4.0458 Perplexity: 57.1597\n",
      "Iteration: 2840; Percent complete: 56.8%; Average loss: 3.9422 Perplexity: 51.5332\n",
      "Iteration: 2841; Percent complete: 56.8%; Average loss: 4.2366 Perplexity: 69.1701\n",
      "Iteration: 2842; Percent complete: 56.8%; Average loss: 3.5672 Perplexity: 35.4172\n",
      "Iteration: 2843; Percent complete: 56.9%; Average loss: 3.9294 Perplexity: 50.8780\n",
      "Iteration: 2844; Percent complete: 56.9%; Average loss: 3.9088 Perplexity: 49.8397\n",
      "Iteration: 2845; Percent complete: 56.9%; Average loss: 3.7534 Perplexity: 42.6666\n",
      "Iteration: 2846; Percent complete: 56.9%; Average loss: 4.0446 Perplexity: 57.0892\n",
      "Iteration: 2847; Percent complete: 56.9%; Average loss: 3.8394 Perplexity: 46.4961\n",
      "Iteration: 2848; Percent complete: 57.0%; Average loss: 3.9681 Perplexity: 52.8841\n",
      "Iteration: 2849; Percent complete: 57.0%; Average loss: 3.9691 Perplexity: 52.9348\n",
      "Iteration: 2850; Percent complete: 57.0%; Average loss: 3.7021 Perplexity: 40.5324\n",
      "Iteration: 2851; Percent complete: 57.0%; Average loss: 3.7997 Perplexity: 44.6894\n",
      "Iteration: 2852; Percent complete: 57.0%; Average loss: 3.8824 Perplexity: 48.5409\n",
      "Iteration: 2853; Percent complete: 57.1%; Average loss: 3.6229 Perplexity: 37.4471\n",
      "Iteration: 2854; Percent complete: 57.1%; Average loss: 3.8032 Perplexity: 44.8427\n",
      "Iteration: 2855; Percent complete: 57.1%; Average loss: 3.8837 Perplexity: 48.6050\n",
      "Iteration: 2856; Percent complete: 57.1%; Average loss: 3.8995 Perplexity: 49.3785\n",
      "Iteration: 2857; Percent complete: 57.1%; Average loss: 4.1372 Perplexity: 62.6262\n",
      "Iteration: 2858; Percent complete: 57.2%; Average loss: 3.9008 Perplexity: 49.4399\n",
      "Iteration: 2859; Percent complete: 57.2%; Average loss: 3.9304 Perplexity: 50.9249\n",
      "Iteration: 2860; Percent complete: 57.2%; Average loss: 4.0309 Perplexity: 56.3116\n",
      "Iteration: 2861; Percent complete: 57.2%; Average loss: 3.8602 Perplexity: 47.4729\n",
      "Iteration: 2862; Percent complete: 57.2%; Average loss: 3.7760 Perplexity: 43.6406\n",
      "Iteration: 2863; Percent complete: 57.3%; Average loss: 3.7942 Perplexity: 44.4433\n",
      "Iteration: 2864; Percent complete: 57.3%; Average loss: 3.7159 Perplexity: 41.0942\n",
      "Iteration: 2865; Percent complete: 57.3%; Average loss: 3.7570 Perplexity: 42.8201\n",
      "Iteration: 2866; Percent complete: 57.3%; Average loss: 3.8731 Perplexity: 48.0912\n",
      "Iteration: 2867; Percent complete: 57.3%; Average loss: 3.6298 Perplexity: 37.7061\n",
      "Iteration: 2868; Percent complete: 57.4%; Average loss: 4.1451 Perplexity: 63.1223\n",
      "Iteration: 2869; Percent complete: 57.4%; Average loss: 4.1006 Perplexity: 60.3763\n",
      "Iteration: 2870; Percent complete: 57.4%; Average loss: 4.1066 Perplexity: 60.7423\n",
      "Iteration: 2871; Percent complete: 57.4%; Average loss: 3.7428 Perplexity: 42.2176\n",
      "Iteration: 2872; Percent complete: 57.4%; Average loss: 3.9818 Perplexity: 53.6120\n",
      "Iteration: 2873; Percent complete: 57.5%; Average loss: 3.9922 Perplexity: 54.1761\n",
      "Iteration: 2874; Percent complete: 57.5%; Average loss: 4.0144 Perplexity: 55.3915\n",
      "Iteration: 2875; Percent complete: 57.5%; Average loss: 3.8752 Perplexity: 48.1914\n",
      "Iteration: 2876; Percent complete: 57.5%; Average loss: 3.9806 Perplexity: 53.5499\n",
      "Iteration: 2877; Percent complete: 57.5%; Average loss: 3.4852 Perplexity: 32.6293\n",
      "Iteration: 2878; Percent complete: 57.6%; Average loss: 3.8647 Perplexity: 47.6907\n",
      "Iteration: 2879; Percent complete: 57.6%; Average loss: 4.2689 Perplexity: 71.4417\n",
      "Iteration: 2880; Percent complete: 57.6%; Average loss: 3.7653 Perplexity: 43.1763\n",
      "Iteration: 2881; Percent complete: 57.6%; Average loss: 3.7219 Perplexity: 41.3447\n",
      "Iteration: 2882; Percent complete: 57.6%; Average loss: 3.7471 Perplexity: 42.3971\n",
      "Iteration: 2883; Percent complete: 57.7%; Average loss: 3.8497 Perplexity: 46.9805\n",
      "Iteration: 2884; Percent complete: 57.7%; Average loss: 4.1332 Perplexity: 62.3746\n",
      "Iteration: 2885; Percent complete: 57.7%; Average loss: 3.4811 Perplexity: 32.4956\n",
      "Iteration: 2886; Percent complete: 57.7%; Average loss: 4.0862 Perplexity: 59.5161\n",
      "Iteration: 2887; Percent complete: 57.7%; Average loss: 3.6214 Perplexity: 37.3886\n",
      "Iteration: 2888; Percent complete: 57.8%; Average loss: 3.9460 Perplexity: 51.7298\n",
      "Iteration: 2889; Percent complete: 57.8%; Average loss: 3.8943 Perplexity: 49.1210\n",
      "Iteration: 2890; Percent complete: 57.8%; Average loss: 3.7143 Perplexity: 41.0315\n",
      "Iteration: 2891; Percent complete: 57.8%; Average loss: 3.8120 Perplexity: 45.2412\n",
      "Iteration: 2892; Percent complete: 57.8%; Average loss: 4.0770 Perplexity: 58.9678\n",
      "Iteration: 2893; Percent complete: 57.9%; Average loss: 3.7856 Perplexity: 44.0616\n",
      "Iteration: 2894; Percent complete: 57.9%; Average loss: 3.7515 Perplexity: 42.5854\n",
      "Iteration: 2895; Percent complete: 57.9%; Average loss: 3.8307 Perplexity: 46.0962\n",
      "Iteration: 2896; Percent complete: 57.9%; Average loss: 4.1332 Perplexity: 62.3790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2897; Percent complete: 57.9%; Average loss: 3.9161 Perplexity: 50.2037\n",
      "Iteration: 2898; Percent complete: 58.0%; Average loss: 4.1492 Perplexity: 63.3816\n",
      "Iteration: 2899; Percent complete: 58.0%; Average loss: 3.8746 Perplexity: 48.1643\n",
      "Iteration: 2900; Percent complete: 58.0%; Average loss: 4.3999 Perplexity: 81.4389\n",
      "Iteration: 2901; Percent complete: 58.0%; Average loss: 4.2988 Perplexity: 73.6144\n",
      "Iteration: 2902; Percent complete: 58.0%; Average loss: 3.7956 Perplexity: 44.5043\n",
      "Iteration: 2903; Percent complete: 58.1%; Average loss: 3.5280 Perplexity: 34.0574\n",
      "Iteration: 2904; Percent complete: 58.1%; Average loss: 3.9519 Perplexity: 52.0343\n",
      "Iteration: 2905; Percent complete: 58.1%; Average loss: 4.2080 Perplexity: 67.2202\n",
      "Iteration: 2906; Percent complete: 58.1%; Average loss: 3.6283 Perplexity: 37.6505\n",
      "Iteration: 2907; Percent complete: 58.1%; Average loss: 4.0285 Perplexity: 56.1782\n",
      "Iteration: 2908; Percent complete: 58.2%; Average loss: 3.9475 Perplexity: 51.8052\n",
      "Iteration: 2909; Percent complete: 58.2%; Average loss: 4.0084 Perplexity: 55.0567\n",
      "Iteration: 2910; Percent complete: 58.2%; Average loss: 4.0806 Perplexity: 59.1818\n",
      "Iteration: 2911; Percent complete: 58.2%; Average loss: 4.3876 Perplexity: 80.4498\n",
      "Iteration: 2912; Percent complete: 58.2%; Average loss: 3.8390 Perplexity: 46.4809\n",
      "Iteration: 2913; Percent complete: 58.3%; Average loss: 4.0957 Perplexity: 60.0842\n",
      "Iteration: 2914; Percent complete: 58.3%; Average loss: 3.8371 Perplexity: 46.3906\n",
      "Iteration: 2915; Percent complete: 58.3%; Average loss: 3.8969 Perplexity: 49.2483\n",
      "Iteration: 2916; Percent complete: 58.3%; Average loss: 3.6592 Perplexity: 38.8318\n",
      "Iteration: 2917; Percent complete: 58.3%; Average loss: 3.9530 Perplexity: 52.0912\n",
      "Iteration: 2918; Percent complete: 58.4%; Average loss: 4.0148 Perplexity: 55.4111\n",
      "Iteration: 2919; Percent complete: 58.4%; Average loss: 3.9596 Perplexity: 52.4371\n",
      "Iteration: 2920; Percent complete: 58.4%; Average loss: 3.7582 Perplexity: 42.8713\n",
      "Iteration: 2921; Percent complete: 58.4%; Average loss: 3.8953 Perplexity: 49.1720\n",
      "Iteration: 2922; Percent complete: 58.4%; Average loss: 3.7728 Perplexity: 43.5028\n",
      "Iteration: 2923; Percent complete: 58.5%; Average loss: 3.7040 Perplexity: 40.6105\n",
      "Iteration: 2924; Percent complete: 58.5%; Average loss: 4.0916 Perplexity: 59.8342\n",
      "Iteration: 2925; Percent complete: 58.5%; Average loss: 3.9063 Perplexity: 49.7153\n",
      "Iteration: 2926; Percent complete: 58.5%; Average loss: 3.7049 Perplexity: 40.6467\n",
      "Iteration: 2927; Percent complete: 58.5%; Average loss: 4.2503 Perplexity: 70.1282\n",
      "Iteration: 2928; Percent complete: 58.6%; Average loss: 4.1366 Perplexity: 62.5892\n",
      "Iteration: 2929; Percent complete: 58.6%; Average loss: 4.0132 Perplexity: 55.3228\n",
      "Iteration: 2930; Percent complete: 58.6%; Average loss: 4.0699 Perplexity: 58.5496\n",
      "Iteration: 2931; Percent complete: 58.6%; Average loss: 4.0133 Perplexity: 55.3303\n",
      "Iteration: 2932; Percent complete: 58.6%; Average loss: 3.9294 Perplexity: 50.8772\n",
      "Iteration: 2933; Percent complete: 58.7%; Average loss: 4.3446 Perplexity: 77.0615\n",
      "Iteration: 2934; Percent complete: 58.7%; Average loss: 3.6423 Perplexity: 38.1779\n",
      "Iteration: 2935; Percent complete: 58.7%; Average loss: 3.7188 Perplexity: 41.2161\n",
      "Iteration: 2936; Percent complete: 58.7%; Average loss: 3.6813 Perplexity: 39.6986\n",
      "Iteration: 2937; Percent complete: 58.7%; Average loss: 4.2628 Perplexity: 71.0096\n",
      "Iteration: 2938; Percent complete: 58.8%; Average loss: 3.7925 Perplexity: 44.3692\n",
      "Iteration: 2939; Percent complete: 58.8%; Average loss: 3.7376 Perplexity: 41.9976\n",
      "Iteration: 2940; Percent complete: 58.8%; Average loss: 3.7399 Perplexity: 42.0958\n",
      "Iteration: 2941; Percent complete: 58.8%; Average loss: 4.2346 Perplexity: 69.0360\n",
      "Iteration: 2942; Percent complete: 58.8%; Average loss: 3.8182 Perplexity: 45.5235\n",
      "Iteration: 2943; Percent complete: 58.9%; Average loss: 3.7267 Perplexity: 41.5434\n",
      "Iteration: 2944; Percent complete: 58.9%; Average loss: 4.0714 Perplexity: 58.6397\n",
      "Iteration: 2945; Percent complete: 58.9%; Average loss: 3.8743 Perplexity: 48.1511\n",
      "Iteration: 2946; Percent complete: 58.9%; Average loss: 3.5274 Perplexity: 34.0345\n",
      "Iteration: 2947; Percent complete: 58.9%; Average loss: 3.6644 Perplexity: 39.0338\n",
      "Iteration: 2948; Percent complete: 59.0%; Average loss: 3.9692 Perplexity: 52.9403\n",
      "Iteration: 2949; Percent complete: 59.0%; Average loss: 4.3671 Perplexity: 78.8146\n",
      "Iteration: 2950; Percent complete: 59.0%; Average loss: 4.1102 Perplexity: 60.9596\n",
      "Iteration: 2951; Percent complete: 59.0%; Average loss: 3.8156 Perplexity: 45.4058\n",
      "Iteration: 2952; Percent complete: 59.0%; Average loss: 4.1764 Perplexity: 65.1303\n",
      "Iteration: 2953; Percent complete: 59.1%; Average loss: 4.3176 Perplexity: 75.0117\n",
      "Iteration: 2954; Percent complete: 59.1%; Average loss: 4.0234 Perplexity: 55.8885\n",
      "Iteration: 2955; Percent complete: 59.1%; Average loss: 3.9547 Perplexity: 52.1788\n",
      "Iteration: 2956; Percent complete: 59.1%; Average loss: 3.6499 Perplexity: 38.4706\n",
      "Iteration: 2957; Percent complete: 59.1%; Average loss: 3.9803 Perplexity: 53.5316\n",
      "Iteration: 2958; Percent complete: 59.2%; Average loss: 3.8731 Perplexity: 48.0928\n",
      "Iteration: 2959; Percent complete: 59.2%; Average loss: 4.1036 Perplexity: 60.5564\n",
      "Iteration: 2960; Percent complete: 59.2%; Average loss: 4.2966 Perplexity: 73.4462\n",
      "Iteration: 2961; Percent complete: 59.2%; Average loss: 3.7346 Perplexity: 41.8711\n",
      "Iteration: 2962; Percent complete: 59.2%; Average loss: 3.7748 Perplexity: 43.5903\n",
      "Iteration: 2963; Percent complete: 59.3%; Average loss: 3.6954 Perplexity: 40.2600\n",
      "Iteration: 2964; Percent complete: 59.3%; Average loss: 3.9767 Perplexity: 53.3420\n",
      "Iteration: 2965; Percent complete: 59.3%; Average loss: 3.7205 Perplexity: 41.2869\n",
      "Iteration: 2966; Percent complete: 59.3%; Average loss: 3.9748 Perplexity: 53.2412\n",
      "Iteration: 2967; Percent complete: 59.3%; Average loss: 4.1420 Perplexity: 62.9286\n",
      "Iteration: 2968; Percent complete: 59.4%; Average loss: 3.7956 Perplexity: 44.5064\n",
      "Iteration: 2969; Percent complete: 59.4%; Average loss: 3.7657 Perplexity: 43.1933\n",
      "Iteration: 2970; Percent complete: 59.4%; Average loss: 3.9970 Perplexity: 54.4344\n",
      "Iteration: 2971; Percent complete: 59.4%; Average loss: 3.9881 Perplexity: 53.9536\n",
      "Iteration: 2972; Percent complete: 59.4%; Average loss: 3.6443 Perplexity: 38.2561\n",
      "Iteration: 2973; Percent complete: 59.5%; Average loss: 3.8594 Perplexity: 47.4390\n",
      "Iteration: 2974; Percent complete: 59.5%; Average loss: 3.8409 Perplexity: 46.5672\n",
      "Iteration: 2975; Percent complete: 59.5%; Average loss: 3.4972 Perplexity: 33.0217\n",
      "Iteration: 2976; Percent complete: 59.5%; Average loss: 3.8652 Perplexity: 47.7132\n",
      "Iteration: 2977; Percent complete: 59.5%; Average loss: 3.8009 Perplexity: 44.7401\n",
      "Iteration: 2978; Percent complete: 59.6%; Average loss: 4.3555 Perplexity: 77.9020\n",
      "Iteration: 2979; Percent complete: 59.6%; Average loss: 3.8035 Perplexity: 44.8571\n",
      "Iteration: 2980; Percent complete: 59.6%; Average loss: 3.9626 Perplexity: 52.5930\n",
      "Iteration: 2981; Percent complete: 59.6%; Average loss: 4.0123 Perplexity: 55.2745\n",
      "Iteration: 2982; Percent complete: 59.6%; Average loss: 3.6581 Perplexity: 38.7892\n",
      "Iteration: 2983; Percent complete: 59.7%; Average loss: 3.8880 Perplexity: 48.8156\n",
      "Iteration: 2984; Percent complete: 59.7%; Average loss: 4.0612 Perplexity: 58.0461\n",
      "Iteration: 2985; Percent complete: 59.7%; Average loss: 3.9156 Perplexity: 50.1803\n",
      "Iteration: 2986; Percent complete: 59.7%; Average loss: 3.8739 Perplexity: 48.1285\n",
      "Iteration: 2987; Percent complete: 59.7%; Average loss: 4.0813 Perplexity: 59.2197\n",
      "Iteration: 2988; Percent complete: 59.8%; Average loss: 4.0787 Perplexity: 59.0685\n",
      "Iteration: 2989; Percent complete: 59.8%; Average loss: 4.0023 Perplexity: 54.7230\n",
      "Iteration: 2990; Percent complete: 59.8%; Average loss: 3.9096 Perplexity: 49.8797\n",
      "Iteration: 2991; Percent complete: 59.8%; Average loss: 3.8323 Perplexity: 46.1702\n",
      "Iteration: 2992; Percent complete: 59.8%; Average loss: 4.4144 Perplexity: 82.6336\n",
      "Iteration: 2993; Percent complete: 59.9%; Average loss: 4.0310 Perplexity: 56.3163\n",
      "Iteration: 2994; Percent complete: 59.9%; Average loss: 3.9401 Perplexity: 51.4214\n",
      "Iteration: 2995; Percent complete: 59.9%; Average loss: 4.0745 Perplexity: 58.8233\n",
      "Iteration: 2996; Percent complete: 59.9%; Average loss: 3.9705 Perplexity: 53.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2997; Percent complete: 59.9%; Average loss: 3.6341 Perplexity: 37.8660\n",
      "Iteration: 2998; Percent complete: 60.0%; Average loss: 4.4148 Perplexity: 82.6681\n",
      "Iteration: 2999; Percent complete: 60.0%; Average loss: 3.5618 Perplexity: 35.2262\n",
      "Iteration: 3000; Percent complete: 60.0%; Average loss: 3.9050 Perplexity: 49.6525\n",
      "Iteration: 3001; Percent complete: 60.0%; Average loss: 4.2151 Perplexity: 67.7000\n",
      "Iteration: 3002; Percent complete: 60.0%; Average loss: 4.0877 Perplexity: 59.6021\n",
      "Iteration: 3003; Percent complete: 60.1%; Average loss: 3.8384 Perplexity: 46.4499\n",
      "Iteration: 3004; Percent complete: 60.1%; Average loss: 3.8207 Perplexity: 45.6375\n",
      "Iteration: 3005; Percent complete: 60.1%; Average loss: 3.7154 Perplexity: 41.0738\n",
      "Iteration: 3006; Percent complete: 60.1%; Average loss: 4.1778 Perplexity: 65.2197\n",
      "Iteration: 3007; Percent complete: 60.1%; Average loss: 3.7737 Perplexity: 43.5423\n",
      "Iteration: 3008; Percent complete: 60.2%; Average loss: 4.0644 Perplexity: 58.2314\n",
      "Iteration: 3009; Percent complete: 60.2%; Average loss: 3.9687 Perplexity: 52.9139\n",
      "Iteration: 3010; Percent complete: 60.2%; Average loss: 4.0000 Perplexity: 54.5964\n",
      "Iteration: 3011; Percent complete: 60.2%; Average loss: 3.6816 Perplexity: 39.7082\n",
      "Iteration: 3012; Percent complete: 60.2%; Average loss: 3.7191 Perplexity: 41.2264\n",
      "Iteration: 3013; Percent complete: 60.3%; Average loss: 4.0074 Perplexity: 55.0064\n",
      "Iteration: 3014; Percent complete: 60.3%; Average loss: 3.9896 Perplexity: 54.0318\n",
      "Iteration: 3015; Percent complete: 60.3%; Average loss: 4.2916 Perplexity: 73.0805\n",
      "Iteration: 3016; Percent complete: 60.3%; Average loss: 4.0566 Perplexity: 57.7795\n",
      "Iteration: 3017; Percent complete: 60.3%; Average loss: 3.8728 Perplexity: 48.0749\n",
      "Iteration: 3018; Percent complete: 60.4%; Average loss: 3.8700 Perplexity: 47.9421\n",
      "Iteration: 3019; Percent complete: 60.4%; Average loss: 3.7344 Perplexity: 41.8639\n",
      "Iteration: 3020; Percent complete: 60.4%; Average loss: 3.9136 Perplexity: 50.0789\n",
      "Iteration: 3021; Percent complete: 60.4%; Average loss: 4.1621 Perplexity: 64.2060\n",
      "Iteration: 3022; Percent complete: 60.4%; Average loss: 3.8610 Perplexity: 47.5124\n",
      "Iteration: 3023; Percent complete: 60.5%; Average loss: 3.8968 Perplexity: 49.2462\n",
      "Iteration: 3024; Percent complete: 60.5%; Average loss: 3.9682 Perplexity: 52.8918\n",
      "Iteration: 3025; Percent complete: 60.5%; Average loss: 3.8679 Perplexity: 47.8440\n",
      "Iteration: 3026; Percent complete: 60.5%; Average loss: 3.8580 Perplexity: 47.3696\n",
      "Iteration: 3027; Percent complete: 60.5%; Average loss: 4.2956 Perplexity: 73.3772\n",
      "Iteration: 3028; Percent complete: 60.6%; Average loss: 3.6365 Perplexity: 37.9582\n",
      "Iteration: 3029; Percent complete: 60.6%; Average loss: 3.6743 Perplexity: 39.4220\n",
      "Iteration: 3030; Percent complete: 60.6%; Average loss: 4.0615 Perplexity: 58.0606\n",
      "Iteration: 3031; Percent complete: 60.6%; Average loss: 3.7559 Perplexity: 42.7735\n",
      "Iteration: 3032; Percent complete: 60.6%; Average loss: 4.2540 Perplexity: 70.3892\n",
      "Iteration: 3033; Percent complete: 60.7%; Average loss: 4.2798 Perplexity: 72.2258\n",
      "Iteration: 3034; Percent complete: 60.7%; Average loss: 3.7581 Perplexity: 42.8673\n",
      "Iteration: 3035; Percent complete: 60.7%; Average loss: 4.1069 Perplexity: 60.7594\n",
      "Iteration: 3036; Percent complete: 60.7%; Average loss: 4.1276 Perplexity: 62.0296\n",
      "Iteration: 3037; Percent complete: 60.7%; Average loss: 4.0155 Perplexity: 55.4512\n",
      "Iteration: 3038; Percent complete: 60.8%; Average loss: 4.0269 Perplexity: 56.0847\n",
      "Iteration: 3039; Percent complete: 60.8%; Average loss: 3.9316 Perplexity: 50.9885\n",
      "Iteration: 3040; Percent complete: 60.8%; Average loss: 3.9556 Perplexity: 52.2265\n",
      "Iteration: 3041; Percent complete: 60.8%; Average loss: 3.4769 Perplexity: 32.3602\n",
      "Iteration: 3042; Percent complete: 60.8%; Average loss: 3.9245 Perplexity: 50.6271\n",
      "Iteration: 3043; Percent complete: 60.9%; Average loss: 4.0588 Perplexity: 57.9044\n",
      "Iteration: 3044; Percent complete: 60.9%; Average loss: 3.6453 Perplexity: 38.2938\n",
      "Iteration: 3045; Percent complete: 60.9%; Average loss: 3.8452 Perplexity: 46.7681\n",
      "Iteration: 3046; Percent complete: 60.9%; Average loss: 3.6139 Perplexity: 37.1115\n",
      "Iteration: 3047; Percent complete: 60.9%; Average loss: 3.7402 Perplexity: 42.1084\n",
      "Iteration: 3048; Percent complete: 61.0%; Average loss: 3.8353 Perplexity: 46.3079\n",
      "Iteration: 3049; Percent complete: 61.0%; Average loss: 3.5917 Perplexity: 36.2952\n",
      "Iteration: 3050; Percent complete: 61.0%; Average loss: 4.0030 Perplexity: 54.7641\n",
      "Iteration: 3051; Percent complete: 61.0%; Average loss: 3.6902 Perplexity: 40.0526\n",
      "Iteration: 3052; Percent complete: 61.0%; Average loss: 3.8256 Perplexity: 45.8622\n",
      "Iteration: 3053; Percent complete: 61.1%; Average loss: 3.6940 Perplexity: 40.2060\n",
      "Iteration: 3054; Percent complete: 61.1%; Average loss: 3.9037 Perplexity: 49.5864\n",
      "Iteration: 3055; Percent complete: 61.1%; Average loss: 3.6762 Perplexity: 39.4960\n",
      "Iteration: 3056; Percent complete: 61.1%; Average loss: 4.1757 Perplexity: 65.0875\n",
      "Iteration: 3057; Percent complete: 61.1%; Average loss: 4.0139 Perplexity: 55.3609\n",
      "Iteration: 3058; Percent complete: 61.2%; Average loss: 3.7459 Perplexity: 42.3491\n",
      "Iteration: 3059; Percent complete: 61.2%; Average loss: 4.0368 Perplexity: 56.6468\n",
      "Iteration: 3060; Percent complete: 61.2%; Average loss: 3.4147 Perplexity: 30.4064\n",
      "Iteration: 3061; Percent complete: 61.2%; Average loss: 3.5743 Perplexity: 35.6704\n",
      "Iteration: 3062; Percent complete: 61.2%; Average loss: 3.5783 Perplexity: 35.8121\n",
      "Iteration: 3063; Percent complete: 61.3%; Average loss: 3.8292 Perplexity: 46.0265\n",
      "Iteration: 3064; Percent complete: 61.3%; Average loss: 3.7228 Perplexity: 41.3792\n",
      "Iteration: 3065; Percent complete: 61.3%; Average loss: 3.4516 Perplexity: 31.5509\n",
      "Iteration: 3066; Percent complete: 61.3%; Average loss: 4.0330 Perplexity: 56.4321\n",
      "Iteration: 3067; Percent complete: 61.3%; Average loss: 3.4480 Perplexity: 31.4372\n",
      "Iteration: 3068; Percent complete: 61.4%; Average loss: 3.8126 Perplexity: 45.2695\n",
      "Iteration: 3069; Percent complete: 61.4%; Average loss: 3.7897 Perplexity: 44.2448\n",
      "Iteration: 3070; Percent complete: 61.4%; Average loss: 3.9568 Perplexity: 52.2910\n",
      "Iteration: 3071; Percent complete: 61.4%; Average loss: 4.2937 Perplexity: 73.2362\n",
      "Iteration: 3072; Percent complete: 61.4%; Average loss: 3.5820 Perplexity: 35.9450\n",
      "Iteration: 3073; Percent complete: 61.5%; Average loss: 4.0254 Perplexity: 56.0034\n",
      "Iteration: 3074; Percent complete: 61.5%; Average loss: 3.7287 Perplexity: 41.6235\n",
      "Iteration: 3075; Percent complete: 61.5%; Average loss: 4.0232 Perplexity: 55.8771\n",
      "Iteration: 3076; Percent complete: 61.5%; Average loss: 3.6016 Perplexity: 36.6557\n",
      "Iteration: 3077; Percent complete: 61.5%; Average loss: 3.6249 Perplexity: 37.5193\n",
      "Iteration: 3078; Percent complete: 61.6%; Average loss: 4.0324 Perplexity: 56.3984\n",
      "Iteration: 3079; Percent complete: 61.6%; Average loss: 3.9459 Perplexity: 51.7218\n",
      "Iteration: 3080; Percent complete: 61.6%; Average loss: 4.1521 Perplexity: 63.5650\n",
      "Iteration: 3081; Percent complete: 61.6%; Average loss: 3.8284 Perplexity: 45.9889\n",
      "Iteration: 3082; Percent complete: 61.6%; Average loss: 3.8071 Perplexity: 45.0196\n",
      "Iteration: 3083; Percent complete: 61.7%; Average loss: 3.5128 Perplexity: 33.5436\n",
      "Iteration: 3084; Percent complete: 61.7%; Average loss: 3.9145 Perplexity: 50.1243\n",
      "Iteration: 3085; Percent complete: 61.7%; Average loss: 4.1889 Perplexity: 65.9481\n",
      "Iteration: 3086; Percent complete: 61.7%; Average loss: 3.9030 Perplexity: 49.5498\n",
      "Iteration: 3087; Percent complete: 61.7%; Average loss: 3.5363 Perplexity: 34.3395\n",
      "Iteration: 3088; Percent complete: 61.8%; Average loss: 3.9551 Perplexity: 52.2015\n",
      "Iteration: 3089; Percent complete: 61.8%; Average loss: 3.6223 Perplexity: 37.4235\n",
      "Iteration: 3090; Percent complete: 61.8%; Average loss: 3.7247 Perplexity: 41.4605\n",
      "Iteration: 3091; Percent complete: 61.8%; Average loss: 4.1164 Perplexity: 61.3398\n",
      "Iteration: 3092; Percent complete: 61.8%; Average loss: 4.1324 Perplexity: 62.3296\n",
      "Iteration: 3093; Percent complete: 61.9%; Average loss: 3.7667 Perplexity: 43.2359\n",
      "Iteration: 3094; Percent complete: 61.9%; Average loss: 4.0947 Perplexity: 60.0199\n",
      "Iteration: 3095; Percent complete: 61.9%; Average loss: 4.1635 Perplexity: 64.2936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3096; Percent complete: 61.9%; Average loss: 3.8216 Perplexity: 45.6769\n",
      "Iteration: 3097; Percent complete: 61.9%; Average loss: 3.7630 Perplexity: 43.0780\n",
      "Iteration: 3098; Percent complete: 62.0%; Average loss: 3.8480 Perplexity: 46.8973\n",
      "Iteration: 3099; Percent complete: 62.0%; Average loss: 4.1709 Perplexity: 64.7751\n",
      "Iteration: 3100; Percent complete: 62.0%; Average loss: 3.5041 Perplexity: 33.2517\n",
      "Iteration: 3101; Percent complete: 62.0%; Average loss: 3.7998 Perplexity: 44.6940\n",
      "Iteration: 3102; Percent complete: 62.0%; Average loss: 3.9275 Perplexity: 50.7800\n",
      "Iteration: 3103; Percent complete: 62.1%; Average loss: 3.8007 Perplexity: 44.7321\n",
      "Iteration: 3104; Percent complete: 62.1%; Average loss: 3.9313 Perplexity: 50.9719\n",
      "Iteration: 3105; Percent complete: 62.1%; Average loss: 3.7032 Perplexity: 40.5780\n",
      "Iteration: 3106; Percent complete: 62.1%; Average loss: 3.6943 Perplexity: 40.2166\n",
      "Iteration: 3107; Percent complete: 62.1%; Average loss: 3.9794 Perplexity: 53.4867\n",
      "Iteration: 3108; Percent complete: 62.2%; Average loss: 4.2245 Perplexity: 68.3377\n",
      "Iteration: 3109; Percent complete: 62.2%; Average loss: 3.2185 Perplexity: 24.9894\n",
      "Iteration: 3110; Percent complete: 62.2%; Average loss: 3.6124 Perplexity: 37.0554\n",
      "Iteration: 3111; Percent complete: 62.2%; Average loss: 3.8004 Perplexity: 44.7197\n",
      "Iteration: 3112; Percent complete: 62.2%; Average loss: 3.6675 Perplexity: 39.1526\n",
      "Iteration: 3113; Percent complete: 62.3%; Average loss: 3.9058 Perplexity: 49.6880\n",
      "Iteration: 3114; Percent complete: 62.3%; Average loss: 3.8530 Perplexity: 47.1330\n",
      "Iteration: 3115; Percent complete: 62.3%; Average loss: 4.0298 Perplexity: 56.2497\n",
      "Iteration: 3116; Percent complete: 62.3%; Average loss: 3.6491 Perplexity: 38.4388\n",
      "Iteration: 3117; Percent complete: 62.3%; Average loss: 3.5335 Perplexity: 34.2436\n",
      "Iteration: 3118; Percent complete: 62.4%; Average loss: 3.9394 Perplexity: 51.3873\n",
      "Iteration: 3119; Percent complete: 62.4%; Average loss: 4.2028 Perplexity: 66.8735\n",
      "Iteration: 3120; Percent complete: 62.4%; Average loss: 4.2109 Perplexity: 67.4204\n",
      "Iteration: 3121; Percent complete: 62.4%; Average loss: 4.0671 Perplexity: 58.3876\n",
      "Iteration: 3122; Percent complete: 62.4%; Average loss: 3.9363 Perplexity: 51.2298\n",
      "Iteration: 3123; Percent complete: 62.5%; Average loss: 3.8540 Perplexity: 47.1825\n",
      "Iteration: 3124; Percent complete: 62.5%; Average loss: 3.6260 Perplexity: 37.5640\n",
      "Iteration: 3125; Percent complete: 62.5%; Average loss: 3.6830 Perplexity: 39.7650\n",
      "Iteration: 3126; Percent complete: 62.5%; Average loss: 4.1389 Perplexity: 62.7343\n",
      "Iteration: 3127; Percent complete: 62.5%; Average loss: 4.2861 Perplexity: 72.6820\n",
      "Iteration: 3128; Percent complete: 62.6%; Average loss: 3.7280 Perplexity: 41.5939\n",
      "Iteration: 3129; Percent complete: 62.6%; Average loss: 3.6619 Perplexity: 38.9345\n",
      "Iteration: 3130; Percent complete: 62.6%; Average loss: 3.7139 Perplexity: 41.0145\n",
      "Iteration: 3131; Percent complete: 62.6%; Average loss: 3.7981 Perplexity: 44.6154\n",
      "Iteration: 3132; Percent complete: 62.6%; Average loss: 4.0607 Perplexity: 58.0150\n",
      "Iteration: 3133; Percent complete: 62.7%; Average loss: 4.3082 Perplexity: 74.3053\n",
      "Iteration: 3134; Percent complete: 62.7%; Average loss: 4.2682 Perplexity: 71.3904\n",
      "Iteration: 3135; Percent complete: 62.7%; Average loss: 3.9362 Perplexity: 51.2253\n",
      "Iteration: 3136; Percent complete: 62.7%; Average loss: 4.1551 Perplexity: 63.7588\n",
      "Iteration: 3137; Percent complete: 62.7%; Average loss: 3.6717 Perplexity: 39.3201\n",
      "Iteration: 3138; Percent complete: 62.8%; Average loss: 3.5509 Perplexity: 34.8447\n",
      "Iteration: 3139; Percent complete: 62.8%; Average loss: 4.5148 Perplexity: 91.3568\n",
      "Iteration: 3140; Percent complete: 62.8%; Average loss: 3.7242 Perplexity: 41.4379\n",
      "Iteration: 3141; Percent complete: 62.8%; Average loss: 3.6908 Perplexity: 40.0783\n",
      "Iteration: 3142; Percent complete: 62.8%; Average loss: 3.5459 Perplexity: 34.6708\n",
      "Iteration: 3143; Percent complete: 62.9%; Average loss: 3.8428 Perplexity: 46.6560\n",
      "Iteration: 3144; Percent complete: 62.9%; Average loss: 3.8477 Perplexity: 46.8843\n",
      "Iteration: 3145; Percent complete: 62.9%; Average loss: 3.7650 Perplexity: 43.1629\n",
      "Iteration: 3146; Percent complete: 62.9%; Average loss: 3.6857 Perplexity: 39.8725\n",
      "Iteration: 3147; Percent complete: 62.9%; Average loss: 3.6954 Perplexity: 40.2626\n",
      "Iteration: 3148; Percent complete: 63.0%; Average loss: 3.6393 Perplexity: 38.0671\n",
      "Iteration: 3149; Percent complete: 63.0%; Average loss: 3.8524 Perplexity: 47.1041\n",
      "Iteration: 3150; Percent complete: 63.0%; Average loss: 4.0323 Perplexity: 56.3885\n",
      "Iteration: 3151; Percent complete: 63.0%; Average loss: 4.1103 Perplexity: 60.9654\n",
      "Iteration: 3152; Percent complete: 63.0%; Average loss: 4.0079 Perplexity: 55.0311\n",
      "Iteration: 3153; Percent complete: 63.1%; Average loss: 4.0256 Perplexity: 56.0145\n",
      "Iteration: 3154; Percent complete: 63.1%; Average loss: 3.7385 Perplexity: 42.0362\n",
      "Iteration: 3155; Percent complete: 63.1%; Average loss: 3.6937 Perplexity: 40.1949\n",
      "Iteration: 3156; Percent complete: 63.1%; Average loss: 4.5940 Perplexity: 98.8931\n",
      "Iteration: 3157; Percent complete: 63.1%; Average loss: 3.8723 Perplexity: 48.0515\n",
      "Iteration: 3158; Percent complete: 63.2%; Average loss: 4.1182 Perplexity: 61.4456\n",
      "Iteration: 3159; Percent complete: 63.2%; Average loss: 4.0568 Perplexity: 57.7888\n",
      "Iteration: 3160; Percent complete: 63.2%; Average loss: 3.4272 Perplexity: 30.7891\n",
      "Iteration: 3161; Percent complete: 63.2%; Average loss: 3.8928 Perplexity: 49.0468\n",
      "Iteration: 3162; Percent complete: 63.2%; Average loss: 3.6835 Perplexity: 39.7874\n",
      "Iteration: 3163; Percent complete: 63.3%; Average loss: 3.8586 Perplexity: 47.3987\n",
      "Iteration: 3164; Percent complete: 63.3%; Average loss: 4.1798 Perplexity: 65.3527\n",
      "Iteration: 3165; Percent complete: 63.3%; Average loss: 3.6096 Perplexity: 36.9530\n",
      "Iteration: 3166; Percent complete: 63.3%; Average loss: 4.1695 Perplexity: 64.6828\n",
      "Iteration: 3167; Percent complete: 63.3%; Average loss: 3.7485 Perplexity: 42.4578\n",
      "Iteration: 3168; Percent complete: 63.4%; Average loss: 4.0586 Perplexity: 57.8919\n",
      "Iteration: 3169; Percent complete: 63.4%; Average loss: 4.0601 Perplexity: 57.9827\n",
      "Iteration: 3170; Percent complete: 63.4%; Average loss: 3.9030 Perplexity: 49.5531\n",
      "Iteration: 3171; Percent complete: 63.4%; Average loss: 3.3518 Perplexity: 28.5532\n",
      "Iteration: 3172; Percent complete: 63.4%; Average loss: 4.1752 Perplexity: 65.0560\n",
      "Iteration: 3173; Percent complete: 63.5%; Average loss: 3.4271 Perplexity: 30.7879\n",
      "Iteration: 3174; Percent complete: 63.5%; Average loss: 3.8832 Perplexity: 48.5791\n",
      "Iteration: 3175; Percent complete: 63.5%; Average loss: 3.6866 Perplexity: 39.9087\n",
      "Iteration: 3176; Percent complete: 63.5%; Average loss: 3.7336 Perplexity: 41.8279\n",
      "Iteration: 3177; Percent complete: 63.5%; Average loss: 3.7551 Perplexity: 42.7391\n",
      "Iteration: 3178; Percent complete: 63.6%; Average loss: 3.9425 Perplexity: 51.5464\n",
      "Iteration: 3179; Percent complete: 63.6%; Average loss: 3.6309 Perplexity: 37.7462\n",
      "Iteration: 3180; Percent complete: 63.6%; Average loss: 4.0669 Perplexity: 58.3779\n",
      "Iteration: 3181; Percent complete: 63.6%; Average loss: 3.7977 Perplexity: 44.5978\n",
      "Iteration: 3182; Percent complete: 63.6%; Average loss: 3.8438 Perplexity: 46.7007\n",
      "Iteration: 3183; Percent complete: 63.7%; Average loss: 4.0861 Perplexity: 59.5095\n",
      "Iteration: 3184; Percent complete: 63.7%; Average loss: 3.2890 Perplexity: 26.8173\n",
      "Iteration: 3185; Percent complete: 63.7%; Average loss: 3.8070 Perplexity: 45.0152\n",
      "Iteration: 3186; Percent complete: 63.7%; Average loss: 4.1493 Perplexity: 63.3882\n",
      "Iteration: 3187; Percent complete: 63.7%; Average loss: 3.4117 Perplexity: 30.3174\n",
      "Iteration: 3188; Percent complete: 63.8%; Average loss: 4.3377 Perplexity: 76.5283\n",
      "Iteration: 3189; Percent complete: 63.8%; Average loss: 3.4779 Perplexity: 32.3920\n",
      "Iteration: 3190; Percent complete: 63.8%; Average loss: 3.8041 Perplexity: 44.8850\n",
      "Iteration: 3191; Percent complete: 63.8%; Average loss: 3.6121 Perplexity: 37.0442\n",
      "Iteration: 3192; Percent complete: 63.8%; Average loss: 3.7985 Perplexity: 44.6343\n",
      "Iteration: 3193; Percent complete: 63.9%; Average loss: 3.9406 Perplexity: 51.4516\n",
      "Iteration: 3194; Percent complete: 63.9%; Average loss: 4.0293 Perplexity: 56.2205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3195; Percent complete: 63.9%; Average loss: 4.0800 Perplexity: 59.1432\n",
      "Iteration: 3196; Percent complete: 63.9%; Average loss: 3.7429 Perplexity: 42.2213\n",
      "Iteration: 3197; Percent complete: 63.9%; Average loss: 3.7704 Perplexity: 43.3959\n",
      "Iteration: 3198; Percent complete: 64.0%; Average loss: 3.3827 Perplexity: 29.4494\n",
      "Iteration: 3199; Percent complete: 64.0%; Average loss: 3.8500 Perplexity: 46.9941\n",
      "Iteration: 3200; Percent complete: 64.0%; Average loss: 3.8720 Perplexity: 48.0399\n",
      "Iteration: 3201; Percent complete: 64.0%; Average loss: 4.2216 Perplexity: 68.1440\n",
      "Iteration: 3202; Percent complete: 64.0%; Average loss: 3.8844 Perplexity: 48.6398\n",
      "Iteration: 3203; Percent complete: 64.1%; Average loss: 4.4454 Perplexity: 85.2334\n",
      "Iteration: 3204; Percent complete: 64.1%; Average loss: 3.9411 Perplexity: 51.4731\n",
      "Iteration: 3205; Percent complete: 64.1%; Average loss: 4.0061 Perplexity: 54.9318\n",
      "Iteration: 3206; Percent complete: 64.1%; Average loss: 3.7366 Perplexity: 41.9563\n",
      "Iteration: 3207; Percent complete: 64.1%; Average loss: 4.1331 Perplexity: 62.3694\n",
      "Iteration: 3208; Percent complete: 64.2%; Average loss: 4.1478 Perplexity: 63.2963\n",
      "Iteration: 3209; Percent complete: 64.2%; Average loss: 3.8758 Perplexity: 48.2234\n",
      "Iteration: 3210; Percent complete: 64.2%; Average loss: 3.5259 Perplexity: 33.9847\n",
      "Iteration: 3211; Percent complete: 64.2%; Average loss: 4.0943 Perplexity: 59.9983\n",
      "Iteration: 3212; Percent complete: 64.2%; Average loss: 4.0125 Perplexity: 55.2831\n",
      "Iteration: 3213; Percent complete: 64.3%; Average loss: 4.2263 Perplexity: 68.4618\n",
      "Iteration: 3214; Percent complete: 64.3%; Average loss: 3.7063 Perplexity: 40.7021\n",
      "Iteration: 3215; Percent complete: 64.3%; Average loss: 3.9952 Perplexity: 54.3379\n",
      "Iteration: 3216; Percent complete: 64.3%; Average loss: 3.8871 Perplexity: 48.7688\n",
      "Iteration: 3217; Percent complete: 64.3%; Average loss: 4.0585 Perplexity: 57.8893\n",
      "Iteration: 3218; Percent complete: 64.4%; Average loss: 3.6000 Perplexity: 36.5991\n",
      "Iteration: 3219; Percent complete: 64.4%; Average loss: 3.9312 Perplexity: 50.9689\n",
      "Iteration: 3220; Percent complete: 64.4%; Average loss: 3.8480 Perplexity: 46.8990\n",
      "Iteration: 3221; Percent complete: 64.4%; Average loss: 3.7358 Perplexity: 41.9231\n",
      "Iteration: 3222; Percent complete: 64.4%; Average loss: 3.8575 Perplexity: 47.3456\n",
      "Iteration: 3223; Percent complete: 64.5%; Average loss: 3.7291 Perplexity: 41.6410\n",
      "Iteration: 3224; Percent complete: 64.5%; Average loss: 3.9208 Perplexity: 50.4406\n",
      "Iteration: 3225; Percent complete: 64.5%; Average loss: 3.5241 Perplexity: 33.9218\n",
      "Iteration: 3226; Percent complete: 64.5%; Average loss: 4.3033 Perplexity: 73.9417\n",
      "Iteration: 3227; Percent complete: 64.5%; Average loss: 3.8608 Perplexity: 47.5047\n",
      "Iteration: 3228; Percent complete: 64.6%; Average loss: 3.2082 Perplexity: 24.7336\n",
      "Iteration: 3229; Percent complete: 64.6%; Average loss: 3.9885 Perplexity: 53.9765\n",
      "Iteration: 3230; Percent complete: 64.6%; Average loss: 3.9565 Perplexity: 52.2721\n",
      "Iteration: 3231; Percent complete: 64.6%; Average loss: 3.8527 Perplexity: 47.1202\n",
      "Iteration: 3232; Percent complete: 64.6%; Average loss: 3.8128 Perplexity: 45.2750\n",
      "Iteration: 3233; Percent complete: 64.7%; Average loss: 4.2368 Perplexity: 69.1861\n",
      "Iteration: 3234; Percent complete: 64.7%; Average loss: 4.1295 Perplexity: 62.1442\n",
      "Iteration: 3235; Percent complete: 64.7%; Average loss: 3.7529 Perplexity: 42.6443\n",
      "Iteration: 3236; Percent complete: 64.7%; Average loss: 3.4401 Perplexity: 31.1906\n",
      "Iteration: 3237; Percent complete: 64.7%; Average loss: 3.6975 Perplexity: 40.3445\n",
      "Iteration: 3238; Percent complete: 64.8%; Average loss: 3.6667 Perplexity: 39.1213\n",
      "Iteration: 3239; Percent complete: 64.8%; Average loss: 3.8867 Perplexity: 48.7484\n",
      "Iteration: 3240; Percent complete: 64.8%; Average loss: 3.4302 Perplexity: 30.8821\n",
      "Iteration: 3241; Percent complete: 64.8%; Average loss: 4.6616 Perplexity: 105.8055\n",
      "Iteration: 3242; Percent complete: 64.8%; Average loss: 3.7274 Perplexity: 41.5697\n",
      "Iteration: 3243; Percent complete: 64.9%; Average loss: 3.7419 Perplexity: 42.1792\n",
      "Iteration: 3244; Percent complete: 64.9%; Average loss: 3.8240 Perplexity: 45.7892\n",
      "Iteration: 3245; Percent complete: 64.9%; Average loss: 3.4130 Perplexity: 30.3564\n",
      "Iteration: 3246; Percent complete: 64.9%; Average loss: 3.9975 Perplexity: 54.4594\n",
      "Iteration: 3247; Percent complete: 64.9%; Average loss: 3.7176 Perplexity: 41.1666\n",
      "Iteration: 3248; Percent complete: 65.0%; Average loss: 3.7624 Perplexity: 43.0516\n",
      "Iteration: 3249; Percent complete: 65.0%; Average loss: 3.7261 Perplexity: 41.5151\n",
      "Iteration: 3250; Percent complete: 65.0%; Average loss: 3.6990 Perplexity: 40.4084\n",
      "Iteration: 3251; Percent complete: 65.0%; Average loss: 3.8498 Perplexity: 46.9818\n",
      "Iteration: 3252; Percent complete: 65.0%; Average loss: 3.8484 Perplexity: 46.9193\n",
      "Iteration: 3253; Percent complete: 65.1%; Average loss: 3.9875 Perplexity: 53.9182\n",
      "Iteration: 3254; Percent complete: 65.1%; Average loss: 3.5849 Perplexity: 36.0504\n",
      "Iteration: 3255; Percent complete: 65.1%; Average loss: 3.9291 Perplexity: 50.8597\n",
      "Iteration: 3256; Percent complete: 65.1%; Average loss: 3.8325 Perplexity: 46.1782\n",
      "Iteration: 3257; Percent complete: 65.1%; Average loss: 3.4261 Perplexity: 30.7576\n",
      "Iteration: 3258; Percent complete: 65.2%; Average loss: 3.9118 Perplexity: 49.9877\n",
      "Iteration: 3259; Percent complete: 65.2%; Average loss: 3.6941 Perplexity: 40.2091\n",
      "Iteration: 3260; Percent complete: 65.2%; Average loss: 4.0222 Perplexity: 55.8242\n",
      "Iteration: 3261; Percent complete: 65.2%; Average loss: 3.7747 Perplexity: 43.5836\n",
      "Iteration: 3262; Percent complete: 65.2%; Average loss: 3.7615 Perplexity: 43.0134\n",
      "Iteration: 3263; Percent complete: 65.3%; Average loss: 4.1833 Perplexity: 65.5845\n",
      "Iteration: 3264; Percent complete: 65.3%; Average loss: 4.0052 Perplexity: 54.8822\n",
      "Iteration: 3265; Percent complete: 65.3%; Average loss: 3.8450 Perplexity: 46.7601\n",
      "Iteration: 3266; Percent complete: 65.3%; Average loss: 3.9283 Perplexity: 50.8223\n",
      "Iteration: 3267; Percent complete: 65.3%; Average loss: 3.8283 Perplexity: 45.9839\n",
      "Iteration: 3268; Percent complete: 65.4%; Average loss: 3.9663 Perplexity: 52.7878\n",
      "Iteration: 3269; Percent complete: 65.4%; Average loss: 3.8805 Perplexity: 48.4490\n",
      "Iteration: 3270; Percent complete: 65.4%; Average loss: 3.9438 Perplexity: 51.6160\n",
      "Iteration: 3271; Percent complete: 65.4%; Average loss: 3.7925 Perplexity: 44.3683\n",
      "Iteration: 3272; Percent complete: 65.4%; Average loss: 3.5722 Perplexity: 35.5957\n",
      "Iteration: 3273; Percent complete: 65.5%; Average loss: 3.5477 Perplexity: 34.7319\n",
      "Iteration: 3274; Percent complete: 65.5%; Average loss: 4.0537 Perplexity: 57.6098\n",
      "Iteration: 3275; Percent complete: 65.5%; Average loss: 3.5361 Perplexity: 34.3325\n",
      "Iteration: 3276; Percent complete: 65.5%; Average loss: 3.9946 Perplexity: 54.3028\n",
      "Iteration: 3277; Percent complete: 65.5%; Average loss: 3.7983 Perplexity: 44.6247\n",
      "Iteration: 3278; Percent complete: 65.6%; Average loss: 4.0272 Perplexity: 56.1052\n",
      "Iteration: 3279; Percent complete: 65.6%; Average loss: 3.9440 Perplexity: 51.6272\n",
      "Iteration: 3280; Percent complete: 65.6%; Average loss: 3.7509 Perplexity: 42.5578\n",
      "Iteration: 3281; Percent complete: 65.6%; Average loss: 3.9773 Perplexity: 53.3705\n",
      "Iteration: 3282; Percent complete: 65.6%; Average loss: 3.7094 Perplexity: 40.8292\n",
      "Iteration: 3283; Percent complete: 65.7%; Average loss: 3.5795 Perplexity: 35.8563\n",
      "Iteration: 3284; Percent complete: 65.7%; Average loss: 3.7273 Perplexity: 41.5667\n",
      "Iteration: 3285; Percent complete: 65.7%; Average loss: 3.8228 Perplexity: 45.7307\n",
      "Iteration: 3286; Percent complete: 65.7%; Average loss: 3.6573 Perplexity: 38.7584\n",
      "Iteration: 3287; Percent complete: 65.7%; Average loss: 3.8499 Perplexity: 46.9885\n",
      "Iteration: 3288; Percent complete: 65.8%; Average loss: 4.0071 Perplexity: 54.9891\n",
      "Iteration: 3289; Percent complete: 65.8%; Average loss: 4.1790 Perplexity: 65.2980\n",
      "Iteration: 3290; Percent complete: 65.8%; Average loss: 3.6980 Perplexity: 40.3658\n",
      "Iteration: 3291; Percent complete: 65.8%; Average loss: 3.6658 Perplexity: 39.0882\n",
      "Iteration: 3292; Percent complete: 65.8%; Average loss: 3.8706 Perplexity: 47.9694\n",
      "Iteration: 3293; Percent complete: 65.9%; Average loss: 3.9854 Perplexity: 53.8053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3294; Percent complete: 65.9%; Average loss: 3.8859 Perplexity: 48.7107\n",
      "Iteration: 3295; Percent complete: 65.9%; Average loss: 3.9343 Perplexity: 51.1284\n",
      "Iteration: 3296; Percent complete: 65.9%; Average loss: 3.5124 Perplexity: 33.5284\n",
      "Iteration: 3297; Percent complete: 65.9%; Average loss: 3.6772 Perplexity: 39.5337\n",
      "Iteration: 3298; Percent complete: 66.0%; Average loss: 3.7102 Perplexity: 40.8630\n",
      "Iteration: 3299; Percent complete: 66.0%; Average loss: 3.9874 Perplexity: 53.9119\n",
      "Iteration: 3300; Percent complete: 66.0%; Average loss: 4.1211 Perplexity: 61.6296\n",
      "Iteration: 3301; Percent complete: 66.0%; Average loss: 3.9211 Perplexity: 50.4545\n",
      "Iteration: 3302; Percent complete: 66.0%; Average loss: 3.6607 Perplexity: 38.8874\n",
      "Iteration: 3303; Percent complete: 66.1%; Average loss: 3.8727 Perplexity: 48.0719\n",
      "Iteration: 3304; Percent complete: 66.1%; Average loss: 3.6484 Perplexity: 38.4148\n",
      "Iteration: 3305; Percent complete: 66.1%; Average loss: 3.8598 Perplexity: 47.4580\n",
      "Iteration: 3306; Percent complete: 66.1%; Average loss: 3.7938 Perplexity: 44.4235\n",
      "Iteration: 3307; Percent complete: 66.1%; Average loss: 3.7101 Perplexity: 40.8587\n",
      "Iteration: 3308; Percent complete: 66.2%; Average loss: 3.5021 Perplexity: 33.1843\n",
      "Iteration: 3309; Percent complete: 66.2%; Average loss: 4.0028 Perplexity: 54.7512\n",
      "Iteration: 3310; Percent complete: 66.2%; Average loss: 3.4191 Perplexity: 30.5427\n",
      "Iteration: 3311; Percent complete: 66.2%; Average loss: 4.0877 Perplexity: 59.6027\n",
      "Iteration: 3312; Percent complete: 66.2%; Average loss: 3.4653 Perplexity: 31.9853\n",
      "Iteration: 3313; Percent complete: 66.3%; Average loss: 3.4406 Perplexity: 31.2064\n",
      "Iteration: 3314; Percent complete: 66.3%; Average loss: 3.4615 Perplexity: 31.8646\n",
      "Iteration: 3315; Percent complete: 66.3%; Average loss: 3.7217 Perplexity: 41.3333\n",
      "Iteration: 3316; Percent complete: 66.3%; Average loss: 3.6823 Perplexity: 39.7382\n",
      "Iteration: 3317; Percent complete: 66.3%; Average loss: 3.7527 Perplexity: 42.6353\n",
      "Iteration: 3318; Percent complete: 66.4%; Average loss: 3.6669 Perplexity: 39.1290\n",
      "Iteration: 3319; Percent complete: 66.4%; Average loss: 3.8526 Perplexity: 47.1136\n",
      "Iteration: 3320; Percent complete: 66.4%; Average loss: 3.9931 Perplexity: 54.2223\n",
      "Iteration: 3321; Percent complete: 66.4%; Average loss: 3.5714 Perplexity: 35.5650\n",
      "Iteration: 3322; Percent complete: 66.4%; Average loss: 3.3889 Perplexity: 29.6331\n",
      "Iteration: 3323; Percent complete: 66.5%; Average loss: 4.1825 Perplexity: 65.5278\n",
      "Iteration: 3324; Percent complete: 66.5%; Average loss: 4.4182 Perplexity: 82.9470\n",
      "Iteration: 3325; Percent complete: 66.5%; Average loss: 4.2096 Perplexity: 67.3305\n",
      "Iteration: 3326; Percent complete: 66.5%; Average loss: 4.0702 Perplexity: 58.5690\n",
      "Iteration: 3327; Percent complete: 66.5%; Average loss: 3.4893 Perplexity: 32.7617\n",
      "Iteration: 3328; Percent complete: 66.6%; Average loss: 4.1804 Perplexity: 65.3928\n",
      "Iteration: 3329; Percent complete: 66.6%; Average loss: 3.7910 Perplexity: 44.3014\n",
      "Iteration: 3330; Percent complete: 66.6%; Average loss: 3.7220 Perplexity: 41.3479\n",
      "Iteration: 3331; Percent complete: 66.6%; Average loss: 4.2138 Perplexity: 67.6152\n",
      "Iteration: 3332; Percent complete: 66.6%; Average loss: 3.8305 Perplexity: 46.0879\n",
      "Iteration: 3333; Percent complete: 66.7%; Average loss: 3.8032 Perplexity: 44.8426\n",
      "Iteration: 3334; Percent complete: 66.7%; Average loss: 4.0148 Perplexity: 55.4121\n",
      "Iteration: 3335; Percent complete: 66.7%; Average loss: 3.5640 Perplexity: 35.3024\n",
      "Iteration: 3336; Percent complete: 66.7%; Average loss: 3.5772 Perplexity: 35.7720\n",
      "Iteration: 3337; Percent complete: 66.7%; Average loss: 3.5846 Perplexity: 36.0402\n",
      "Iteration: 3338; Percent complete: 66.8%; Average loss: 3.6878 Perplexity: 39.9570\n",
      "Iteration: 3339; Percent complete: 66.8%; Average loss: 4.1165 Perplexity: 61.3457\n",
      "Iteration: 3340; Percent complete: 66.8%; Average loss: 3.3586 Perplexity: 28.7487\n",
      "Iteration: 3341; Percent complete: 66.8%; Average loss: 3.6805 Perplexity: 39.6681\n",
      "Iteration: 3342; Percent complete: 66.8%; Average loss: 4.0327 Perplexity: 56.4110\n",
      "Iteration: 3343; Percent complete: 66.9%; Average loss: 3.8028 Perplexity: 44.8268\n",
      "Iteration: 3344; Percent complete: 66.9%; Average loss: 3.8090 Perplexity: 45.1065\n",
      "Iteration: 3345; Percent complete: 66.9%; Average loss: 3.8645 Perplexity: 47.6781\n",
      "Iteration: 3346; Percent complete: 66.9%; Average loss: 3.8154 Perplexity: 45.3934\n",
      "Iteration: 3347; Percent complete: 66.9%; Average loss: 3.7532 Perplexity: 42.6572\n",
      "Iteration: 3348; Percent complete: 67.0%; Average loss: 3.3155 Perplexity: 27.5350\n",
      "Iteration: 3349; Percent complete: 67.0%; Average loss: 3.8320 Perplexity: 46.1564\n",
      "Iteration: 3350; Percent complete: 67.0%; Average loss: 3.8183 Perplexity: 45.5290\n",
      "Iteration: 3351; Percent complete: 67.0%; Average loss: 3.3911 Perplexity: 29.6992\n",
      "Iteration: 3352; Percent complete: 67.0%; Average loss: 3.5869 Perplexity: 36.1236\n",
      "Iteration: 3353; Percent complete: 67.1%; Average loss: 3.9248 Perplexity: 50.6450\n",
      "Iteration: 3354; Percent complete: 67.1%; Average loss: 3.6121 Perplexity: 37.0435\n",
      "Iteration: 3355; Percent complete: 67.1%; Average loss: 3.5669 Perplexity: 35.4051\n",
      "Iteration: 3356; Percent complete: 67.1%; Average loss: 3.6130 Perplexity: 37.0758\n",
      "Iteration: 3357; Percent complete: 67.1%; Average loss: 4.0718 Perplexity: 58.6615\n",
      "Iteration: 3358; Percent complete: 67.2%; Average loss: 4.0456 Perplexity: 57.1442\n",
      "Iteration: 3359; Percent complete: 67.2%; Average loss: 3.3770 Perplexity: 29.2817\n",
      "Iteration: 3360; Percent complete: 67.2%; Average loss: 3.6688 Perplexity: 39.2030\n",
      "Iteration: 3361; Percent complete: 67.2%; Average loss: 3.8866 Perplexity: 48.7443\n",
      "Iteration: 3362; Percent complete: 67.2%; Average loss: 4.0378 Perplexity: 56.6989\n",
      "Iteration: 3363; Percent complete: 67.3%; Average loss: 3.4498 Perplexity: 31.4946\n",
      "Iteration: 3364; Percent complete: 67.3%; Average loss: 3.6478 Perplexity: 38.3896\n",
      "Iteration: 3365; Percent complete: 67.3%; Average loss: 3.8992 Perplexity: 49.3618\n",
      "Iteration: 3366; Percent complete: 67.3%; Average loss: 3.6971 Perplexity: 40.3312\n",
      "Iteration: 3367; Percent complete: 67.3%; Average loss: 4.0291 Perplexity: 56.2108\n",
      "Iteration: 3368; Percent complete: 67.4%; Average loss: 3.4734 Perplexity: 32.2475\n",
      "Iteration: 3369; Percent complete: 67.4%; Average loss: 3.8580 Perplexity: 47.3708\n",
      "Iteration: 3370; Percent complete: 67.4%; Average loss: 3.8011 Perplexity: 44.7507\n",
      "Iteration: 3371; Percent complete: 67.4%; Average loss: 3.8142 Perplexity: 45.3389\n",
      "Iteration: 3372; Percent complete: 67.4%; Average loss: 3.8192 Perplexity: 45.5692\n",
      "Iteration: 3373; Percent complete: 67.5%; Average loss: 3.8389 Perplexity: 46.4747\n",
      "Iteration: 3374; Percent complete: 67.5%; Average loss: 4.1923 Perplexity: 66.1732\n",
      "Iteration: 3375; Percent complete: 67.5%; Average loss: 3.6426 Perplexity: 38.1906\n",
      "Iteration: 3376; Percent complete: 67.5%; Average loss: 3.9325 Perplexity: 51.0334\n",
      "Iteration: 3377; Percent complete: 67.5%; Average loss: 3.7851 Perplexity: 44.0407\n",
      "Iteration: 3378; Percent complete: 67.6%; Average loss: 3.5326 Perplexity: 34.2111\n",
      "Iteration: 3379; Percent complete: 67.6%; Average loss: 3.7292 Perplexity: 41.6477\n",
      "Iteration: 3380; Percent complete: 67.6%; Average loss: 3.4834 Perplexity: 32.5710\n",
      "Iteration: 3381; Percent complete: 67.6%; Average loss: 3.4299 Perplexity: 30.8736\n",
      "Iteration: 3382; Percent complete: 67.6%; Average loss: 3.8580 Perplexity: 47.3712\n",
      "Iteration: 3383; Percent complete: 67.7%; Average loss: 3.7638 Perplexity: 43.1135\n",
      "Iteration: 3384; Percent complete: 67.7%; Average loss: 3.8076 Perplexity: 45.0414\n",
      "Iteration: 3385; Percent complete: 67.7%; Average loss: 3.7589 Perplexity: 42.9017\n",
      "Iteration: 3386; Percent complete: 67.7%; Average loss: 3.4571 Perplexity: 31.7259\n",
      "Iteration: 3387; Percent complete: 67.7%; Average loss: 3.8421 Perplexity: 46.6211\n",
      "Iteration: 3388; Percent complete: 67.8%; Average loss: 3.9985 Perplexity: 54.5176\n",
      "Iteration: 3389; Percent complete: 67.8%; Average loss: 3.7329 Perplexity: 41.7989\n",
      "Iteration: 3390; Percent complete: 67.8%; Average loss: 4.1697 Perplexity: 64.6944\n",
      "Iteration: 3391; Percent complete: 67.8%; Average loss: 3.7219 Perplexity: 41.3442\n",
      "Iteration: 3392; Percent complete: 67.8%; Average loss: 3.6934 Perplexity: 40.1831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3393; Percent complete: 67.9%; Average loss: 4.3642 Perplexity: 78.5859\n",
      "Iteration: 3394; Percent complete: 67.9%; Average loss: 4.0002 Perplexity: 54.6079\n",
      "Iteration: 3395; Percent complete: 67.9%; Average loss: 3.2808 Perplexity: 26.5964\n",
      "Iteration: 3396; Percent complete: 67.9%; Average loss: 3.5553 Perplexity: 34.9980\n",
      "Iteration: 3397; Percent complete: 67.9%; Average loss: 3.7384 Perplexity: 42.0318\n",
      "Iteration: 3398; Percent complete: 68.0%; Average loss: 3.9194 Perplexity: 50.3702\n",
      "Iteration: 3399; Percent complete: 68.0%; Average loss: 3.5212 Perplexity: 33.8255\n",
      "Iteration: 3400; Percent complete: 68.0%; Average loss: 3.3196 Perplexity: 27.6486\n",
      "Iteration: 3401; Percent complete: 68.0%; Average loss: 3.6042 Perplexity: 36.7509\n",
      "Iteration: 3402; Percent complete: 68.0%; Average loss: 3.5844 Perplexity: 36.0312\n",
      "Iteration: 3403; Percent complete: 68.1%; Average loss: 3.9627 Perplexity: 52.5995\n",
      "Iteration: 3404; Percent complete: 68.1%; Average loss: 3.7942 Perplexity: 44.4429\n",
      "Iteration: 3405; Percent complete: 68.1%; Average loss: 3.9125 Perplexity: 50.0250\n",
      "Iteration: 3406; Percent complete: 68.1%; Average loss: 3.6859 Perplexity: 39.8820\n",
      "Iteration: 3407; Percent complete: 68.1%; Average loss: 3.1239 Perplexity: 22.7348\n",
      "Iteration: 3408; Percent complete: 68.2%; Average loss: 3.6592 Perplexity: 38.8285\n",
      "Iteration: 3409; Percent complete: 68.2%; Average loss: 3.5271 Perplexity: 34.0266\n",
      "Iteration: 3410; Percent complete: 68.2%; Average loss: 3.9252 Perplexity: 50.6627\n",
      "Iteration: 3411; Percent complete: 68.2%; Average loss: 4.0011 Perplexity: 54.6581\n",
      "Iteration: 3412; Percent complete: 68.2%; Average loss: 3.5041 Perplexity: 33.2516\n",
      "Iteration: 3413; Percent complete: 68.3%; Average loss: 4.1741 Perplexity: 64.9786\n",
      "Iteration: 3414; Percent complete: 68.3%; Average loss: 3.7802 Perplexity: 43.8231\n",
      "Iteration: 3415; Percent complete: 68.3%; Average loss: 3.6102 Perplexity: 36.9719\n",
      "Iteration: 3416; Percent complete: 68.3%; Average loss: 3.2665 Perplexity: 26.2200\n",
      "Iteration: 3417; Percent complete: 68.3%; Average loss: 3.9632 Perplexity: 52.6264\n",
      "Iteration: 3418; Percent complete: 68.4%; Average loss: 4.0476 Perplexity: 57.2622\n",
      "Iteration: 3419; Percent complete: 68.4%; Average loss: 4.0474 Perplexity: 57.2508\n",
      "Iteration: 3420; Percent complete: 68.4%; Average loss: 3.8255 Perplexity: 45.8535\n",
      "Iteration: 3421; Percent complete: 68.4%; Average loss: 3.7426 Perplexity: 42.2092\n",
      "Iteration: 3422; Percent complete: 68.4%; Average loss: 3.6812 Perplexity: 39.6930\n",
      "Iteration: 3423; Percent complete: 68.5%; Average loss: 3.7621 Perplexity: 43.0405\n",
      "Iteration: 3424; Percent complete: 68.5%; Average loss: 3.7068 Perplexity: 40.7241\n",
      "Iteration: 3425; Percent complete: 68.5%; Average loss: 3.7037 Perplexity: 40.5989\n",
      "Iteration: 3426; Percent complete: 68.5%; Average loss: 3.2680 Perplexity: 26.2575\n",
      "Iteration: 3427; Percent complete: 68.5%; Average loss: 4.0016 Perplexity: 54.6862\n",
      "Iteration: 3428; Percent complete: 68.6%; Average loss: 3.2333 Perplexity: 25.3643\n",
      "Iteration: 3429; Percent complete: 68.6%; Average loss: 3.6186 Perplexity: 37.2872\n",
      "Iteration: 3430; Percent complete: 68.6%; Average loss: 3.8459 Perplexity: 46.7990\n",
      "Iteration: 3431; Percent complete: 68.6%; Average loss: 3.5608 Perplexity: 35.1905\n",
      "Iteration: 3432; Percent complete: 68.6%; Average loss: 3.3319 Perplexity: 27.9903\n",
      "Iteration: 3433; Percent complete: 68.7%; Average loss: 3.9381 Perplexity: 51.3234\n",
      "Iteration: 3434; Percent complete: 68.7%; Average loss: 3.9026 Perplexity: 49.5326\n",
      "Iteration: 3435; Percent complete: 68.7%; Average loss: 3.3800 Perplexity: 29.3711\n",
      "Iteration: 3436; Percent complete: 68.7%; Average loss: 4.3527 Perplexity: 77.6874\n",
      "Iteration: 3437; Percent complete: 68.7%; Average loss: 3.8946 Perplexity: 49.1369\n",
      "Iteration: 3438; Percent complete: 68.8%; Average loss: 3.5839 Perplexity: 36.0141\n",
      "Iteration: 3439; Percent complete: 68.8%; Average loss: 3.2882 Perplexity: 26.7936\n",
      "Iteration: 3440; Percent complete: 68.8%; Average loss: 3.9185 Perplexity: 50.3249\n",
      "Iteration: 3441; Percent complete: 68.8%; Average loss: 4.0390 Perplexity: 56.7715\n",
      "Iteration: 3442; Percent complete: 68.8%; Average loss: 3.7473 Perplexity: 42.4053\n",
      "Iteration: 3443; Percent complete: 68.9%; Average loss: 3.7123 Perplexity: 40.9472\n",
      "Iteration: 3444; Percent complete: 68.9%; Average loss: 4.1912 Perplexity: 66.1051\n",
      "Iteration: 3445; Percent complete: 68.9%; Average loss: 3.6055 Perplexity: 36.8013\n",
      "Iteration: 3446; Percent complete: 68.9%; Average loss: 3.6156 Perplexity: 37.1721\n",
      "Iteration: 3447; Percent complete: 68.9%; Average loss: 3.8178 Perplexity: 45.5041\n",
      "Iteration: 3448; Percent complete: 69.0%; Average loss: 4.0604 Perplexity: 57.9965\n",
      "Iteration: 3449; Percent complete: 69.0%; Average loss: 3.5678 Perplexity: 35.4382\n",
      "Iteration: 3450; Percent complete: 69.0%; Average loss: 3.9465 Perplexity: 51.7544\n",
      "Iteration: 3451; Percent complete: 69.0%; Average loss: 3.7758 Perplexity: 43.6313\n",
      "Iteration: 3452; Percent complete: 69.0%; Average loss: 3.6073 Perplexity: 36.8677\n",
      "Iteration: 3453; Percent complete: 69.1%; Average loss: 3.9557 Perplexity: 52.2313\n",
      "Iteration: 3454; Percent complete: 69.1%; Average loss: 3.7901 Perplexity: 44.2613\n",
      "Iteration: 3455; Percent complete: 69.1%; Average loss: 3.8929 Perplexity: 49.0514\n",
      "Iteration: 3456; Percent complete: 69.1%; Average loss: 3.9321 Perplexity: 51.0154\n",
      "Iteration: 3457; Percent complete: 69.1%; Average loss: 3.6547 Perplexity: 38.6578\n",
      "Iteration: 3458; Percent complete: 69.2%; Average loss: 3.7715 Perplexity: 43.4438\n",
      "Iteration: 3459; Percent complete: 69.2%; Average loss: 4.0926 Perplexity: 59.8959\n",
      "Iteration: 3460; Percent complete: 69.2%; Average loss: 3.9614 Perplexity: 52.5325\n",
      "Iteration: 3461; Percent complete: 69.2%; Average loss: 3.5858 Perplexity: 36.0812\n",
      "Iteration: 3462; Percent complete: 69.2%; Average loss: 3.6262 Perplexity: 37.5713\n",
      "Iteration: 3463; Percent complete: 69.3%; Average loss: 3.9933 Perplexity: 54.2340\n",
      "Iteration: 3464; Percent complete: 69.3%; Average loss: 3.6627 Perplexity: 38.9649\n",
      "Iteration: 3465; Percent complete: 69.3%; Average loss: 3.7134 Perplexity: 40.9923\n",
      "Iteration: 3466; Percent complete: 69.3%; Average loss: 3.4787 Perplexity: 32.4162\n",
      "Iteration: 3467; Percent complete: 69.3%; Average loss: 3.8313 Perplexity: 46.1248\n",
      "Iteration: 3468; Percent complete: 69.4%; Average loss: 3.5508 Perplexity: 34.8419\n",
      "Iteration: 3469; Percent complete: 69.4%; Average loss: 3.5660 Perplexity: 35.3753\n",
      "Iteration: 3470; Percent complete: 69.4%; Average loss: 3.9419 Perplexity: 51.5154\n",
      "Iteration: 3471; Percent complete: 69.4%; Average loss: 3.8025 Perplexity: 44.8132\n",
      "Iteration: 3472; Percent complete: 69.4%; Average loss: 3.8580 Perplexity: 47.3683\n",
      "Iteration: 3473; Percent complete: 69.5%; Average loss: 3.6030 Perplexity: 36.7092\n",
      "Iteration: 3474; Percent complete: 69.5%; Average loss: 3.9762 Perplexity: 53.3136\n",
      "Iteration: 3475; Percent complete: 69.5%; Average loss: 3.7344 Perplexity: 41.8643\n",
      "Iteration: 3476; Percent complete: 69.5%; Average loss: 3.6952 Perplexity: 40.2556\n",
      "Iteration: 3477; Percent complete: 69.5%; Average loss: 3.4635 Perplexity: 31.9289\n",
      "Iteration: 3478; Percent complete: 69.6%; Average loss: 3.5835 Perplexity: 35.9981\n",
      "Iteration: 3479; Percent complete: 69.6%; Average loss: 3.8199 Perplexity: 45.6017\n",
      "Iteration: 3480; Percent complete: 69.6%; Average loss: 3.6305 Perplexity: 37.7309\n",
      "Iteration: 3481; Percent complete: 69.6%; Average loss: 3.5800 Perplexity: 35.8727\n",
      "Iteration: 3482; Percent complete: 69.6%; Average loss: 3.5987 Perplexity: 36.5522\n",
      "Iteration: 3483; Percent complete: 69.7%; Average loss: 3.6711 Perplexity: 39.2949\n",
      "Iteration: 3484; Percent complete: 69.7%; Average loss: 3.4603 Perplexity: 31.8261\n",
      "Iteration: 3485; Percent complete: 69.7%; Average loss: 3.5776 Perplexity: 35.7891\n",
      "Iteration: 3486; Percent complete: 69.7%; Average loss: 3.5869 Perplexity: 36.1229\n",
      "Iteration: 3487; Percent complete: 69.7%; Average loss: 3.6642 Perplexity: 39.0255\n",
      "Iteration: 3488; Percent complete: 69.8%; Average loss: 3.5739 Perplexity: 35.6566\n",
      "Iteration: 3489; Percent complete: 69.8%; Average loss: 3.7444 Perplexity: 42.2829\n",
      "Iteration: 3490; Percent complete: 69.8%; Average loss: 3.3286 Perplexity: 27.8996\n",
      "Iteration: 3491; Percent complete: 69.8%; Average loss: 3.9154 Perplexity: 50.1710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3492; Percent complete: 69.8%; Average loss: 3.5857 Perplexity: 36.0787\n",
      "Iteration: 3493; Percent complete: 69.9%; Average loss: 3.7424 Perplexity: 42.1990\n",
      "Iteration: 3494; Percent complete: 69.9%; Average loss: 3.8664 Perplexity: 47.7712\n",
      "Iteration: 3495; Percent complete: 69.9%; Average loss: 3.6344 Perplexity: 37.8803\n",
      "Iteration: 3496; Percent complete: 69.9%; Average loss: 3.8845 Perplexity: 48.6427\n",
      "Iteration: 3497; Percent complete: 69.9%; Average loss: 3.5442 Perplexity: 34.6123\n",
      "Iteration: 3498; Percent complete: 70.0%; Average loss: 4.1414 Perplexity: 62.8893\n",
      "Iteration: 3499; Percent complete: 70.0%; Average loss: 3.7712 Perplexity: 43.4313\n",
      "Iteration: 3500; Percent complete: 70.0%; Average loss: 4.3050 Perplexity: 74.0698\n",
      "Iteration: 3501; Percent complete: 70.0%; Average loss: 3.6810 Perplexity: 39.6857\n",
      "Iteration: 3502; Percent complete: 70.0%; Average loss: 3.6952 Perplexity: 40.2526\n",
      "Iteration: 3503; Percent complete: 70.1%; Average loss: 3.4662 Perplexity: 32.0144\n",
      "Iteration: 3504; Percent complete: 70.1%; Average loss: 4.1649 Perplexity: 64.3861\n",
      "Iteration: 3505; Percent complete: 70.1%; Average loss: 3.5358 Perplexity: 34.3229\n",
      "Iteration: 3506; Percent complete: 70.1%; Average loss: 3.5070 Perplexity: 33.3471\n",
      "Iteration: 3507; Percent complete: 70.1%; Average loss: 3.9300 Perplexity: 50.9084\n",
      "Iteration: 3508; Percent complete: 70.2%; Average loss: 3.6184 Perplexity: 37.2766\n",
      "Iteration: 3509; Percent complete: 70.2%; Average loss: 3.9973 Perplexity: 54.4500\n",
      "Iteration: 3510; Percent complete: 70.2%; Average loss: 3.7313 Perplexity: 41.7341\n",
      "Iteration: 3511; Percent complete: 70.2%; Average loss: 3.5460 Perplexity: 34.6750\n",
      "Iteration: 3512; Percent complete: 70.2%; Average loss: 3.6983 Perplexity: 40.3783\n",
      "Iteration: 3513; Percent complete: 70.3%; Average loss: 3.4592 Perplexity: 31.7911\n",
      "Iteration: 3514; Percent complete: 70.3%; Average loss: 3.5603 Perplexity: 35.1745\n",
      "Iteration: 3515; Percent complete: 70.3%; Average loss: 3.8099 Perplexity: 45.1479\n",
      "Iteration: 3516; Percent complete: 70.3%; Average loss: 4.1736 Perplexity: 64.9476\n",
      "Iteration: 3517; Percent complete: 70.3%; Average loss: 3.6400 Perplexity: 38.0916\n",
      "Iteration: 3518; Percent complete: 70.4%; Average loss: 3.4974 Perplexity: 33.0308\n",
      "Iteration: 3519; Percent complete: 70.4%; Average loss: 3.4096 Perplexity: 30.2533\n",
      "Iteration: 3520; Percent complete: 70.4%; Average loss: 3.7975 Perplexity: 44.5882\n",
      "Iteration: 3521; Percent complete: 70.4%; Average loss: 3.5853 Perplexity: 36.0641\n",
      "Iteration: 3522; Percent complete: 70.4%; Average loss: 3.9530 Perplexity: 52.0925\n",
      "Iteration: 3523; Percent complete: 70.5%; Average loss: 3.5335 Perplexity: 34.2428\n",
      "Iteration: 3524; Percent complete: 70.5%; Average loss: 3.8286 Perplexity: 45.9970\n",
      "Iteration: 3525; Percent complete: 70.5%; Average loss: 3.4034 Perplexity: 30.0659\n",
      "Iteration: 3526; Percent complete: 70.5%; Average loss: 3.5953 Perplexity: 36.4251\n",
      "Iteration: 3527; Percent complete: 70.5%; Average loss: 3.6383 Perplexity: 38.0266\n",
      "Iteration: 3528; Percent complete: 70.6%; Average loss: 3.6118 Perplexity: 37.0338\n",
      "Iteration: 3529; Percent complete: 70.6%; Average loss: 3.6349 Perplexity: 37.8991\n",
      "Iteration: 3530; Percent complete: 70.6%; Average loss: 3.8682 Perplexity: 47.8545\n",
      "Iteration: 3531; Percent complete: 70.6%; Average loss: 4.1030 Perplexity: 60.5212\n",
      "Iteration: 3532; Percent complete: 70.6%; Average loss: 3.5804 Perplexity: 35.8890\n",
      "Iteration: 3533; Percent complete: 70.7%; Average loss: 3.9263 Perplexity: 50.7167\n",
      "Iteration: 3534; Percent complete: 70.7%; Average loss: 3.9600 Perplexity: 52.4563\n",
      "Iteration: 3535; Percent complete: 70.7%; Average loss: 3.6911 Perplexity: 40.0896\n",
      "Iteration: 3536; Percent complete: 70.7%; Average loss: 3.5931 Perplexity: 36.3448\n",
      "Iteration: 3537; Percent complete: 70.7%; Average loss: 3.7117 Perplexity: 40.9220\n",
      "Iteration: 3538; Percent complete: 70.8%; Average loss: 3.6587 Perplexity: 38.8101\n",
      "Iteration: 3539; Percent complete: 70.8%; Average loss: 3.4586 Perplexity: 31.7735\n",
      "Iteration: 3540; Percent complete: 70.8%; Average loss: 3.4515 Perplexity: 31.5465\n",
      "Iteration: 3541; Percent complete: 70.8%; Average loss: 3.9126 Perplexity: 50.0306\n",
      "Iteration: 3542; Percent complete: 70.8%; Average loss: 3.3741 Perplexity: 29.1977\n",
      "Iteration: 3543; Percent complete: 70.9%; Average loss: 3.7242 Perplexity: 41.4376\n",
      "Iteration: 3544; Percent complete: 70.9%; Average loss: 3.6639 Perplexity: 39.0114\n",
      "Iteration: 3545; Percent complete: 70.9%; Average loss: 3.7654 Perplexity: 43.1812\n",
      "Iteration: 3546; Percent complete: 70.9%; Average loss: 3.8371 Perplexity: 46.3930\n",
      "Iteration: 3547; Percent complete: 70.9%; Average loss: 3.6103 Perplexity: 36.9772\n",
      "Iteration: 3548; Percent complete: 71.0%; Average loss: 3.4146 Perplexity: 30.4057\n",
      "Iteration: 3549; Percent complete: 71.0%; Average loss: 3.7549 Perplexity: 42.7299\n",
      "Iteration: 3550; Percent complete: 71.0%; Average loss: 3.3152 Perplexity: 27.5287\n",
      "Iteration: 3551; Percent complete: 71.0%; Average loss: 3.7849 Perplexity: 44.0325\n",
      "Iteration: 3552; Percent complete: 71.0%; Average loss: 3.5393 Perplexity: 34.4413\n",
      "Iteration: 3553; Percent complete: 71.1%; Average loss: 3.6878 Perplexity: 39.9549\n",
      "Iteration: 3554; Percent complete: 71.1%; Average loss: 3.6861 Perplexity: 39.8882\n",
      "Iteration: 3555; Percent complete: 71.1%; Average loss: 3.4547 Perplexity: 31.6499\n",
      "Iteration: 3556; Percent complete: 71.1%; Average loss: 4.2464 Perplexity: 69.8524\n",
      "Iteration: 3557; Percent complete: 71.1%; Average loss: 3.7113 Perplexity: 40.9085\n",
      "Iteration: 3558; Percent complete: 71.2%; Average loss: 4.1870 Perplexity: 65.8231\n",
      "Iteration: 3559; Percent complete: 71.2%; Average loss: 3.6031 Perplexity: 36.7126\n",
      "Iteration: 3560; Percent complete: 71.2%; Average loss: 4.3661 Perplexity: 78.7345\n",
      "Iteration: 3561; Percent complete: 71.2%; Average loss: 3.4445 Perplexity: 31.3277\n",
      "Iteration: 3562; Percent complete: 71.2%; Average loss: 3.2941 Perplexity: 26.9526\n",
      "Iteration: 3563; Percent complete: 71.3%; Average loss: 3.6077 Perplexity: 36.8823\n",
      "Iteration: 3564; Percent complete: 71.3%; Average loss: 3.5663 Perplexity: 35.3850\n",
      "Iteration: 3565; Percent complete: 71.3%; Average loss: 3.8377 Perplexity: 46.4171\n",
      "Iteration: 3566; Percent complete: 71.3%; Average loss: 3.4003 Perplexity: 29.9724\n",
      "Iteration: 3567; Percent complete: 71.3%; Average loss: 3.8088 Perplexity: 45.0984\n",
      "Iteration: 3568; Percent complete: 71.4%; Average loss: 3.6993 Perplexity: 40.4198\n",
      "Iteration: 3569; Percent complete: 71.4%; Average loss: 3.7566 Perplexity: 42.8047\n",
      "Iteration: 3570; Percent complete: 71.4%; Average loss: 3.6482 Perplexity: 38.4059\n",
      "Iteration: 3571; Percent complete: 71.4%; Average loss: 4.3029 Perplexity: 73.9142\n",
      "Iteration: 3572; Percent complete: 71.4%; Average loss: 3.4280 Perplexity: 30.8150\n",
      "Iteration: 3573; Percent complete: 71.5%; Average loss: 3.6899 Perplexity: 40.0426\n",
      "Iteration: 3574; Percent complete: 71.5%; Average loss: 3.5398 Perplexity: 34.4594\n",
      "Iteration: 3575; Percent complete: 71.5%; Average loss: 3.2302 Perplexity: 25.2837\n",
      "Iteration: 3576; Percent complete: 71.5%; Average loss: 3.6573 Perplexity: 38.7559\n",
      "Iteration: 3577; Percent complete: 71.5%; Average loss: 3.6681 Perplexity: 39.1778\n",
      "Iteration: 3578; Percent complete: 71.6%; Average loss: 3.7476 Perplexity: 42.4191\n",
      "Iteration: 3579; Percent complete: 71.6%; Average loss: 3.7489 Perplexity: 42.4751\n",
      "Iteration: 3580; Percent complete: 71.6%; Average loss: 3.1892 Perplexity: 24.2698\n",
      "Iteration: 3581; Percent complete: 71.6%; Average loss: 3.3869 Perplexity: 29.5755\n",
      "Iteration: 3582; Percent complete: 71.6%; Average loss: 3.6784 Perplexity: 39.5849\n",
      "Iteration: 3583; Percent complete: 71.7%; Average loss: 3.5235 Perplexity: 33.9037\n",
      "Iteration: 3584; Percent complete: 71.7%; Average loss: 3.3520 Perplexity: 28.5598\n",
      "Iteration: 3585; Percent complete: 71.7%; Average loss: 3.5749 Perplexity: 35.6924\n",
      "Iteration: 3586; Percent complete: 71.7%; Average loss: 4.0803 Perplexity: 59.1605\n",
      "Iteration: 3587; Percent complete: 71.7%; Average loss: 3.7017 Perplexity: 40.5174\n",
      "Iteration: 3588; Percent complete: 71.8%; Average loss: 3.7367 Perplexity: 41.9603\n",
      "Iteration: 3589; Percent complete: 71.8%; Average loss: 3.3095 Perplexity: 27.3714\n",
      "Iteration: 3590; Percent complete: 71.8%; Average loss: 4.1309 Perplexity: 62.2362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3591; Percent complete: 71.8%; Average loss: 3.4211 Perplexity: 30.6024\n",
      "Iteration: 3592; Percent complete: 71.8%; Average loss: 3.6326 Perplexity: 37.8112\n",
      "Iteration: 3593; Percent complete: 71.9%; Average loss: 3.4545 Perplexity: 31.6417\n",
      "Iteration: 3594; Percent complete: 71.9%; Average loss: 3.7678 Perplexity: 43.2835\n",
      "Iteration: 3595; Percent complete: 71.9%; Average loss: 3.3721 Perplexity: 29.1404\n",
      "Iteration: 3596; Percent complete: 71.9%; Average loss: 3.2774 Perplexity: 26.5061\n",
      "Iteration: 3597; Percent complete: 71.9%; Average loss: 3.8577 Perplexity: 47.3572\n",
      "Iteration: 3598; Percent complete: 72.0%; Average loss: 3.5527 Perplexity: 34.9079\n",
      "Iteration: 3599; Percent complete: 72.0%; Average loss: 3.5390 Perplexity: 34.4308\n",
      "Iteration: 3600; Percent complete: 72.0%; Average loss: 3.7417 Perplexity: 42.1677\n",
      "Iteration: 3601; Percent complete: 72.0%; Average loss: 3.7196 Perplexity: 41.2466\n",
      "Iteration: 3602; Percent complete: 72.0%; Average loss: 3.6834 Perplexity: 39.7800\n",
      "Iteration: 3603; Percent complete: 72.1%; Average loss: 3.6950 Perplexity: 40.2439\n",
      "Iteration: 3604; Percent complete: 72.1%; Average loss: 3.3796 Perplexity: 29.3589\n",
      "Iteration: 3605; Percent complete: 72.1%; Average loss: 3.3837 Perplexity: 29.4797\n",
      "Iteration: 3606; Percent complete: 72.1%; Average loss: 3.7995 Perplexity: 44.6805\n",
      "Iteration: 3607; Percent complete: 72.1%; Average loss: 3.4924 Perplexity: 32.8650\n",
      "Iteration: 3608; Percent complete: 72.2%; Average loss: 3.5560 Perplexity: 35.0235\n",
      "Iteration: 3609; Percent complete: 72.2%; Average loss: 3.7290 Perplexity: 41.6386\n",
      "Iteration: 3610; Percent complete: 72.2%; Average loss: 3.7942 Perplexity: 44.4419\n",
      "Iteration: 3611; Percent complete: 72.2%; Average loss: 3.7358 Perplexity: 41.9212\n",
      "Iteration: 3612; Percent complete: 72.2%; Average loss: 3.8625 Perplexity: 47.5835\n",
      "Iteration: 3613; Percent complete: 72.3%; Average loss: 3.3894 Perplexity: 29.6494\n",
      "Iteration: 3614; Percent complete: 72.3%; Average loss: 3.5984 Perplexity: 36.5400\n",
      "Iteration: 3615; Percent complete: 72.3%; Average loss: 3.7081 Perplexity: 40.7742\n",
      "Iteration: 3616; Percent complete: 72.3%; Average loss: 3.8112 Perplexity: 45.2065\n",
      "Iteration: 3617; Percent complete: 72.3%; Average loss: 3.7117 Perplexity: 40.9219\n",
      "Iteration: 3618; Percent complete: 72.4%; Average loss: 4.0752 Perplexity: 58.8627\n",
      "Iteration: 3619; Percent complete: 72.4%; Average loss: 3.3718 Perplexity: 29.1303\n",
      "Iteration: 3620; Percent complete: 72.4%; Average loss: 3.8467 Perplexity: 46.8362\n",
      "Iteration: 3621; Percent complete: 72.4%; Average loss: 3.6091 Perplexity: 36.9318\n",
      "Iteration: 3622; Percent complete: 72.4%; Average loss: 3.8536 Perplexity: 47.1612\n",
      "Iteration: 3623; Percent complete: 72.5%; Average loss: 3.8335 Perplexity: 46.2261\n",
      "Iteration: 3624; Percent complete: 72.5%; Average loss: 3.9873 Perplexity: 53.9105\n",
      "Iteration: 3625; Percent complete: 72.5%; Average loss: 3.7889 Perplexity: 44.2099\n",
      "Iteration: 3626; Percent complete: 72.5%; Average loss: 3.7698 Perplexity: 43.3696\n",
      "Iteration: 3627; Percent complete: 72.5%; Average loss: 3.4950 Perplexity: 32.9497\n",
      "Iteration: 3628; Percent complete: 72.6%; Average loss: 3.0560 Perplexity: 21.2425\n",
      "Iteration: 3629; Percent complete: 72.6%; Average loss: 3.7500 Perplexity: 42.5208\n",
      "Iteration: 3630; Percent complete: 72.6%; Average loss: 3.6175 Perplexity: 37.2452\n",
      "Iteration: 3631; Percent complete: 72.6%; Average loss: 3.5069 Perplexity: 33.3433\n",
      "Iteration: 3632; Percent complete: 72.6%; Average loss: 3.3623 Perplexity: 28.8554\n",
      "Iteration: 3633; Percent complete: 72.7%; Average loss: 3.2695 Perplexity: 26.2984\n",
      "Iteration: 3634; Percent complete: 72.7%; Average loss: 3.8046 Perplexity: 44.9067\n",
      "Iteration: 3635; Percent complete: 72.7%; Average loss: 3.6376 Perplexity: 38.0006\n",
      "Iteration: 3636; Percent complete: 72.7%; Average loss: 3.6059 Perplexity: 36.8143\n",
      "Iteration: 3637; Percent complete: 72.7%; Average loss: 3.4507 Perplexity: 31.5217\n",
      "Iteration: 3638; Percent complete: 72.8%; Average loss: 3.8619 Perplexity: 47.5552\n",
      "Iteration: 3639; Percent complete: 72.8%; Average loss: 3.9074 Perplexity: 49.7717\n",
      "Iteration: 3640; Percent complete: 72.8%; Average loss: 3.6610 Perplexity: 38.9010\n",
      "Iteration: 3641; Percent complete: 72.8%; Average loss: 3.5657 Perplexity: 35.3630\n",
      "Iteration: 3642; Percent complete: 72.8%; Average loss: 3.7918 Perplexity: 44.3369\n",
      "Iteration: 3643; Percent complete: 72.9%; Average loss: 3.4695 Perplexity: 32.1201\n",
      "Iteration: 3644; Percent complete: 72.9%; Average loss: 4.1011 Perplexity: 60.4049\n",
      "Iteration: 3645; Percent complete: 72.9%; Average loss: 3.7602 Perplexity: 42.9581\n",
      "Iteration: 3646; Percent complete: 72.9%; Average loss: 3.7247 Perplexity: 41.4605\n",
      "Iteration: 3647; Percent complete: 72.9%; Average loss: 3.3932 Perplexity: 29.7614\n",
      "Iteration: 3648; Percent complete: 73.0%; Average loss: 3.6261 Perplexity: 37.5679\n",
      "Iteration: 3649; Percent complete: 73.0%; Average loss: 4.0704 Perplexity: 58.5776\n",
      "Iteration: 3650; Percent complete: 73.0%; Average loss: 3.7408 Perplexity: 42.1333\n",
      "Iteration: 3651; Percent complete: 73.0%; Average loss: 3.7504 Perplexity: 42.5387\n",
      "Iteration: 3652; Percent complete: 73.0%; Average loss: 3.4419 Perplexity: 31.2464\n",
      "Iteration: 3653; Percent complete: 73.1%; Average loss: 3.5885 Perplexity: 36.1795\n",
      "Iteration: 3654; Percent complete: 73.1%; Average loss: 4.0170 Perplexity: 55.5334\n",
      "Iteration: 3655; Percent complete: 73.1%; Average loss: 3.8441 Perplexity: 46.7160\n",
      "Iteration: 3656; Percent complete: 73.1%; Average loss: 3.7936 Perplexity: 44.4155\n",
      "Iteration: 3657; Percent complete: 73.1%; Average loss: 3.5013 Perplexity: 33.1576\n",
      "Iteration: 3658; Percent complete: 73.2%; Average loss: 3.5441 Perplexity: 34.6068\n",
      "Iteration: 3659; Percent complete: 73.2%; Average loss: 3.5330 Perplexity: 34.2274\n",
      "Iteration: 3660; Percent complete: 73.2%; Average loss: 3.5738 Perplexity: 35.6533\n",
      "Iteration: 3661; Percent complete: 73.2%; Average loss: 3.5173 Perplexity: 33.6930\n",
      "Iteration: 3662; Percent complete: 73.2%; Average loss: 3.9809 Perplexity: 53.5628\n",
      "Iteration: 3663; Percent complete: 73.3%; Average loss: 3.1743 Perplexity: 23.9099\n",
      "Iteration: 3664; Percent complete: 73.3%; Average loss: 3.4995 Perplexity: 33.0983\n",
      "Iteration: 3665; Percent complete: 73.3%; Average loss: 3.7237 Perplexity: 41.4161\n",
      "Iteration: 3666; Percent complete: 73.3%; Average loss: 3.1362 Perplexity: 23.0168\n",
      "Iteration: 3667; Percent complete: 73.3%; Average loss: 3.7448 Perplexity: 42.3009\n",
      "Iteration: 3668; Percent complete: 73.4%; Average loss: 3.9110 Perplexity: 49.9481\n",
      "Iteration: 3669; Percent complete: 73.4%; Average loss: 4.3247 Perplexity: 75.5400\n",
      "Iteration: 3670; Percent complete: 73.4%; Average loss: 3.1934 Perplexity: 24.3710\n",
      "Iteration: 3671; Percent complete: 73.4%; Average loss: 3.4126 Perplexity: 30.3447\n",
      "Iteration: 3672; Percent complete: 73.4%; Average loss: 3.7946 Perplexity: 44.4619\n",
      "Iteration: 3673; Percent complete: 73.5%; Average loss: 3.3290 Perplexity: 27.9116\n",
      "Iteration: 3674; Percent complete: 73.5%; Average loss: 3.5959 Perplexity: 36.4470\n",
      "Iteration: 3675; Percent complete: 73.5%; Average loss: 3.7159 Perplexity: 41.0946\n",
      "Iteration: 3676; Percent complete: 73.5%; Average loss: 3.3749 Perplexity: 29.2220\n",
      "Iteration: 3677; Percent complete: 73.5%; Average loss: 3.6766 Perplexity: 39.5115\n",
      "Iteration: 3678; Percent complete: 73.6%; Average loss: 3.7271 Perplexity: 41.5566\n",
      "Iteration: 3679; Percent complete: 73.6%; Average loss: 3.8353 Perplexity: 46.3051\n",
      "Iteration: 3680; Percent complete: 73.6%; Average loss: 3.3802 Perplexity: 29.3778\n",
      "Iteration: 3681; Percent complete: 73.6%; Average loss: 3.6408 Perplexity: 38.1222\n",
      "Iteration: 3682; Percent complete: 73.6%; Average loss: 3.7249 Perplexity: 41.4681\n",
      "Iteration: 3683; Percent complete: 73.7%; Average loss: 3.5412 Perplexity: 34.5087\n",
      "Iteration: 3684; Percent complete: 73.7%; Average loss: 4.0253 Perplexity: 55.9946\n",
      "Iteration: 3685; Percent complete: 73.7%; Average loss: 3.3079 Perplexity: 27.3290\n",
      "Iteration: 3686; Percent complete: 73.7%; Average loss: 3.6435 Perplexity: 38.2254\n",
      "Iteration: 3687; Percent complete: 73.7%; Average loss: 3.6957 Perplexity: 40.2737\n",
      "Iteration: 3688; Percent complete: 73.8%; Average loss: 3.5509 Perplexity: 34.8453\n",
      "Iteration: 3689; Percent complete: 73.8%; Average loss: 3.9222 Perplexity: 50.5139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3690; Percent complete: 73.8%; Average loss: 3.3808 Perplexity: 29.3935\n",
      "Iteration: 3691; Percent complete: 73.8%; Average loss: 3.6284 Perplexity: 37.6513\n",
      "Iteration: 3692; Percent complete: 73.8%; Average loss: 4.1649 Perplexity: 64.3867\n",
      "Iteration: 3693; Percent complete: 73.9%; Average loss: 3.4898 Perplexity: 32.7799\n",
      "Iteration: 3694; Percent complete: 73.9%; Average loss: 3.7534 Perplexity: 42.6676\n",
      "Iteration: 3695; Percent complete: 73.9%; Average loss: 3.6940 Perplexity: 40.2041\n",
      "Iteration: 3696; Percent complete: 73.9%; Average loss: 3.5376 Perplexity: 34.3847\n",
      "Iteration: 3697; Percent complete: 73.9%; Average loss: 3.8292 Perplexity: 46.0269\n",
      "Iteration: 3698; Percent complete: 74.0%; Average loss: 3.9240 Perplexity: 50.6045\n",
      "Iteration: 3699; Percent complete: 74.0%; Average loss: 3.3203 Perplexity: 27.6697\n",
      "Iteration: 3700; Percent complete: 74.0%; Average loss: 3.8667 Perplexity: 47.7862\n",
      "Iteration: 3701; Percent complete: 74.0%; Average loss: 3.2384 Perplexity: 25.4922\n",
      "Iteration: 3702; Percent complete: 74.0%; Average loss: 3.6772 Perplexity: 39.5344\n",
      "Iteration: 3703; Percent complete: 74.1%; Average loss: 3.4130 Perplexity: 30.3554\n",
      "Iteration: 3704; Percent complete: 74.1%; Average loss: 3.7401 Perplexity: 42.1040\n",
      "Iteration: 3705; Percent complete: 74.1%; Average loss: 3.5835 Perplexity: 36.0001\n",
      "Iteration: 3706; Percent complete: 74.1%; Average loss: 3.7016 Perplexity: 40.5115\n",
      "Iteration: 3707; Percent complete: 74.1%; Average loss: 3.4520 Perplexity: 31.5646\n",
      "Iteration: 3708; Percent complete: 74.2%; Average loss: 3.4196 Perplexity: 30.5576\n",
      "Iteration: 3709; Percent complete: 74.2%; Average loss: 3.6866 Perplexity: 39.9087\n",
      "Iteration: 3710; Percent complete: 74.2%; Average loss: 3.5967 Perplexity: 36.4781\n",
      "Iteration: 3711; Percent complete: 74.2%; Average loss: 3.5929 Perplexity: 36.3405\n",
      "Iteration: 3712; Percent complete: 74.2%; Average loss: 3.8464 Perplexity: 46.8247\n",
      "Iteration: 3713; Percent complete: 74.3%; Average loss: 3.6185 Perplexity: 37.2826\n",
      "Iteration: 3714; Percent complete: 74.3%; Average loss: 3.6279 Perplexity: 37.6335\n",
      "Iteration: 3715; Percent complete: 74.3%; Average loss: 3.5921 Perplexity: 36.3091\n",
      "Iteration: 3716; Percent complete: 74.3%; Average loss: 3.7085 Perplexity: 40.7940\n",
      "Iteration: 3717; Percent complete: 74.3%; Average loss: 3.7715 Perplexity: 43.4471\n",
      "Iteration: 3718; Percent complete: 74.4%; Average loss: 3.5744 Perplexity: 35.6741\n",
      "Iteration: 3719; Percent complete: 74.4%; Average loss: 3.5714 Perplexity: 35.5652\n",
      "Iteration: 3720; Percent complete: 74.4%; Average loss: 3.8969 Perplexity: 49.2506\n",
      "Iteration: 3721; Percent complete: 74.4%; Average loss: 3.7894 Perplexity: 44.2292\n",
      "Iteration: 3722; Percent complete: 74.4%; Average loss: 3.6127 Perplexity: 37.0669\n",
      "Iteration: 3723; Percent complete: 74.5%; Average loss: 3.6717 Perplexity: 39.3206\n",
      "Iteration: 3724; Percent complete: 74.5%; Average loss: 3.4950 Perplexity: 32.9518\n",
      "Iteration: 3725; Percent complete: 74.5%; Average loss: 3.3960 Perplexity: 29.8431\n",
      "Iteration: 3726; Percent complete: 74.5%; Average loss: 3.5842 Perplexity: 36.0237\n",
      "Iteration: 3727; Percent complete: 74.5%; Average loss: 4.4052 Perplexity: 81.8791\n",
      "Iteration: 3728; Percent complete: 74.6%; Average loss: 3.8136 Perplexity: 45.3136\n",
      "Iteration: 3729; Percent complete: 74.6%; Average loss: 3.2279 Perplexity: 25.2266\n",
      "Iteration: 3730; Percent complete: 74.6%; Average loss: 3.5262 Perplexity: 33.9938\n",
      "Iteration: 3731; Percent complete: 74.6%; Average loss: 3.5745 Perplexity: 35.6784\n",
      "Iteration: 3732; Percent complete: 74.6%; Average loss: 3.6945 Perplexity: 40.2247\n",
      "Iteration: 3733; Percent complete: 74.7%; Average loss: 4.0000 Perplexity: 54.5963\n",
      "Iteration: 3734; Percent complete: 74.7%; Average loss: 3.4295 Perplexity: 30.8598\n",
      "Iteration: 3735; Percent complete: 74.7%; Average loss: 3.6665 Perplexity: 39.1144\n",
      "Iteration: 3736; Percent complete: 74.7%; Average loss: 3.4641 Perplexity: 31.9483\n",
      "Iteration: 3737; Percent complete: 74.7%; Average loss: 3.6473 Perplexity: 38.3711\n",
      "Iteration: 3738; Percent complete: 74.8%; Average loss: 3.5707 Perplexity: 35.5401\n",
      "Iteration: 3739; Percent complete: 74.8%; Average loss: 3.4438 Perplexity: 31.3051\n",
      "Iteration: 3740; Percent complete: 74.8%; Average loss: 3.3920 Perplexity: 29.7242\n",
      "Iteration: 3741; Percent complete: 74.8%; Average loss: 3.5898 Perplexity: 36.2263\n",
      "Iteration: 3742; Percent complete: 74.8%; Average loss: 3.6429 Perplexity: 38.2023\n",
      "Iteration: 3743; Percent complete: 74.9%; Average loss: 3.5526 Perplexity: 34.9026\n",
      "Iteration: 3744; Percent complete: 74.9%; Average loss: 3.7153 Perplexity: 41.0723\n",
      "Iteration: 3745; Percent complete: 74.9%; Average loss: 3.6818 Perplexity: 39.7196\n",
      "Iteration: 3746; Percent complete: 74.9%; Average loss: 3.3350 Perplexity: 28.0772\n",
      "Iteration: 3747; Percent complete: 74.9%; Average loss: 3.4054 Perplexity: 30.1263\n",
      "Iteration: 3748; Percent complete: 75.0%; Average loss: 3.5840 Perplexity: 36.0156\n",
      "Iteration: 3749; Percent complete: 75.0%; Average loss: 3.5902 Perplexity: 36.2431\n",
      "Iteration: 3750; Percent complete: 75.0%; Average loss: 3.2367 Perplexity: 25.4491\n",
      "Iteration: 3751; Percent complete: 75.0%; Average loss: 3.7643 Perplexity: 43.1323\n",
      "Iteration: 3752; Percent complete: 75.0%; Average loss: 3.8109 Perplexity: 45.1908\n",
      "Iteration: 3753; Percent complete: 75.1%; Average loss: 3.2569 Perplexity: 25.9687\n",
      "Iteration: 3754; Percent complete: 75.1%; Average loss: 3.5488 Perplexity: 34.7706\n",
      "Iteration: 3755; Percent complete: 75.1%; Average loss: 3.3458 Perplexity: 28.3833\n",
      "Iteration: 3756; Percent complete: 75.1%; Average loss: 4.1125 Perplexity: 61.1015\n",
      "Iteration: 3757; Percent complete: 75.1%; Average loss: 3.6386 Perplexity: 38.0395\n",
      "Iteration: 3758; Percent complete: 75.2%; Average loss: 3.8354 Perplexity: 46.3128\n",
      "Iteration: 3759; Percent complete: 75.2%; Average loss: 3.4824 Perplexity: 32.5373\n",
      "Iteration: 3760; Percent complete: 75.2%; Average loss: 3.6567 Perplexity: 38.7321\n",
      "Iteration: 3761; Percent complete: 75.2%; Average loss: 3.8085 Perplexity: 45.0834\n",
      "Iteration: 3762; Percent complete: 75.2%; Average loss: 3.5291 Perplexity: 34.0936\n",
      "Iteration: 3763; Percent complete: 75.3%; Average loss: 3.4962 Perplexity: 32.9902\n",
      "Iteration: 3764; Percent complete: 75.3%; Average loss: 3.4365 Perplexity: 31.0771\n",
      "Iteration: 3765; Percent complete: 75.3%; Average loss: 3.5695 Perplexity: 35.4979\n",
      "Iteration: 3766; Percent complete: 75.3%; Average loss: 3.3941 Perplexity: 29.7873\n",
      "Iteration: 3767; Percent complete: 75.3%; Average loss: 3.8037 Perplexity: 44.8677\n",
      "Iteration: 3768; Percent complete: 75.4%; Average loss: 3.3613 Perplexity: 28.8253\n",
      "Iteration: 3769; Percent complete: 75.4%; Average loss: 3.4358 Perplexity: 31.0567\n",
      "Iteration: 3770; Percent complete: 75.4%; Average loss: 3.6041 Perplexity: 36.7482\n",
      "Iteration: 3771; Percent complete: 75.4%; Average loss: 3.4641 Perplexity: 31.9492\n",
      "Iteration: 3772; Percent complete: 75.4%; Average loss: 3.4270 Perplexity: 30.7838\n",
      "Iteration: 3773; Percent complete: 75.5%; Average loss: 3.8131 Perplexity: 45.2901\n",
      "Iteration: 3774; Percent complete: 75.5%; Average loss: 3.6184 Perplexity: 37.2787\n",
      "Iteration: 3775; Percent complete: 75.5%; Average loss: 3.6263 Perplexity: 37.5725\n",
      "Iteration: 3776; Percent complete: 75.5%; Average loss: 3.3131 Perplexity: 27.4689\n",
      "Iteration: 3777; Percent complete: 75.5%; Average loss: 3.6010 Perplexity: 36.6333\n",
      "Iteration: 3778; Percent complete: 75.6%; Average loss: 3.4137 Perplexity: 30.3763\n",
      "Iteration: 3779; Percent complete: 75.6%; Average loss: 3.6886 Perplexity: 39.9878\n",
      "Iteration: 3780; Percent complete: 75.6%; Average loss: 3.8153 Perplexity: 45.3900\n",
      "Iteration: 3781; Percent complete: 75.6%; Average loss: 3.4646 Perplexity: 31.9639\n",
      "Iteration: 3782; Percent complete: 75.6%; Average loss: 3.3520 Perplexity: 28.5585\n",
      "Iteration: 3783; Percent complete: 75.7%; Average loss: 3.0609 Perplexity: 21.3468\n",
      "Iteration: 3784; Percent complete: 75.7%; Average loss: 3.5872 Perplexity: 36.1310\n",
      "Iteration: 3785; Percent complete: 75.7%; Average loss: 3.6459 Perplexity: 38.3168\n",
      "Iteration: 3786; Percent complete: 75.7%; Average loss: 3.3369 Perplexity: 28.1317\n",
      "Iteration: 3787; Percent complete: 75.7%; Average loss: 3.7243 Perplexity: 41.4435\n",
      "Iteration: 3788; Percent complete: 75.8%; Average loss: 3.6093 Perplexity: 36.9391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3789; Percent complete: 75.8%; Average loss: 3.4034 Perplexity: 30.0675\n",
      "Iteration: 3790; Percent complete: 75.8%; Average loss: 3.5746 Perplexity: 35.6790\n",
      "Iteration: 3791; Percent complete: 75.8%; Average loss: 3.9292 Perplexity: 50.8667\n",
      "Iteration: 3792; Percent complete: 75.8%; Average loss: 3.5458 Perplexity: 34.6659\n",
      "Iteration: 3793; Percent complete: 75.9%; Average loss: 3.7614 Perplexity: 43.0095\n",
      "Iteration: 3794; Percent complete: 75.9%; Average loss: 3.2126 Perplexity: 24.8442\n",
      "Iteration: 3795; Percent complete: 75.9%; Average loss: 4.1185 Perplexity: 61.4654\n",
      "Iteration: 3796; Percent complete: 75.9%; Average loss: 3.8169 Perplexity: 45.4610\n",
      "Iteration: 3797; Percent complete: 75.9%; Average loss: 3.8144 Perplexity: 45.3501\n",
      "Iteration: 3798; Percent complete: 76.0%; Average loss: 3.5416 Perplexity: 34.5235\n",
      "Iteration: 3799; Percent complete: 76.0%; Average loss: 3.4032 Perplexity: 30.0604\n",
      "Iteration: 3800; Percent complete: 76.0%; Average loss: 3.4882 Perplexity: 32.7260\n",
      "Iteration: 3801; Percent complete: 76.0%; Average loss: 3.3852 Perplexity: 29.5243\n",
      "Iteration: 3802; Percent complete: 76.0%; Average loss: 3.4998 Perplexity: 33.1097\n",
      "Iteration: 3803; Percent complete: 76.1%; Average loss: 3.6574 Perplexity: 38.7612\n",
      "Iteration: 3804; Percent complete: 76.1%; Average loss: 3.7583 Perplexity: 42.8735\n",
      "Iteration: 3805; Percent complete: 76.1%; Average loss: 3.4289 Perplexity: 30.8421\n",
      "Iteration: 3806; Percent complete: 76.1%; Average loss: 3.8126 Perplexity: 45.2678\n",
      "Iteration: 3807; Percent complete: 76.1%; Average loss: 3.4174 Perplexity: 30.4903\n",
      "Iteration: 3808; Percent complete: 76.2%; Average loss: 3.5726 Perplexity: 35.6076\n",
      "Iteration: 3809; Percent complete: 76.2%; Average loss: 3.5877 Perplexity: 36.1503\n",
      "Iteration: 3810; Percent complete: 76.2%; Average loss: 3.2522 Perplexity: 25.8459\n",
      "Iteration: 3811; Percent complete: 76.2%; Average loss: 3.5792 Perplexity: 35.8441\n",
      "Iteration: 3812; Percent complete: 76.2%; Average loss: 3.5292 Perplexity: 34.0958\n",
      "Iteration: 3813; Percent complete: 76.3%; Average loss: 3.5382 Perplexity: 34.4038\n",
      "Iteration: 3814; Percent complete: 76.3%; Average loss: 3.6569 Perplexity: 38.7425\n",
      "Iteration: 3815; Percent complete: 76.3%; Average loss: 3.3097 Perplexity: 27.3759\n",
      "Iteration: 3816; Percent complete: 76.3%; Average loss: 3.5977 Perplexity: 36.5135\n",
      "Iteration: 3817; Percent complete: 76.3%; Average loss: 3.8676 Perplexity: 47.8262\n",
      "Iteration: 3818; Percent complete: 76.4%; Average loss: 3.1750 Perplexity: 23.9264\n",
      "Iteration: 3819; Percent complete: 76.4%; Average loss: 3.3910 Perplexity: 29.6967\n",
      "Iteration: 3820; Percent complete: 76.4%; Average loss: 3.4311 Perplexity: 30.9098\n",
      "Iteration: 3821; Percent complete: 76.4%; Average loss: 3.6227 Perplexity: 37.4398\n",
      "Iteration: 3822; Percent complete: 76.4%; Average loss: 3.5051 Perplexity: 33.2863\n",
      "Iteration: 3823; Percent complete: 76.5%; Average loss: 3.5858 Perplexity: 36.0840\n",
      "Iteration: 3824; Percent complete: 76.5%; Average loss: 3.5380 Perplexity: 34.3974\n",
      "Iteration: 3825; Percent complete: 76.5%; Average loss: 3.6535 Perplexity: 38.6080\n",
      "Iteration: 3826; Percent complete: 76.5%; Average loss: 3.9591 Perplexity: 52.4106\n",
      "Iteration: 3827; Percent complete: 76.5%; Average loss: 3.5503 Perplexity: 34.8233\n",
      "Iteration: 3828; Percent complete: 76.6%; Average loss: 3.5623 Perplexity: 35.2458\n",
      "Iteration: 3829; Percent complete: 76.6%; Average loss: 3.6450 Perplexity: 38.2835\n",
      "Iteration: 3830; Percent complete: 76.6%; Average loss: 3.4903 Perplexity: 32.7944\n",
      "Iteration: 3831; Percent complete: 76.6%; Average loss: 3.3048 Perplexity: 27.2440\n",
      "Iteration: 3832; Percent complete: 76.6%; Average loss: 3.4542 Perplexity: 31.6343\n",
      "Iteration: 3833; Percent complete: 76.7%; Average loss: 3.2603 Perplexity: 26.0582\n",
      "Iteration: 3834; Percent complete: 76.7%; Average loss: 3.0704 Perplexity: 21.5512\n",
      "Iteration: 3835; Percent complete: 76.7%; Average loss: 3.8025 Perplexity: 44.8138\n",
      "Iteration: 3836; Percent complete: 76.7%; Average loss: 3.8034 Perplexity: 44.8552\n",
      "Iteration: 3837; Percent complete: 76.7%; Average loss: 3.5889 Perplexity: 36.1957\n",
      "Iteration: 3838; Percent complete: 76.8%; Average loss: 3.2933 Perplexity: 26.9323\n",
      "Iteration: 3839; Percent complete: 76.8%; Average loss: 3.7316 Perplexity: 41.7450\n",
      "Iteration: 3840; Percent complete: 76.8%; Average loss: 3.3188 Perplexity: 27.6264\n",
      "Iteration: 3841; Percent complete: 76.8%; Average loss: 3.7541 Perplexity: 42.6967\n",
      "Iteration: 3842; Percent complete: 76.8%; Average loss: 3.4262 Perplexity: 30.7590\n",
      "Iteration: 3843; Percent complete: 76.9%; Average loss: 3.3559 Perplexity: 28.6715\n",
      "Iteration: 3844; Percent complete: 76.9%; Average loss: 3.7011 Perplexity: 40.4926\n",
      "Iteration: 3845; Percent complete: 76.9%; Average loss: 3.7340 Perplexity: 41.8467\n",
      "Iteration: 3846; Percent complete: 76.9%; Average loss: 3.5064 Perplexity: 33.3294\n",
      "Iteration: 3847; Percent complete: 76.9%; Average loss: 3.5923 Perplexity: 36.3189\n",
      "Iteration: 3848; Percent complete: 77.0%; Average loss: 3.4180 Perplexity: 30.5087\n",
      "Iteration: 3849; Percent complete: 77.0%; Average loss: 3.9444 Perplexity: 51.6440\n",
      "Iteration: 3850; Percent complete: 77.0%; Average loss: 3.3978 Perplexity: 29.8973\n",
      "Iteration: 3851; Percent complete: 77.0%; Average loss: 3.9774 Perplexity: 53.3754\n",
      "Iteration: 3852; Percent complete: 77.0%; Average loss: 3.3047 Perplexity: 27.2398\n",
      "Iteration: 3853; Percent complete: 77.1%; Average loss: 3.6719 Perplexity: 39.3261\n",
      "Iteration: 3854; Percent complete: 77.1%; Average loss: 3.6066 Perplexity: 36.8403\n",
      "Iteration: 3855; Percent complete: 77.1%; Average loss: 3.2777 Perplexity: 26.5153\n",
      "Iteration: 3856; Percent complete: 77.1%; Average loss: 3.6233 Perplexity: 37.4609\n",
      "Iteration: 3857; Percent complete: 77.1%; Average loss: 3.2995 Perplexity: 27.1004\n",
      "Iteration: 3858; Percent complete: 77.2%; Average loss: 2.9870 Perplexity: 19.8260\n",
      "Iteration: 3859; Percent complete: 77.2%; Average loss: 4.1185 Perplexity: 61.4672\n",
      "Iteration: 3860; Percent complete: 77.2%; Average loss: 3.3293 Perplexity: 27.9175\n",
      "Iteration: 3861; Percent complete: 77.2%; Average loss: 3.4624 Perplexity: 31.8937\n",
      "Iteration: 3862; Percent complete: 77.2%; Average loss: 3.5291 Perplexity: 34.0945\n",
      "Iteration: 3863; Percent complete: 77.3%; Average loss: 3.6510 Perplexity: 38.5113\n",
      "Iteration: 3864; Percent complete: 77.3%; Average loss: 3.5668 Perplexity: 35.4015\n",
      "Iteration: 3865; Percent complete: 77.3%; Average loss: 3.8533 Perplexity: 47.1494\n",
      "Iteration: 3866; Percent complete: 77.3%; Average loss: 3.6591 Perplexity: 38.8256\n",
      "Iteration: 3867; Percent complete: 77.3%; Average loss: 3.6253 Perplexity: 37.5349\n",
      "Iteration: 3868; Percent complete: 77.4%; Average loss: 3.3240 Perplexity: 27.7725\n",
      "Iteration: 3869; Percent complete: 77.4%; Average loss: 3.2726 Perplexity: 26.3804\n",
      "Iteration: 3870; Percent complete: 77.4%; Average loss: 3.1514 Perplexity: 23.3691\n",
      "Iteration: 3871; Percent complete: 77.4%; Average loss: 3.5960 Perplexity: 36.4526\n",
      "Iteration: 3872; Percent complete: 77.4%; Average loss: 3.9510 Perplexity: 51.9864\n",
      "Iteration: 3873; Percent complete: 77.5%; Average loss: 3.5882 Perplexity: 36.1685\n",
      "Iteration: 3874; Percent complete: 77.5%; Average loss: 3.5628 Perplexity: 35.2630\n",
      "Iteration: 3875; Percent complete: 77.5%; Average loss: 3.6089 Perplexity: 36.9270\n",
      "Iteration: 3876; Percent complete: 77.5%; Average loss: 3.5616 Perplexity: 35.2210\n",
      "Iteration: 3877; Percent complete: 77.5%; Average loss: 3.3777 Perplexity: 29.3026\n",
      "Iteration: 3878; Percent complete: 77.6%; Average loss: 3.4210 Perplexity: 30.6005\n",
      "Iteration: 3879; Percent complete: 77.6%; Average loss: 3.6180 Perplexity: 37.2617\n",
      "Iteration: 3880; Percent complete: 77.6%; Average loss: 3.4230 Perplexity: 30.6627\n",
      "Iteration: 3881; Percent complete: 77.6%; Average loss: 3.5994 Perplexity: 36.5764\n",
      "Iteration: 3882; Percent complete: 77.6%; Average loss: 3.5633 Perplexity: 35.2807\n",
      "Iteration: 3883; Percent complete: 77.7%; Average loss: 3.3496 Perplexity: 28.4910\n",
      "Iteration: 3884; Percent complete: 77.7%; Average loss: 3.5738 Perplexity: 35.6508\n",
      "Iteration: 3885; Percent complete: 77.7%; Average loss: 3.5727 Perplexity: 35.6139\n",
      "Iteration: 3886; Percent complete: 77.7%; Average loss: 3.3779 Perplexity: 29.3106\n",
      "Iteration: 3887; Percent complete: 77.7%; Average loss: 3.7771 Perplexity: 43.6888\n",
      "Iteration: 3888; Percent complete: 77.8%; Average loss: 3.3666 Perplexity: 28.9807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3889; Percent complete: 77.8%; Average loss: 3.2971 Perplexity: 27.0351\n",
      "Iteration: 3890; Percent complete: 77.8%; Average loss: 3.4832 Perplexity: 32.5637\n",
      "Iteration: 3891; Percent complete: 77.8%; Average loss: 3.7226 Perplexity: 41.3713\n",
      "Iteration: 3892; Percent complete: 77.8%; Average loss: 3.8529 Perplexity: 47.1278\n",
      "Iteration: 3893; Percent complete: 77.9%; Average loss: 3.5907 Perplexity: 36.2577\n",
      "Iteration: 3894; Percent complete: 77.9%; Average loss: 3.5455 Perplexity: 34.6575\n",
      "Iteration: 3895; Percent complete: 77.9%; Average loss: 3.6604 Perplexity: 38.8783\n",
      "Iteration: 3896; Percent complete: 77.9%; Average loss: 3.3162 Perplexity: 27.5559\n",
      "Iteration: 3897; Percent complete: 77.9%; Average loss: 3.4818 Perplexity: 32.5173\n",
      "Iteration: 3898; Percent complete: 78.0%; Average loss: 3.2263 Perplexity: 25.1874\n",
      "Iteration: 3899; Percent complete: 78.0%; Average loss: 3.7068 Perplexity: 40.7213\n",
      "Iteration: 3900; Percent complete: 78.0%; Average loss: 3.4451 Perplexity: 31.3461\n",
      "Iteration: 3901; Percent complete: 78.0%; Average loss: 3.2817 Perplexity: 26.6205\n",
      "Iteration: 3902; Percent complete: 78.0%; Average loss: 3.7740 Perplexity: 43.5548\n",
      "Iteration: 3903; Percent complete: 78.1%; Average loss: 3.2259 Perplexity: 25.1756\n",
      "Iteration: 3904; Percent complete: 78.1%; Average loss: 3.5412 Perplexity: 34.5085\n",
      "Iteration: 3905; Percent complete: 78.1%; Average loss: 3.0907 Perplexity: 21.9922\n",
      "Iteration: 3906; Percent complete: 78.1%; Average loss: 3.5867 Perplexity: 36.1149\n",
      "Iteration: 3907; Percent complete: 78.1%; Average loss: 3.3581 Perplexity: 28.7355\n",
      "Iteration: 3908; Percent complete: 78.2%; Average loss: 3.4516 Perplexity: 31.5515\n",
      "Iteration: 3909; Percent complete: 78.2%; Average loss: 3.5126 Perplexity: 33.5362\n",
      "Iteration: 3910; Percent complete: 78.2%; Average loss: 3.6047 Perplexity: 36.7703\n",
      "Iteration: 3911; Percent complete: 78.2%; Average loss: 3.2826 Perplexity: 26.6441\n",
      "Iteration: 3912; Percent complete: 78.2%; Average loss: 3.6399 Perplexity: 38.0893\n",
      "Iteration: 3913; Percent complete: 78.3%; Average loss: 3.6598 Perplexity: 38.8548\n",
      "Iteration: 3914; Percent complete: 78.3%; Average loss: 3.7739 Perplexity: 43.5510\n",
      "Iteration: 3915; Percent complete: 78.3%; Average loss: 3.5350 Perplexity: 34.2965\n",
      "Iteration: 3916; Percent complete: 78.3%; Average loss: 3.8335 Perplexity: 46.2254\n",
      "Iteration: 3917; Percent complete: 78.3%; Average loss: 3.3037 Perplexity: 27.2132\n",
      "Iteration: 3918; Percent complete: 78.4%; Average loss: 3.9434 Perplexity: 51.5952\n",
      "Iteration: 3919; Percent complete: 78.4%; Average loss: 3.7009 Perplexity: 40.4844\n",
      "Iteration: 3920; Percent complete: 78.4%; Average loss: 3.2780 Perplexity: 26.5235\n",
      "Iteration: 3921; Percent complete: 78.4%; Average loss: 3.3830 Perplexity: 29.4589\n",
      "Iteration: 3922; Percent complete: 78.4%; Average loss: 3.9930 Perplexity: 54.2173\n",
      "Iteration: 3923; Percent complete: 78.5%; Average loss: 3.1222 Perplexity: 22.6973\n",
      "Iteration: 3924; Percent complete: 78.5%; Average loss: 3.6181 Perplexity: 37.2678\n",
      "Iteration: 3925; Percent complete: 78.5%; Average loss: 3.1565 Perplexity: 23.4889\n",
      "Iteration: 3926; Percent complete: 78.5%; Average loss: 3.6198 Perplexity: 37.3306\n",
      "Iteration: 3927; Percent complete: 78.5%; Average loss: 3.3533 Perplexity: 28.5983\n",
      "Iteration: 3928; Percent complete: 78.6%; Average loss: 3.7871 Perplexity: 44.1290\n",
      "Iteration: 3929; Percent complete: 78.6%; Average loss: 3.5749 Perplexity: 35.6923\n",
      "Iteration: 3930; Percent complete: 78.6%; Average loss: 3.4028 Perplexity: 30.0494\n",
      "Iteration: 3931; Percent complete: 78.6%; Average loss: 3.6154 Perplexity: 37.1665\n",
      "Iteration: 3932; Percent complete: 78.6%; Average loss: 3.6621 Perplexity: 38.9434\n",
      "Iteration: 3933; Percent complete: 78.7%; Average loss: 3.4840 Perplexity: 32.5909\n",
      "Iteration: 3934; Percent complete: 78.7%; Average loss: 3.9051 Perplexity: 49.6557\n",
      "Iteration: 3935; Percent complete: 78.7%; Average loss: 3.9110 Perplexity: 49.9483\n",
      "Iteration: 3936; Percent complete: 78.7%; Average loss: 3.4463 Perplexity: 31.3850\n",
      "Iteration: 3937; Percent complete: 78.7%; Average loss: 3.5005 Perplexity: 33.1333\n",
      "Iteration: 3938; Percent complete: 78.8%; Average loss: 3.4722 Perplexity: 32.2068\n",
      "Iteration: 3939; Percent complete: 78.8%; Average loss: 3.7635 Perplexity: 43.0977\n",
      "Iteration: 3940; Percent complete: 78.8%; Average loss: 3.8681 Perplexity: 47.8503\n",
      "Iteration: 3941; Percent complete: 78.8%; Average loss: 3.2285 Perplexity: 25.2418\n",
      "Iteration: 3942; Percent complete: 78.8%; Average loss: 3.8772 Perplexity: 48.2909\n",
      "Iteration: 3943; Percent complete: 78.9%; Average loss: 3.4667 Perplexity: 32.0304\n",
      "Iteration: 3944; Percent complete: 78.9%; Average loss: 3.0013 Perplexity: 20.1121\n",
      "Iteration: 3945; Percent complete: 78.9%; Average loss: 3.1983 Perplexity: 24.4911\n",
      "Iteration: 3946; Percent complete: 78.9%; Average loss: 3.6769 Perplexity: 39.5230\n",
      "Iteration: 3947; Percent complete: 78.9%; Average loss: 3.4680 Perplexity: 32.0712\n",
      "Iteration: 3948; Percent complete: 79.0%; Average loss: 3.6599 Perplexity: 38.8589\n",
      "Iteration: 3949; Percent complete: 79.0%; Average loss: 3.2907 Perplexity: 26.8609\n",
      "Iteration: 3950; Percent complete: 79.0%; Average loss: 3.1751 Perplexity: 23.9288\n",
      "Iteration: 3951; Percent complete: 79.0%; Average loss: 3.8465 Perplexity: 46.8295\n",
      "Iteration: 3952; Percent complete: 79.0%; Average loss: 3.7922 Perplexity: 44.3525\n",
      "Iteration: 3953; Percent complete: 79.1%; Average loss: 3.0240 Perplexity: 20.5737\n",
      "Iteration: 3954; Percent complete: 79.1%; Average loss: 3.4691 Perplexity: 32.1067\n",
      "Iteration: 3955; Percent complete: 79.1%; Average loss: 3.2340 Perplexity: 25.3798\n",
      "Iteration: 3956; Percent complete: 79.1%; Average loss: 3.6539 Perplexity: 38.6231\n",
      "Iteration: 3957; Percent complete: 79.1%; Average loss: 3.5202 Perplexity: 33.7904\n",
      "Iteration: 3958; Percent complete: 79.2%; Average loss: 3.7048 Perplexity: 40.6426\n",
      "Iteration: 3959; Percent complete: 79.2%; Average loss: 3.4860 Perplexity: 32.6564\n",
      "Iteration: 3960; Percent complete: 79.2%; Average loss: 3.7526 Perplexity: 42.6299\n",
      "Iteration: 3961; Percent complete: 79.2%; Average loss: 3.6605 Perplexity: 38.8818\n",
      "Iteration: 3962; Percent complete: 79.2%; Average loss: 3.6423 Perplexity: 38.1811\n",
      "Iteration: 3963; Percent complete: 79.3%; Average loss: 3.9869 Perplexity: 53.8901\n",
      "Iteration: 3964; Percent complete: 79.3%; Average loss: 3.7064 Perplexity: 40.7085\n",
      "Iteration: 3965; Percent complete: 79.3%; Average loss: 3.5638 Perplexity: 35.2984\n",
      "Iteration: 3966; Percent complete: 79.3%; Average loss: 3.4541 Perplexity: 31.6297\n",
      "Iteration: 3967; Percent complete: 79.3%; Average loss: 3.6314 Perplexity: 37.7655\n",
      "Iteration: 3968; Percent complete: 79.4%; Average loss: 3.8255 Perplexity: 45.8547\n",
      "Iteration: 3969; Percent complete: 79.4%; Average loss: 3.5607 Perplexity: 35.1869\n",
      "Iteration: 3970; Percent complete: 79.4%; Average loss: 3.5324 Perplexity: 34.2050\n",
      "Iteration: 3971; Percent complete: 79.4%; Average loss: 4.0595 Perplexity: 57.9455\n",
      "Iteration: 3972; Percent complete: 79.4%; Average loss: 3.7944 Perplexity: 44.4531\n",
      "Iteration: 3973; Percent complete: 79.5%; Average loss: 3.4823 Perplexity: 32.5348\n",
      "Iteration: 3974; Percent complete: 79.5%; Average loss: 3.4709 Perplexity: 32.1656\n",
      "Iteration: 3975; Percent complete: 79.5%; Average loss: 3.1193 Perplexity: 22.6295\n",
      "Iteration: 3976; Percent complete: 79.5%; Average loss: 3.6205 Perplexity: 37.3553\n",
      "Iteration: 3977; Percent complete: 79.5%; Average loss: 3.8706 Perplexity: 47.9724\n",
      "Iteration: 3978; Percent complete: 79.6%; Average loss: 3.2800 Perplexity: 26.5770\n",
      "Iteration: 3979; Percent complete: 79.6%; Average loss: 3.7534 Perplexity: 42.6651\n",
      "Iteration: 3980; Percent complete: 79.6%; Average loss: 3.5029 Perplexity: 33.2121\n",
      "Iteration: 3981; Percent complete: 79.6%; Average loss: 3.4925 Perplexity: 32.8674\n",
      "Iteration: 3982; Percent complete: 79.6%; Average loss: 3.6539 Perplexity: 38.6251\n",
      "Iteration: 3983; Percent complete: 79.7%; Average loss: 3.7056 Perplexity: 40.6730\n",
      "Iteration: 3984; Percent complete: 79.7%; Average loss: 3.6370 Perplexity: 37.9791\n",
      "Iteration: 3985; Percent complete: 79.7%; Average loss: 3.7538 Perplexity: 42.6839\n",
      "Iteration: 3986; Percent complete: 79.7%; Average loss: 3.5481 Perplexity: 34.7467\n",
      "Iteration: 3987; Percent complete: 79.7%; Average loss: 3.3462 Perplexity: 28.3947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3988; Percent complete: 79.8%; Average loss: 3.2868 Perplexity: 26.7576\n",
      "Iteration: 3989; Percent complete: 79.8%; Average loss: 3.5893 Perplexity: 36.2084\n",
      "Iteration: 3990; Percent complete: 79.8%; Average loss: 3.6007 Perplexity: 36.6249\n",
      "Iteration: 3991; Percent complete: 79.8%; Average loss: 3.6329 Perplexity: 37.8206\n",
      "Iteration: 3992; Percent complete: 79.8%; Average loss: 3.8257 Perplexity: 45.8635\n",
      "Iteration: 3993; Percent complete: 79.9%; Average loss: 3.5881 Perplexity: 36.1657\n",
      "Iteration: 3994; Percent complete: 79.9%; Average loss: 3.9114 Perplexity: 49.9708\n",
      "Iteration: 3995; Percent complete: 79.9%; Average loss: 3.5090 Perplexity: 33.4153\n",
      "Iteration: 3996; Percent complete: 79.9%; Average loss: 3.3137 Perplexity: 27.4868\n",
      "Iteration: 3997; Percent complete: 79.9%; Average loss: 3.7630 Perplexity: 43.0769\n",
      "Iteration: 3998; Percent complete: 80.0%; Average loss: 3.9504 Perplexity: 51.9573\n",
      "Iteration: 3999; Percent complete: 80.0%; Average loss: 3.3658 Perplexity: 28.9571\n",
      "Iteration: 4000; Percent complete: 80.0%; Average loss: 3.8217 Perplexity: 45.6824\n",
      "Iteration: 4001; Percent complete: 80.0%; Average loss: 3.3709 Perplexity: 29.1035\n",
      "Iteration: 4002; Percent complete: 80.0%; Average loss: 3.1779 Perplexity: 23.9968\n",
      "Iteration: 4003; Percent complete: 80.1%; Average loss: 3.6303 Perplexity: 37.7243\n",
      "Iteration: 4004; Percent complete: 80.1%; Average loss: 3.6190 Perplexity: 37.2990\n",
      "Iteration: 4005; Percent complete: 80.1%; Average loss: 3.6719 Perplexity: 39.3269\n",
      "Iteration: 4006; Percent complete: 80.1%; Average loss: 3.1766 Perplexity: 23.9649\n",
      "Iteration: 4007; Percent complete: 80.1%; Average loss: 3.6231 Perplexity: 37.4527\n",
      "Iteration: 4008; Percent complete: 80.2%; Average loss: 3.5843 Perplexity: 36.0287\n",
      "Iteration: 4009; Percent complete: 80.2%; Average loss: 3.4072 Perplexity: 30.1805\n",
      "Iteration: 4010; Percent complete: 80.2%; Average loss: 3.3204 Perplexity: 27.6707\n",
      "Iteration: 4011; Percent complete: 80.2%; Average loss: 3.4319 Perplexity: 30.9352\n",
      "Iteration: 4012; Percent complete: 80.2%; Average loss: 3.1992 Perplexity: 24.5130\n",
      "Iteration: 4013; Percent complete: 80.3%; Average loss: 3.6861 Perplexity: 39.8892\n",
      "Iteration: 4014; Percent complete: 80.3%; Average loss: 3.2941 Perplexity: 26.9531\n",
      "Iteration: 4015; Percent complete: 80.3%; Average loss: 3.6034 Perplexity: 36.7229\n",
      "Iteration: 4016; Percent complete: 80.3%; Average loss: 3.1200 Perplexity: 22.6454\n",
      "Iteration: 4017; Percent complete: 80.3%; Average loss: 3.8973 Perplexity: 49.2690\n",
      "Iteration: 4018; Percent complete: 80.4%; Average loss: 3.3125 Perplexity: 27.4547\n",
      "Iteration: 4019; Percent complete: 80.4%; Average loss: 3.4982 Perplexity: 33.0572\n",
      "Iteration: 4020; Percent complete: 80.4%; Average loss: 3.5513 Perplexity: 34.8588\n",
      "Iteration: 4021; Percent complete: 80.4%; Average loss: 3.4627 Perplexity: 31.9025\n",
      "Iteration: 4022; Percent complete: 80.4%; Average loss: 3.6302 Perplexity: 37.7207\n",
      "Iteration: 4023; Percent complete: 80.5%; Average loss: 3.3556 Perplexity: 28.6616\n",
      "Iteration: 4024; Percent complete: 80.5%; Average loss: 3.1821 Perplexity: 24.0969\n",
      "Iteration: 4025; Percent complete: 80.5%; Average loss: 3.4669 Perplexity: 32.0372\n",
      "Iteration: 4026; Percent complete: 80.5%; Average loss: 3.5694 Perplexity: 35.4949\n",
      "Iteration: 4027; Percent complete: 80.5%; Average loss: 3.5114 Perplexity: 33.4962\n",
      "Iteration: 4028; Percent complete: 80.6%; Average loss: 3.5856 Perplexity: 36.0752\n",
      "Iteration: 4029; Percent complete: 80.6%; Average loss: 3.2352 Perplexity: 25.4117\n",
      "Iteration: 4030; Percent complete: 80.6%; Average loss: 3.6276 Perplexity: 37.6206\n",
      "Iteration: 4031; Percent complete: 80.6%; Average loss: 3.1803 Perplexity: 24.0531\n",
      "Iteration: 4032; Percent complete: 80.6%; Average loss: 3.5347 Perplexity: 34.2848\n",
      "Iteration: 4033; Percent complete: 80.7%; Average loss: 4.1115 Perplexity: 61.0361\n",
      "Iteration: 4034; Percent complete: 80.7%; Average loss: 3.3566 Perplexity: 28.6904\n",
      "Iteration: 4035; Percent complete: 80.7%; Average loss: 3.3259 Perplexity: 27.8239\n",
      "Iteration: 4036; Percent complete: 80.7%; Average loss: 3.7697 Perplexity: 43.3663\n",
      "Iteration: 4037; Percent complete: 80.7%; Average loss: 3.7300 Perplexity: 41.6804\n",
      "Iteration: 4038; Percent complete: 80.8%; Average loss: 3.7239 Perplexity: 41.4256\n",
      "Iteration: 4039; Percent complete: 80.8%; Average loss: 3.6449 Perplexity: 38.2783\n",
      "Iteration: 4040; Percent complete: 80.8%; Average loss: 3.6683 Perplexity: 39.1850\n",
      "Iteration: 4041; Percent complete: 80.8%; Average loss: 3.7022 Perplexity: 40.5357\n",
      "Iteration: 4042; Percent complete: 80.8%; Average loss: 3.4551 Perplexity: 31.6619\n",
      "Iteration: 4043; Percent complete: 80.9%; Average loss: 3.5137 Perplexity: 33.5732\n",
      "Iteration: 4044; Percent complete: 80.9%; Average loss: 3.4803 Perplexity: 32.4692\n",
      "Iteration: 4045; Percent complete: 80.9%; Average loss: 3.5666 Perplexity: 35.3969\n",
      "Iteration: 4046; Percent complete: 80.9%; Average loss: 3.4860 Perplexity: 32.6541\n",
      "Iteration: 4047; Percent complete: 80.9%; Average loss: 3.5176 Perplexity: 33.7048\n",
      "Iteration: 4048; Percent complete: 81.0%; Average loss: 3.3323 Perplexity: 28.0038\n",
      "Iteration: 4049; Percent complete: 81.0%; Average loss: 3.8863 Perplexity: 48.7312\n",
      "Iteration: 4050; Percent complete: 81.0%; Average loss: 3.3388 Perplexity: 28.1850\n",
      "Iteration: 4051; Percent complete: 81.0%; Average loss: 3.2639 Perplexity: 26.1524\n",
      "Iteration: 4052; Percent complete: 81.0%; Average loss: 3.3463 Perplexity: 28.3984\n",
      "Iteration: 4053; Percent complete: 81.1%; Average loss: 3.5712 Perplexity: 35.5604\n",
      "Iteration: 4054; Percent complete: 81.1%; Average loss: 3.2446 Perplexity: 25.6514\n",
      "Iteration: 4055; Percent complete: 81.1%; Average loss: 3.4695 Perplexity: 32.1211\n",
      "Iteration: 4056; Percent complete: 81.1%; Average loss: 3.1720 Perplexity: 23.8552\n",
      "Iteration: 4057; Percent complete: 81.1%; Average loss: 3.4272 Perplexity: 30.7899\n",
      "Iteration: 4058; Percent complete: 81.2%; Average loss: 3.6718 Perplexity: 39.3221\n",
      "Iteration: 4059; Percent complete: 81.2%; Average loss: 3.7470 Perplexity: 42.3921\n",
      "Iteration: 4060; Percent complete: 81.2%; Average loss: 3.2904 Perplexity: 26.8540\n",
      "Iteration: 4061; Percent complete: 81.2%; Average loss: 3.3009 Perplexity: 27.1382\n",
      "Iteration: 4062; Percent complete: 81.2%; Average loss: 3.4783 Perplexity: 32.4032\n",
      "Iteration: 4063; Percent complete: 81.3%; Average loss: 3.4073 Perplexity: 30.1845\n",
      "Iteration: 4064; Percent complete: 81.3%; Average loss: 2.9943 Perplexity: 19.9712\n",
      "Iteration: 4065; Percent complete: 81.3%; Average loss: 3.5044 Perplexity: 33.2608\n",
      "Iteration: 4066; Percent complete: 81.3%; Average loss: 3.4655 Perplexity: 31.9914\n",
      "Iteration: 4067; Percent complete: 81.3%; Average loss: 3.5598 Perplexity: 35.1549\n",
      "Iteration: 4068; Percent complete: 81.4%; Average loss: 3.2326 Perplexity: 25.3448\n",
      "Iteration: 4069; Percent complete: 81.4%; Average loss: 3.3365 Perplexity: 28.1215\n",
      "Iteration: 4070; Percent complete: 81.4%; Average loss: 3.6997 Perplexity: 40.4359\n",
      "Iteration: 4071; Percent complete: 81.4%; Average loss: 3.5249 Perplexity: 33.9504\n",
      "Iteration: 4072; Percent complete: 81.4%; Average loss: 3.7299 Perplexity: 41.6765\n",
      "Iteration: 4073; Percent complete: 81.5%; Average loss: 3.4277 Perplexity: 30.8044\n",
      "Iteration: 4074; Percent complete: 81.5%; Average loss: 3.4724 Perplexity: 32.2146\n",
      "Iteration: 4075; Percent complete: 81.5%; Average loss: 3.4229 Perplexity: 30.6569\n",
      "Iteration: 4076; Percent complete: 81.5%; Average loss: 3.5861 Perplexity: 36.0932\n",
      "Iteration: 4077; Percent complete: 81.5%; Average loss: 3.5778 Perplexity: 35.7959\n",
      "Iteration: 4078; Percent complete: 81.6%; Average loss: 3.3025 Perplexity: 27.1815\n",
      "Iteration: 4079; Percent complete: 81.6%; Average loss: 3.6690 Perplexity: 39.2132\n",
      "Iteration: 4080; Percent complete: 81.6%; Average loss: 3.4287 Perplexity: 30.8360\n",
      "Iteration: 4081; Percent complete: 81.6%; Average loss: 3.6538 Perplexity: 38.6201\n",
      "Iteration: 4082; Percent complete: 81.6%; Average loss: 3.3142 Perplexity: 27.5004\n",
      "Iteration: 4083; Percent complete: 81.7%; Average loss: 3.0760 Perplexity: 21.6705\n",
      "Iteration: 4084; Percent complete: 81.7%; Average loss: 3.5355 Perplexity: 34.3138\n",
      "Iteration: 4085; Percent complete: 81.7%; Average loss: 3.7895 Perplexity: 44.2352\n",
      "Iteration: 4086; Percent complete: 81.7%; Average loss: 3.4307 Perplexity: 30.8994\n",
      "Iteration: 4087; Percent complete: 81.7%; Average loss: 3.4773 Perplexity: 32.3725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4088; Percent complete: 81.8%; Average loss: 3.5958 Perplexity: 36.4457\n",
      "Iteration: 4089; Percent complete: 81.8%; Average loss: 3.2966 Perplexity: 27.0194\n",
      "Iteration: 4090; Percent complete: 81.8%; Average loss: 3.6058 Perplexity: 36.8096\n",
      "Iteration: 4091; Percent complete: 81.8%; Average loss: 3.7066 Perplexity: 40.7145\n",
      "Iteration: 4092; Percent complete: 81.8%; Average loss: 3.4897 Perplexity: 32.7768\n",
      "Iteration: 4093; Percent complete: 81.9%; Average loss: 3.2274 Perplexity: 25.2129\n",
      "Iteration: 4094; Percent complete: 81.9%; Average loss: 3.2120 Perplexity: 24.8298\n",
      "Iteration: 4095; Percent complete: 81.9%; Average loss: 3.3255 Perplexity: 27.8122\n",
      "Iteration: 4096; Percent complete: 81.9%; Average loss: 3.4713 Perplexity: 32.1798\n",
      "Iteration: 4097; Percent complete: 81.9%; Average loss: 3.9032 Perplexity: 49.5588\n",
      "Iteration: 4098; Percent complete: 82.0%; Average loss: 3.2833 Perplexity: 26.6647\n",
      "Iteration: 4099; Percent complete: 82.0%; Average loss: 3.6448 Perplexity: 38.2733\n",
      "Iteration: 4100; Percent complete: 82.0%; Average loss: 3.6865 Perplexity: 39.9065\n",
      "Iteration: 4101; Percent complete: 82.0%; Average loss: 3.7036 Perplexity: 40.5926\n",
      "Iteration: 4102; Percent complete: 82.0%; Average loss: 3.4673 Perplexity: 32.0502\n",
      "Iteration: 4103; Percent complete: 82.1%; Average loss: 3.3260 Perplexity: 27.8271\n",
      "Iteration: 4104; Percent complete: 82.1%; Average loss: 3.6834 Perplexity: 39.7817\n",
      "Iteration: 4105; Percent complete: 82.1%; Average loss: 3.4775 Perplexity: 32.3793\n",
      "Iteration: 4106; Percent complete: 82.1%; Average loss: 3.1776 Perplexity: 23.9900\n",
      "Iteration: 4107; Percent complete: 82.1%; Average loss: 3.3718 Perplexity: 29.1317\n",
      "Iteration: 4108; Percent complete: 82.2%; Average loss: 3.4446 Perplexity: 31.3296\n",
      "Iteration: 4109; Percent complete: 82.2%; Average loss: 3.2341 Perplexity: 25.3829\n",
      "Iteration: 4110; Percent complete: 82.2%; Average loss: 3.1222 Perplexity: 22.6964\n",
      "Iteration: 4111; Percent complete: 82.2%; Average loss: 3.1019 Perplexity: 22.2406\n",
      "Iteration: 4112; Percent complete: 82.2%; Average loss: 3.8738 Perplexity: 48.1236\n",
      "Iteration: 4113; Percent complete: 82.3%; Average loss: 3.5177 Perplexity: 33.7061\n",
      "Iteration: 4114; Percent complete: 82.3%; Average loss: 3.3588 Perplexity: 28.7554\n",
      "Iteration: 4115; Percent complete: 82.3%; Average loss: 3.1667 Perplexity: 23.7280\n",
      "Iteration: 4116; Percent complete: 82.3%; Average loss: 3.3076 Perplexity: 27.3192\n",
      "Iteration: 4117; Percent complete: 82.3%; Average loss: 3.4940 Perplexity: 32.9164\n",
      "Iteration: 4118; Percent complete: 82.4%; Average loss: 3.1622 Perplexity: 23.6218\n",
      "Iteration: 4119; Percent complete: 82.4%; Average loss: 3.0878 Perplexity: 21.9278\n",
      "Iteration: 4120; Percent complete: 82.4%; Average loss: 3.4883 Perplexity: 32.7308\n",
      "Iteration: 4121; Percent complete: 82.4%; Average loss: 3.5661 Perplexity: 35.3784\n",
      "Iteration: 4122; Percent complete: 82.4%; Average loss: 3.5009 Perplexity: 33.1460\n",
      "Iteration: 4123; Percent complete: 82.5%; Average loss: 3.1186 Perplexity: 22.6141\n",
      "Iteration: 4124; Percent complete: 82.5%; Average loss: 3.4341 Perplexity: 31.0046\n",
      "Iteration: 4125; Percent complete: 82.5%; Average loss: 3.1939 Perplexity: 24.3839\n",
      "Iteration: 4126; Percent complete: 82.5%; Average loss: 3.1659 Perplexity: 23.7110\n",
      "Iteration: 4127; Percent complete: 82.5%; Average loss: 3.6752 Perplexity: 39.4572\n",
      "Iteration: 4128; Percent complete: 82.6%; Average loss: 3.3641 Perplexity: 28.9065\n",
      "Iteration: 4129; Percent complete: 82.6%; Average loss: 3.6990 Perplexity: 40.4058\n",
      "Iteration: 4130; Percent complete: 82.6%; Average loss: 3.8868 Perplexity: 48.7557\n",
      "Iteration: 4131; Percent complete: 82.6%; Average loss: 3.1519 Perplexity: 23.3807\n",
      "Iteration: 4132; Percent complete: 82.6%; Average loss: 3.3754 Perplexity: 29.2374\n",
      "Iteration: 4133; Percent complete: 82.7%; Average loss: 3.3169 Perplexity: 27.5741\n",
      "Iteration: 4134; Percent complete: 82.7%; Average loss: 3.3586 Perplexity: 28.7480\n",
      "Iteration: 4135; Percent complete: 82.7%; Average loss: 3.5243 Perplexity: 33.9307\n",
      "Iteration: 4136; Percent complete: 82.7%; Average loss: 3.5716 Perplexity: 35.5731\n",
      "Iteration: 4137; Percent complete: 82.7%; Average loss: 3.5736 Perplexity: 35.6439\n",
      "Iteration: 4138; Percent complete: 82.8%; Average loss: 3.2046 Perplexity: 24.6450\n",
      "Iteration: 4139; Percent complete: 82.8%; Average loss: 3.1952 Perplexity: 24.4149\n",
      "Iteration: 4140; Percent complete: 82.8%; Average loss: 3.6727 Perplexity: 39.3599\n",
      "Iteration: 4141; Percent complete: 82.8%; Average loss: 3.2837 Perplexity: 26.6745\n",
      "Iteration: 4142; Percent complete: 82.8%; Average loss: 3.4112 Perplexity: 30.3011\n",
      "Iteration: 4143; Percent complete: 82.9%; Average loss: 3.3154 Perplexity: 27.5347\n",
      "Iteration: 4144; Percent complete: 82.9%; Average loss: 3.4371 Perplexity: 31.0966\n",
      "Iteration: 4145; Percent complete: 82.9%; Average loss: 3.7198 Perplexity: 41.2572\n",
      "Iteration: 4146; Percent complete: 82.9%; Average loss: 3.5460 Perplexity: 34.6731\n",
      "Iteration: 4147; Percent complete: 82.9%; Average loss: 3.2983 Perplexity: 27.0664\n",
      "Iteration: 4148; Percent complete: 83.0%; Average loss: 3.5182 Perplexity: 33.7252\n",
      "Iteration: 4149; Percent complete: 83.0%; Average loss: 3.7398 Perplexity: 42.0913\n",
      "Iteration: 4150; Percent complete: 83.0%; Average loss: 3.3565 Perplexity: 28.6882\n",
      "Iteration: 4151; Percent complete: 83.0%; Average loss: 3.7496 Perplexity: 42.5039\n",
      "Iteration: 4152; Percent complete: 83.0%; Average loss: 3.4982 Perplexity: 33.0568\n",
      "Iteration: 4153; Percent complete: 83.1%; Average loss: 3.8331 Perplexity: 46.2065\n",
      "Iteration: 4154; Percent complete: 83.1%; Average loss: 3.2894 Perplexity: 26.8263\n",
      "Iteration: 4155; Percent complete: 83.1%; Average loss: 3.3502 Perplexity: 28.5072\n",
      "Iteration: 4156; Percent complete: 83.1%; Average loss: 3.2089 Perplexity: 24.7525\n",
      "Iteration: 4157; Percent complete: 83.1%; Average loss: 3.8729 Perplexity: 48.0814\n",
      "Iteration: 4158; Percent complete: 83.2%; Average loss: 3.7612 Perplexity: 43.0014\n",
      "Iteration: 4159; Percent complete: 83.2%; Average loss: 3.4175 Perplexity: 30.4918\n",
      "Iteration: 4160; Percent complete: 83.2%; Average loss: 3.6857 Perplexity: 39.8741\n",
      "Iteration: 4161; Percent complete: 83.2%; Average loss: 3.3988 Perplexity: 29.9278\n",
      "Iteration: 4162; Percent complete: 83.2%; Average loss: 3.3224 Perplexity: 27.7267\n",
      "Iteration: 4163; Percent complete: 83.3%; Average loss: 3.3684 Perplexity: 29.0329\n",
      "Iteration: 4164; Percent complete: 83.3%; Average loss: 3.7286 Perplexity: 41.6216\n",
      "Iteration: 4165; Percent complete: 83.3%; Average loss: 3.4978 Perplexity: 33.0416\n",
      "Iteration: 4166; Percent complete: 83.3%; Average loss: 3.3714 Perplexity: 29.1204\n",
      "Iteration: 4167; Percent complete: 83.3%; Average loss: 3.5144 Perplexity: 33.5972\n",
      "Iteration: 4168; Percent complete: 83.4%; Average loss: 3.8598 Perplexity: 47.4549\n",
      "Iteration: 4169; Percent complete: 83.4%; Average loss: 3.4063 Perplexity: 30.1531\n",
      "Iteration: 4170; Percent complete: 83.4%; Average loss: 3.2474 Perplexity: 25.7234\n",
      "Iteration: 4171; Percent complete: 83.4%; Average loss: 3.7876 Perplexity: 44.1493\n",
      "Iteration: 4172; Percent complete: 83.4%; Average loss: 3.7328 Perplexity: 41.7945\n",
      "Iteration: 4173; Percent complete: 83.5%; Average loss: 3.6574 Perplexity: 38.7604\n",
      "Iteration: 4174; Percent complete: 83.5%; Average loss: 3.5881 Perplexity: 36.1656\n",
      "Iteration: 4175; Percent complete: 83.5%; Average loss: 3.4471 Perplexity: 31.4092\n",
      "Iteration: 4176; Percent complete: 83.5%; Average loss: 3.4762 Perplexity: 32.3370\n",
      "Iteration: 4177; Percent complete: 83.5%; Average loss: 3.2443 Perplexity: 25.6444\n",
      "Iteration: 4178; Percent complete: 83.6%; Average loss: 3.4990 Perplexity: 33.0817\n",
      "Iteration: 4179; Percent complete: 83.6%; Average loss: 3.2318 Perplexity: 25.3250\n",
      "Iteration: 4180; Percent complete: 83.6%; Average loss: 3.5442 Perplexity: 34.6119\n",
      "Iteration: 4181; Percent complete: 83.6%; Average loss: 3.6157 Perplexity: 37.1765\n",
      "Iteration: 4182; Percent complete: 83.6%; Average loss: 3.5320 Perplexity: 34.1909\n",
      "Iteration: 4183; Percent complete: 83.7%; Average loss: 3.8572 Perplexity: 47.3315\n",
      "Iteration: 4184; Percent complete: 83.7%; Average loss: 3.3867 Perplexity: 29.5675\n",
      "Iteration: 4185; Percent complete: 83.7%; Average loss: 3.3474 Perplexity: 28.4286\n",
      "Iteration: 4186; Percent complete: 83.7%; Average loss: 2.9712 Perplexity: 19.5162\n",
      "Iteration: 4187; Percent complete: 83.7%; Average loss: 3.4405 Perplexity: 31.2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4188; Percent complete: 83.8%; Average loss: 3.4296 Perplexity: 30.8653\n",
      "Iteration: 4189; Percent complete: 83.8%; Average loss: 3.2060 Perplexity: 24.6799\n",
      "Iteration: 4190; Percent complete: 83.8%; Average loss: 3.4412 Perplexity: 31.2239\n",
      "Iteration: 4191; Percent complete: 83.8%; Average loss: 3.0411 Perplexity: 20.9287\n",
      "Iteration: 4192; Percent complete: 83.8%; Average loss: 3.1590 Perplexity: 23.5482\n",
      "Iteration: 4193; Percent complete: 83.9%; Average loss: 3.8469 Perplexity: 46.8498\n",
      "Iteration: 4194; Percent complete: 83.9%; Average loss: 3.4392 Perplexity: 31.1607\n",
      "Iteration: 4195; Percent complete: 83.9%; Average loss: 3.5797 Perplexity: 35.8642\n",
      "Iteration: 4196; Percent complete: 83.9%; Average loss: 3.2194 Perplexity: 25.0120\n",
      "Iteration: 4197; Percent complete: 83.9%; Average loss: 3.2926 Perplexity: 26.9121\n",
      "Iteration: 4198; Percent complete: 84.0%; Average loss: 3.3197 Perplexity: 27.6508\n",
      "Iteration: 4199; Percent complete: 84.0%; Average loss: 3.5499 Perplexity: 34.8089\n",
      "Iteration: 4200; Percent complete: 84.0%; Average loss: 3.4947 Perplexity: 32.9390\n",
      "Iteration: 4201; Percent complete: 84.0%; Average loss: 3.6059 Perplexity: 36.8161\n",
      "Iteration: 4202; Percent complete: 84.0%; Average loss: 3.5125 Perplexity: 33.5320\n",
      "Iteration: 4203; Percent complete: 84.1%; Average loss: 3.0696 Perplexity: 21.5324\n",
      "Iteration: 4204; Percent complete: 84.1%; Average loss: 3.3289 Perplexity: 27.9064\n",
      "Iteration: 4205; Percent complete: 84.1%; Average loss: 3.6203 Perplexity: 37.3503\n",
      "Iteration: 4206; Percent complete: 84.1%; Average loss: 3.4276 Perplexity: 30.8015\n",
      "Iteration: 4207; Percent complete: 84.1%; Average loss: 3.3135 Perplexity: 27.4820\n",
      "Iteration: 4208; Percent complete: 84.2%; Average loss: 3.4211 Perplexity: 30.6040\n",
      "Iteration: 4209; Percent complete: 84.2%; Average loss: 3.5730 Perplexity: 35.6217\n",
      "Iteration: 4210; Percent complete: 84.2%; Average loss: 3.8519 Perplexity: 47.0804\n",
      "Iteration: 4211; Percent complete: 84.2%; Average loss: 3.4355 Perplexity: 31.0468\n",
      "Iteration: 4212; Percent complete: 84.2%; Average loss: 3.1448 Perplexity: 23.2147\n",
      "Iteration: 4213; Percent complete: 84.3%; Average loss: 3.1675 Perplexity: 23.7488\n",
      "Iteration: 4214; Percent complete: 84.3%; Average loss: 3.6683 Perplexity: 39.1841\n",
      "Iteration: 4215; Percent complete: 84.3%; Average loss: 3.7325 Perplexity: 41.7843\n",
      "Iteration: 4216; Percent complete: 84.3%; Average loss: 3.4425 Perplexity: 31.2646\n",
      "Iteration: 4217; Percent complete: 84.3%; Average loss: 3.6080 Perplexity: 36.8921\n",
      "Iteration: 4218; Percent complete: 84.4%; Average loss: 3.3423 Perplexity: 28.2834\n",
      "Iteration: 4219; Percent complete: 84.4%; Average loss: 3.6636 Perplexity: 38.9998\n",
      "Iteration: 4220; Percent complete: 84.4%; Average loss: 3.3369 Perplexity: 28.1314\n",
      "Iteration: 4221; Percent complete: 84.4%; Average loss: 3.3812 Perplexity: 29.4048\n",
      "Iteration: 4222; Percent complete: 84.4%; Average loss: 3.2197 Perplexity: 25.0205\n",
      "Iteration: 4223; Percent complete: 84.5%; Average loss: 3.5540 Perplexity: 34.9526\n",
      "Iteration: 4224; Percent complete: 84.5%; Average loss: 3.2294 Perplexity: 25.2645\n",
      "Iteration: 4225; Percent complete: 84.5%; Average loss: 3.0185 Perplexity: 20.4600\n",
      "Iteration: 4226; Percent complete: 84.5%; Average loss: 3.3572 Perplexity: 28.7076\n",
      "Iteration: 4227; Percent complete: 84.5%; Average loss: 3.0416 Perplexity: 20.9385\n",
      "Iteration: 4228; Percent complete: 84.6%; Average loss: 3.6668 Perplexity: 39.1272\n",
      "Iteration: 4229; Percent complete: 84.6%; Average loss: 3.1951 Perplexity: 24.4118\n",
      "Iteration: 4230; Percent complete: 84.6%; Average loss: 3.6694 Perplexity: 39.2277\n",
      "Iteration: 4231; Percent complete: 84.6%; Average loss: 3.9336 Perplexity: 51.0903\n",
      "Iteration: 4232; Percent complete: 84.6%; Average loss: 3.5578 Perplexity: 35.0868\n",
      "Iteration: 4233; Percent complete: 84.7%; Average loss: 3.7721 Perplexity: 43.4706\n",
      "Iteration: 4234; Percent complete: 84.7%; Average loss: 3.6153 Perplexity: 37.1608\n",
      "Iteration: 4235; Percent complete: 84.7%; Average loss: 3.3972 Perplexity: 29.8800\n",
      "Iteration: 4236; Percent complete: 84.7%; Average loss: 3.7209 Perplexity: 41.3023\n",
      "Iteration: 4237; Percent complete: 84.7%; Average loss: 3.9416 Perplexity: 51.5011\n",
      "Iteration: 4238; Percent complete: 84.8%; Average loss: 3.3862 Perplexity: 29.5535\n",
      "Iteration: 4239; Percent complete: 84.8%; Average loss: 3.7825 Perplexity: 43.9276\n",
      "Iteration: 4240; Percent complete: 84.8%; Average loss: 3.2637 Perplexity: 26.1458\n",
      "Iteration: 4241; Percent complete: 84.8%; Average loss: 3.3602 Perplexity: 28.7949\n",
      "Iteration: 4242; Percent complete: 84.8%; Average loss: 3.4388 Perplexity: 31.1481\n",
      "Iteration: 4243; Percent complete: 84.9%; Average loss: 3.3386 Perplexity: 28.1806\n",
      "Iteration: 4244; Percent complete: 84.9%; Average loss: 3.3288 Perplexity: 27.9059\n",
      "Iteration: 4245; Percent complete: 84.9%; Average loss: 3.5593 Perplexity: 35.1394\n",
      "Iteration: 4246; Percent complete: 84.9%; Average loss: 3.4337 Perplexity: 30.9913\n",
      "Iteration: 4247; Percent complete: 84.9%; Average loss: 3.1889 Perplexity: 24.2617\n",
      "Iteration: 4248; Percent complete: 85.0%; Average loss: 3.7913 Perplexity: 44.3131\n",
      "Iteration: 4249; Percent complete: 85.0%; Average loss: 2.9146 Perplexity: 18.4410\n",
      "Iteration: 4250; Percent complete: 85.0%; Average loss: 3.4737 Perplexity: 32.2570\n",
      "Iteration: 4251; Percent complete: 85.0%; Average loss: 3.4409 Perplexity: 31.2166\n",
      "Iteration: 4252; Percent complete: 85.0%; Average loss: 3.4657 Perplexity: 31.9990\n",
      "Iteration: 4253; Percent complete: 85.1%; Average loss: 3.4143 Perplexity: 30.3959\n",
      "Iteration: 4254; Percent complete: 85.1%; Average loss: 3.6075 Perplexity: 36.8722\n",
      "Iteration: 4255; Percent complete: 85.1%; Average loss: 3.4434 Perplexity: 31.2936\n",
      "Iteration: 4256; Percent complete: 85.1%; Average loss: 4.0390 Perplexity: 56.7694\n",
      "Iteration: 4257; Percent complete: 85.1%; Average loss: 3.1950 Perplexity: 24.4105\n",
      "Iteration: 4258; Percent complete: 85.2%; Average loss: 3.6621 Perplexity: 38.9437\n",
      "Iteration: 4259; Percent complete: 85.2%; Average loss: 3.3796 Perplexity: 29.3580\n",
      "Iteration: 4260; Percent complete: 85.2%; Average loss: 3.1763 Perplexity: 23.9570\n",
      "Iteration: 4261; Percent complete: 85.2%; Average loss: 3.6099 Perplexity: 36.9609\n",
      "Iteration: 4262; Percent complete: 85.2%; Average loss: 3.5991 Perplexity: 36.5662\n",
      "Iteration: 4263; Percent complete: 85.3%; Average loss: 3.7997 Perplexity: 44.6863\n",
      "Iteration: 4264; Percent complete: 85.3%; Average loss: 3.5219 Perplexity: 33.8472\n",
      "Iteration: 4265; Percent complete: 85.3%; Average loss: 3.4624 Perplexity: 31.8942\n",
      "Iteration: 4266; Percent complete: 85.3%; Average loss: 3.3972 Perplexity: 29.8805\n",
      "Iteration: 4267; Percent complete: 85.3%; Average loss: 3.4142 Perplexity: 30.3923\n",
      "Iteration: 4268; Percent complete: 85.4%; Average loss: 3.4614 Perplexity: 31.8630\n",
      "Iteration: 4269; Percent complete: 85.4%; Average loss: 3.6491 Perplexity: 38.4419\n",
      "Iteration: 4270; Percent complete: 85.4%; Average loss: 3.2266 Perplexity: 25.1936\n",
      "Iteration: 4271; Percent complete: 85.4%; Average loss: 3.3675 Perplexity: 29.0070\n",
      "Iteration: 4272; Percent complete: 85.4%; Average loss: 3.6128 Perplexity: 37.0687\n",
      "Iteration: 4273; Percent complete: 85.5%; Average loss: 3.7324 Perplexity: 41.7773\n",
      "Iteration: 4274; Percent complete: 85.5%; Average loss: 3.1125 Perplexity: 22.4767\n",
      "Iteration: 4275; Percent complete: 85.5%; Average loss: 3.4709 Perplexity: 32.1661\n",
      "Iteration: 4276; Percent complete: 85.5%; Average loss: 3.8752 Perplexity: 48.1927\n",
      "Iteration: 4277; Percent complete: 85.5%; Average loss: 3.5883 Perplexity: 36.1716\n",
      "Iteration: 4278; Percent complete: 85.6%; Average loss: 3.4113 Perplexity: 30.3055\n",
      "Iteration: 4279; Percent complete: 85.6%; Average loss: 3.4323 Perplexity: 30.9491\n",
      "Iteration: 4280; Percent complete: 85.6%; Average loss: 3.5189 Perplexity: 33.7457\n",
      "Iteration: 4281; Percent complete: 85.6%; Average loss: 3.4971 Perplexity: 33.0184\n",
      "Iteration: 4282; Percent complete: 85.6%; Average loss: 3.0203 Perplexity: 20.4969\n",
      "Iteration: 4283; Percent complete: 85.7%; Average loss: 2.9689 Perplexity: 19.4701\n",
      "Iteration: 4284; Percent complete: 85.7%; Average loss: 3.1852 Perplexity: 24.1712\n",
      "Iteration: 4285; Percent complete: 85.7%; Average loss: 3.2349 Perplexity: 25.4050\n",
      "Iteration: 4286; Percent complete: 85.7%; Average loss: 3.0109 Perplexity: 20.3056\n",
      "Iteration: 4287; Percent complete: 85.7%; Average loss: 3.8312 Perplexity: 46.1186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4288; Percent complete: 85.8%; Average loss: 3.6847 Perplexity: 39.8346\n",
      "Iteration: 4289; Percent complete: 85.8%; Average loss: 3.5323 Perplexity: 34.2017\n",
      "Iteration: 4290; Percent complete: 85.8%; Average loss: 3.6896 Perplexity: 40.0282\n",
      "Iteration: 4291; Percent complete: 85.8%; Average loss: 3.4927 Perplexity: 32.8752\n",
      "Iteration: 4292; Percent complete: 85.8%; Average loss: 4.0688 Perplexity: 58.4895\n",
      "Iteration: 4293; Percent complete: 85.9%; Average loss: 3.8248 Perplexity: 45.8234\n",
      "Iteration: 4294; Percent complete: 85.9%; Average loss: 3.7555 Perplexity: 42.7535\n",
      "Iteration: 4295; Percent complete: 85.9%; Average loss: 3.2996 Perplexity: 27.1017\n",
      "Iteration: 4296; Percent complete: 85.9%; Average loss: 3.8448 Perplexity: 46.7495\n",
      "Iteration: 4297; Percent complete: 85.9%; Average loss: 3.4136 Perplexity: 30.3742\n",
      "Iteration: 4298; Percent complete: 86.0%; Average loss: 2.8513 Perplexity: 17.3102\n",
      "Iteration: 4299; Percent complete: 86.0%; Average loss: 3.1070 Perplexity: 22.3538\n",
      "Iteration: 4300; Percent complete: 86.0%; Average loss: 3.3518 Perplexity: 28.5550\n",
      "Iteration: 4301; Percent complete: 86.0%; Average loss: 3.0380 Perplexity: 20.8627\n",
      "Iteration: 4302; Percent complete: 86.0%; Average loss: 3.1359 Perplexity: 23.0086\n",
      "Iteration: 4303; Percent complete: 86.1%; Average loss: 3.3585 Perplexity: 28.7448\n",
      "Iteration: 4304; Percent complete: 86.1%; Average loss: 3.2646 Perplexity: 26.1707\n",
      "Iteration: 4305; Percent complete: 86.1%; Average loss: 3.3615 Perplexity: 28.8327\n",
      "Iteration: 4306; Percent complete: 86.1%; Average loss: 3.1671 Perplexity: 23.7397\n",
      "Iteration: 4307; Percent complete: 86.1%; Average loss: 3.4110 Perplexity: 30.2964\n",
      "Iteration: 4308; Percent complete: 86.2%; Average loss: 3.0782 Perplexity: 21.7201\n",
      "Iteration: 4309; Percent complete: 86.2%; Average loss: 3.3791 Perplexity: 29.3439\n",
      "Iteration: 4310; Percent complete: 86.2%; Average loss: 3.6671 Perplexity: 39.1368\n",
      "Iteration: 4311; Percent complete: 86.2%; Average loss: 3.1791 Perplexity: 24.0257\n",
      "Iteration: 4312; Percent complete: 86.2%; Average loss: 3.7349 Perplexity: 41.8818\n",
      "Iteration: 4313; Percent complete: 86.3%; Average loss: 3.1914 Perplexity: 24.3214\n",
      "Iteration: 4314; Percent complete: 86.3%; Average loss: 3.6524 Perplexity: 38.5675\n",
      "Iteration: 4315; Percent complete: 86.3%; Average loss: 3.7676 Perplexity: 43.2739\n",
      "Iteration: 4316; Percent complete: 86.3%; Average loss: 3.3531 Perplexity: 28.5909\n",
      "Iteration: 4317; Percent complete: 86.3%; Average loss: 3.5297 Perplexity: 34.1126\n",
      "Iteration: 4318; Percent complete: 86.4%; Average loss: 3.2877 Perplexity: 26.7803\n",
      "Iteration: 4319; Percent complete: 86.4%; Average loss: 3.6602 Perplexity: 38.8705\n",
      "Iteration: 4320; Percent complete: 86.4%; Average loss: 3.4488 Perplexity: 31.4630\n",
      "Iteration: 4321; Percent complete: 86.4%; Average loss: 3.3141 Perplexity: 27.4974\n",
      "Iteration: 4322; Percent complete: 86.4%; Average loss: 3.4369 Perplexity: 31.0910\n",
      "Iteration: 4323; Percent complete: 86.5%; Average loss: 3.6611 Perplexity: 38.9058\n",
      "Iteration: 4324; Percent complete: 86.5%; Average loss: 3.6324 Perplexity: 37.8035\n",
      "Iteration: 4325; Percent complete: 86.5%; Average loss: 3.4329 Perplexity: 30.9673\n",
      "Iteration: 4326; Percent complete: 86.5%; Average loss: 3.6558 Perplexity: 38.6993\n",
      "Iteration: 4327; Percent complete: 86.5%; Average loss: 3.7282 Perplexity: 41.6026\n",
      "Iteration: 4328; Percent complete: 86.6%; Average loss: 3.2616 Perplexity: 26.0905\n",
      "Iteration: 4329; Percent complete: 86.6%; Average loss: 3.6734 Perplexity: 39.3838\n",
      "Iteration: 4330; Percent complete: 86.6%; Average loss: 3.3679 Perplexity: 29.0187\n",
      "Iteration: 4331; Percent complete: 86.6%; Average loss: 3.4344 Perplexity: 31.0132\n",
      "Iteration: 4332; Percent complete: 86.6%; Average loss: 3.3777 Perplexity: 29.3046\n",
      "Iteration: 4333; Percent complete: 86.7%; Average loss: 3.1726 Perplexity: 23.8686\n",
      "Iteration: 4334; Percent complete: 86.7%; Average loss: 3.2398 Perplexity: 25.5279\n",
      "Iteration: 4335; Percent complete: 86.7%; Average loss: 3.1989 Perplexity: 24.5056\n",
      "Iteration: 4336; Percent complete: 86.7%; Average loss: 3.6494 Perplexity: 38.4504\n",
      "Iteration: 4337; Percent complete: 86.7%; Average loss: 3.6746 Perplexity: 39.4328\n",
      "Iteration: 4338; Percent complete: 86.8%; Average loss: 3.7475 Perplexity: 42.4131\n",
      "Iteration: 4339; Percent complete: 86.8%; Average loss: 2.7867 Perplexity: 16.2273\n",
      "Iteration: 4340; Percent complete: 86.8%; Average loss: 3.1963 Perplexity: 24.4420\n",
      "Iteration: 4341; Percent complete: 86.8%; Average loss: 3.5301 Perplexity: 34.1262\n",
      "Iteration: 4342; Percent complete: 86.8%; Average loss: 3.3638 Perplexity: 28.8978\n",
      "Iteration: 4343; Percent complete: 86.9%; Average loss: 3.2280 Perplexity: 25.2284\n",
      "Iteration: 4344; Percent complete: 86.9%; Average loss: 3.6176 Perplexity: 37.2493\n",
      "Iteration: 4345; Percent complete: 86.9%; Average loss: 3.4309 Perplexity: 30.9040\n",
      "Iteration: 4346; Percent complete: 86.9%; Average loss: 3.2418 Perplexity: 25.5805\n",
      "Iteration: 4347; Percent complete: 86.9%; Average loss: 3.2634 Perplexity: 26.1379\n",
      "Iteration: 4348; Percent complete: 87.0%; Average loss: 3.5881 Perplexity: 36.1662\n",
      "Iteration: 4349; Percent complete: 87.0%; Average loss: 3.3108 Perplexity: 27.4074\n",
      "Iteration: 4350; Percent complete: 87.0%; Average loss: 3.4844 Perplexity: 32.6016\n",
      "Iteration: 4351; Percent complete: 87.0%; Average loss: 3.5198 Perplexity: 33.7773\n",
      "Iteration: 4352; Percent complete: 87.0%; Average loss: 3.0055 Perplexity: 20.1968\n",
      "Iteration: 4353; Percent complete: 87.1%; Average loss: 3.3732 Perplexity: 29.1719\n",
      "Iteration: 4354; Percent complete: 87.1%; Average loss: 3.4091 Perplexity: 30.2378\n",
      "Iteration: 4355; Percent complete: 87.1%; Average loss: 3.3277 Perplexity: 27.8748\n",
      "Iteration: 4356; Percent complete: 87.1%; Average loss: 2.8907 Perplexity: 18.0054\n",
      "Iteration: 4357; Percent complete: 87.1%; Average loss: 3.5156 Perplexity: 33.6345\n",
      "Iteration: 4358; Percent complete: 87.2%; Average loss: 3.3140 Perplexity: 27.4961\n",
      "Iteration: 4359; Percent complete: 87.2%; Average loss: 4.1685 Perplexity: 64.6185\n",
      "Iteration: 4360; Percent complete: 87.2%; Average loss: 3.5866 Perplexity: 36.1095\n",
      "Iteration: 4361; Percent complete: 87.2%; Average loss: 3.3874 Perplexity: 29.5881\n",
      "Iteration: 4362; Percent complete: 87.2%; Average loss: 3.5468 Perplexity: 34.7022\n",
      "Iteration: 4363; Percent complete: 87.3%; Average loss: 3.2269 Perplexity: 25.2017\n",
      "Iteration: 4364; Percent complete: 87.3%; Average loss: 3.1626 Perplexity: 23.6311\n",
      "Iteration: 4365; Percent complete: 87.3%; Average loss: 3.7010 Perplexity: 40.4865\n",
      "Iteration: 4366; Percent complete: 87.3%; Average loss: 3.6985 Perplexity: 40.3879\n",
      "Iteration: 4367; Percent complete: 87.3%; Average loss: 3.3202 Perplexity: 27.6668\n",
      "Iteration: 4368; Percent complete: 87.4%; Average loss: 3.4163 Perplexity: 30.4575\n",
      "Iteration: 4369; Percent complete: 87.4%; Average loss: 3.4585 Perplexity: 31.7708\n",
      "Iteration: 4370; Percent complete: 87.4%; Average loss: 3.2187 Perplexity: 24.9964\n",
      "Iteration: 4371; Percent complete: 87.4%; Average loss: 3.4669 Perplexity: 32.0381\n",
      "Iteration: 4372; Percent complete: 87.4%; Average loss: 3.9370 Perplexity: 51.2631\n",
      "Iteration: 4373; Percent complete: 87.5%; Average loss: 3.1329 Perplexity: 22.9394\n",
      "Iteration: 4374; Percent complete: 87.5%; Average loss: 3.8921 Perplexity: 49.0129\n",
      "Iteration: 4375; Percent complete: 87.5%; Average loss: 3.5313 Perplexity: 34.1683\n",
      "Iteration: 4376; Percent complete: 87.5%; Average loss: 3.3240 Perplexity: 27.7703\n",
      "Iteration: 4377; Percent complete: 87.5%; Average loss: 2.8387 Perplexity: 17.0933\n",
      "Iteration: 4378; Percent complete: 87.6%; Average loss: 3.6419 Perplexity: 38.1625\n",
      "Iteration: 4379; Percent complete: 87.6%; Average loss: 3.4110 Perplexity: 30.2956\n",
      "Iteration: 4380; Percent complete: 87.6%; Average loss: 3.9641 Perplexity: 52.6736\n",
      "Iteration: 4381; Percent complete: 87.6%; Average loss: 3.1994 Perplexity: 24.5171\n",
      "Iteration: 4382; Percent complete: 87.6%; Average loss: 3.1919 Perplexity: 24.3351\n",
      "Iteration: 4383; Percent complete: 87.7%; Average loss: 3.2619 Perplexity: 26.1000\n",
      "Iteration: 4384; Percent complete: 87.7%; Average loss: 3.1688 Perplexity: 23.7778\n",
      "Iteration: 4385; Percent complete: 87.7%; Average loss: 3.1473 Perplexity: 23.2725\n",
      "Iteration: 4386; Percent complete: 87.7%; Average loss: 3.3479 Perplexity: 28.4430\n",
      "Iteration: 4387; Percent complete: 87.7%; Average loss: 3.1123 Perplexity: 22.4718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4388; Percent complete: 87.8%; Average loss: 3.3457 Perplexity: 28.3796\n",
      "Iteration: 4389; Percent complete: 87.8%; Average loss: 3.4221 Perplexity: 30.6337\n",
      "Iteration: 4390; Percent complete: 87.8%; Average loss: 3.5028 Perplexity: 33.2082\n",
      "Iteration: 4391; Percent complete: 87.8%; Average loss: 3.0235 Perplexity: 20.5624\n",
      "Iteration: 4392; Percent complete: 87.8%; Average loss: 3.5954 Perplexity: 36.4307\n",
      "Iteration: 4393; Percent complete: 87.9%; Average loss: 3.4564 Perplexity: 31.7012\n",
      "Iteration: 4394; Percent complete: 87.9%; Average loss: 3.4400 Perplexity: 31.1855\n",
      "Iteration: 4395; Percent complete: 87.9%; Average loss: 3.6973 Perplexity: 40.3393\n",
      "Iteration: 4396; Percent complete: 87.9%; Average loss: 3.4462 Perplexity: 31.3806\n",
      "Iteration: 4397; Percent complete: 87.9%; Average loss: 3.6314 Perplexity: 37.7670\n",
      "Iteration: 4398; Percent complete: 88.0%; Average loss: 3.2296 Perplexity: 25.2707\n",
      "Iteration: 4399; Percent complete: 88.0%; Average loss: 3.5127 Perplexity: 33.5388\n",
      "Iteration: 4400; Percent complete: 88.0%; Average loss: 3.8053 Perplexity: 44.9387\n",
      "Iteration: 4401; Percent complete: 88.0%; Average loss: 3.3460 Perplexity: 28.3897\n",
      "Iteration: 4402; Percent complete: 88.0%; Average loss: 3.4487 Perplexity: 31.4596\n",
      "Iteration: 4403; Percent complete: 88.1%; Average loss: 3.1138 Perplexity: 22.5060\n",
      "Iteration: 4404; Percent complete: 88.1%; Average loss: 3.5568 Perplexity: 35.0509\n",
      "Iteration: 4405; Percent complete: 88.1%; Average loss: 3.0788 Perplexity: 21.7319\n",
      "Iteration: 4406; Percent complete: 88.1%; Average loss: 3.7727 Perplexity: 43.4965\n",
      "Iteration: 4407; Percent complete: 88.1%; Average loss: 3.3355 Perplexity: 28.0929\n",
      "Iteration: 4408; Percent complete: 88.2%; Average loss: 3.4686 Perplexity: 32.0903\n",
      "Iteration: 4409; Percent complete: 88.2%; Average loss: 3.3534 Perplexity: 28.5990\n",
      "Iteration: 4410; Percent complete: 88.2%; Average loss: 3.1207 Perplexity: 22.6625\n",
      "Iteration: 4411; Percent complete: 88.2%; Average loss: 3.5124 Perplexity: 33.5301\n",
      "Iteration: 4412; Percent complete: 88.2%; Average loss: 3.2037 Perplexity: 24.6235\n",
      "Iteration: 4413; Percent complete: 88.3%; Average loss: 3.5039 Perplexity: 33.2456\n",
      "Iteration: 4414; Percent complete: 88.3%; Average loss: 3.5312 Perplexity: 34.1640\n",
      "Iteration: 4415; Percent complete: 88.3%; Average loss: 3.3156 Perplexity: 27.5401\n",
      "Iteration: 4416; Percent complete: 88.3%; Average loss: 2.9648 Perplexity: 19.3910\n",
      "Iteration: 4417; Percent complete: 88.3%; Average loss: 3.5146 Perplexity: 33.6028\n",
      "Iteration: 4418; Percent complete: 88.4%; Average loss: 3.1335 Perplexity: 22.9552\n",
      "Iteration: 4419; Percent complete: 88.4%; Average loss: 3.1688 Perplexity: 23.7797\n",
      "Iteration: 4420; Percent complete: 88.4%; Average loss: 3.3538 Perplexity: 28.6124\n",
      "Iteration: 4421; Percent complete: 88.4%; Average loss: 3.7385 Perplexity: 42.0349\n",
      "Iteration: 4422; Percent complete: 88.4%; Average loss: 3.3618 Perplexity: 28.8397\n",
      "Iteration: 4423; Percent complete: 88.5%; Average loss: 3.6463 Perplexity: 38.3313\n",
      "Iteration: 4424; Percent complete: 88.5%; Average loss: 3.1642 Perplexity: 23.6692\n",
      "Iteration: 4425; Percent complete: 88.5%; Average loss: 3.2643 Perplexity: 26.1614\n",
      "Iteration: 4426; Percent complete: 88.5%; Average loss: 3.2222 Perplexity: 25.0827\n",
      "Iteration: 4427; Percent complete: 88.5%; Average loss: 3.4201 Perplexity: 30.5715\n",
      "Iteration: 4428; Percent complete: 88.6%; Average loss: 3.3500 Perplexity: 28.5036\n",
      "Iteration: 4429; Percent complete: 88.6%; Average loss: 3.1938 Perplexity: 24.3807\n",
      "Iteration: 4430; Percent complete: 88.6%; Average loss: 3.4101 Perplexity: 30.2689\n",
      "Iteration: 4431; Percent complete: 88.6%; Average loss: 3.7837 Perplexity: 43.9782\n",
      "Iteration: 4432; Percent complete: 88.6%; Average loss: 3.4290 Perplexity: 30.8454\n",
      "Iteration: 4433; Percent complete: 88.7%; Average loss: 3.2708 Perplexity: 26.3319\n",
      "Iteration: 4434; Percent complete: 88.7%; Average loss: 3.2899 Perplexity: 26.8414\n",
      "Iteration: 4435; Percent complete: 88.7%; Average loss: 3.2065 Perplexity: 24.6926\n",
      "Iteration: 4436; Percent complete: 88.7%; Average loss: 3.2748 Perplexity: 26.4385\n",
      "Iteration: 4437; Percent complete: 88.7%; Average loss: 3.1255 Perplexity: 22.7721\n",
      "Iteration: 4438; Percent complete: 88.8%; Average loss: 3.2725 Perplexity: 26.3770\n",
      "Iteration: 4439; Percent complete: 88.8%; Average loss: 3.4588 Perplexity: 31.7779\n",
      "Iteration: 4440; Percent complete: 88.8%; Average loss: 3.3902 Perplexity: 29.6727\n",
      "Iteration: 4441; Percent complete: 88.8%; Average loss: 3.5707 Perplexity: 35.5403\n",
      "Iteration: 4442; Percent complete: 88.8%; Average loss: 3.4889 Perplexity: 32.7509\n",
      "Iteration: 4443; Percent complete: 88.9%; Average loss: 3.6422 Perplexity: 38.1765\n",
      "Iteration: 4444; Percent complete: 88.9%; Average loss: 3.3017 Perplexity: 27.1597\n",
      "Iteration: 4445; Percent complete: 88.9%; Average loss: 3.3002 Perplexity: 27.1170\n",
      "Iteration: 4446; Percent complete: 88.9%; Average loss: 2.8908 Perplexity: 18.0071\n",
      "Iteration: 4447; Percent complete: 88.9%; Average loss: 3.3812 Perplexity: 29.4049\n",
      "Iteration: 4448; Percent complete: 89.0%; Average loss: 3.2404 Perplexity: 25.5433\n",
      "Iteration: 4449; Percent complete: 89.0%; Average loss: 3.0707 Perplexity: 21.5569\n",
      "Iteration: 4450; Percent complete: 89.0%; Average loss: 3.6439 Perplexity: 38.2411\n",
      "Iteration: 4451; Percent complete: 89.0%; Average loss: 3.0849 Perplexity: 21.8644\n",
      "Iteration: 4452; Percent complete: 89.0%; Average loss: 3.5027 Perplexity: 33.2046\n",
      "Iteration: 4453; Percent complete: 89.1%; Average loss: 3.2466 Perplexity: 25.7036\n",
      "Iteration: 4454; Percent complete: 89.1%; Average loss: 3.3142 Perplexity: 27.5011\n",
      "Iteration: 4455; Percent complete: 89.1%; Average loss: 3.7128 Perplexity: 40.9673\n",
      "Iteration: 4456; Percent complete: 89.1%; Average loss: 3.3688 Perplexity: 29.0429\n",
      "Iteration: 4457; Percent complete: 89.1%; Average loss: 3.0754 Perplexity: 21.6593\n",
      "Iteration: 4458; Percent complete: 89.2%; Average loss: 3.7457 Perplexity: 42.3380\n",
      "Iteration: 4459; Percent complete: 89.2%; Average loss: 3.3205 Perplexity: 27.6742\n",
      "Iteration: 4460; Percent complete: 89.2%; Average loss: 3.1618 Perplexity: 23.6129\n",
      "Iteration: 4461; Percent complete: 89.2%; Average loss: 3.4717 Perplexity: 32.1907\n",
      "Iteration: 4462; Percent complete: 89.2%; Average loss: 2.9909 Perplexity: 19.9026\n",
      "Iteration: 4463; Percent complete: 89.3%; Average loss: 3.0876 Perplexity: 21.9251\n",
      "Iteration: 4464; Percent complete: 89.3%; Average loss: 3.1942 Perplexity: 24.3895\n",
      "Iteration: 4465; Percent complete: 89.3%; Average loss: 3.7781 Perplexity: 43.7340\n",
      "Iteration: 4466; Percent complete: 89.3%; Average loss: 3.6301 Perplexity: 37.7176\n",
      "Iteration: 4467; Percent complete: 89.3%; Average loss: 3.6982 Perplexity: 40.3762\n",
      "Iteration: 4468; Percent complete: 89.4%; Average loss: 2.6721 Perplexity: 14.4705\n",
      "Iteration: 4469; Percent complete: 89.4%; Average loss: 3.6034 Perplexity: 36.7244\n",
      "Iteration: 4470; Percent complete: 89.4%; Average loss: 3.6443 Perplexity: 38.2565\n",
      "Iteration: 4471; Percent complete: 89.4%; Average loss: 3.4878 Perplexity: 32.7126\n",
      "Iteration: 4472; Percent complete: 89.4%; Average loss: 3.5625 Perplexity: 35.2506\n",
      "Iteration: 4473; Percent complete: 89.5%; Average loss: 3.1077 Perplexity: 22.3697\n",
      "Iteration: 4474; Percent complete: 89.5%; Average loss: 3.6489 Perplexity: 38.4341\n",
      "Iteration: 4475; Percent complete: 89.5%; Average loss: 3.6309 Perplexity: 37.7452\n",
      "Iteration: 4476; Percent complete: 89.5%; Average loss: 3.1907 Perplexity: 24.3059\n",
      "Iteration: 4477; Percent complete: 89.5%; Average loss: 3.2685 Perplexity: 26.2707\n",
      "Iteration: 4478; Percent complete: 89.6%; Average loss: 3.3137 Perplexity: 27.4876\n",
      "Iteration: 4479; Percent complete: 89.6%; Average loss: 3.3963 Perplexity: 29.8536\n",
      "Iteration: 4480; Percent complete: 89.6%; Average loss: 3.8522 Perplexity: 47.0977\n",
      "Iteration: 4481; Percent complete: 89.6%; Average loss: 3.4470 Perplexity: 31.4075\n",
      "Iteration: 4482; Percent complete: 89.6%; Average loss: 3.2728 Perplexity: 26.3857\n",
      "Iteration: 4483; Percent complete: 89.7%; Average loss: 3.7905 Perplexity: 44.2766\n",
      "Iteration: 4484; Percent complete: 89.7%; Average loss: 3.1515 Perplexity: 23.3712\n",
      "Iteration: 4485; Percent complete: 89.7%; Average loss: 3.3868 Perplexity: 29.5720\n",
      "Iteration: 4486; Percent complete: 89.7%; Average loss: 3.0835 Perplexity: 21.8342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4487; Percent complete: 89.7%; Average loss: 3.6254 Perplexity: 37.5395\n",
      "Iteration: 4488; Percent complete: 89.8%; Average loss: 3.3691 Perplexity: 29.0528\n",
      "Iteration: 4489; Percent complete: 89.8%; Average loss: 3.7103 Perplexity: 40.8667\n",
      "Iteration: 4490; Percent complete: 89.8%; Average loss: 3.5491 Perplexity: 34.7811\n",
      "Iteration: 4491; Percent complete: 89.8%; Average loss: 3.2828 Perplexity: 26.6502\n",
      "Iteration: 4492; Percent complete: 89.8%; Average loss: 3.0240 Perplexity: 20.5736\n",
      "Iteration: 4493; Percent complete: 89.9%; Average loss: 3.0947 Perplexity: 22.0811\n",
      "Iteration: 4494; Percent complete: 89.9%; Average loss: 3.1211 Perplexity: 22.6720\n",
      "Iteration: 4495; Percent complete: 89.9%; Average loss: 3.6949 Perplexity: 40.2408\n",
      "Iteration: 4496; Percent complete: 89.9%; Average loss: 3.0538 Perplexity: 21.1967\n",
      "Iteration: 4497; Percent complete: 89.9%; Average loss: 3.1270 Perplexity: 22.8063\n",
      "Iteration: 4498; Percent complete: 90.0%; Average loss: 3.4863 Perplexity: 32.6660\n",
      "Iteration: 4499; Percent complete: 90.0%; Average loss: 3.4104 Perplexity: 30.2776\n",
      "Iteration: 4500; Percent complete: 90.0%; Average loss: 3.0377 Perplexity: 20.8564\n",
      "Iteration: 4501; Percent complete: 90.0%; Average loss: 3.1866 Perplexity: 24.2070\n",
      "Iteration: 4502; Percent complete: 90.0%; Average loss: 3.7158 Perplexity: 41.0912\n",
      "Iteration: 4503; Percent complete: 90.1%; Average loss: 3.3584 Perplexity: 28.7431\n",
      "Iteration: 4504; Percent complete: 90.1%; Average loss: 3.2145 Perplexity: 24.8919\n",
      "Iteration: 4505; Percent complete: 90.1%; Average loss: 3.2720 Perplexity: 26.3638\n",
      "Iteration: 4506; Percent complete: 90.1%; Average loss: 3.3090 Perplexity: 27.3568\n",
      "Iteration: 4507; Percent complete: 90.1%; Average loss: 3.3326 Perplexity: 28.0109\n",
      "Iteration: 4508; Percent complete: 90.2%; Average loss: 3.3830 Perplexity: 29.4589\n",
      "Iteration: 4509; Percent complete: 90.2%; Average loss: 3.6016 Perplexity: 36.6559\n",
      "Iteration: 4510; Percent complete: 90.2%; Average loss: 3.5328 Perplexity: 34.2181\n",
      "Iteration: 4511; Percent complete: 90.2%; Average loss: 3.3872 Perplexity: 29.5845\n",
      "Iteration: 4512; Percent complete: 90.2%; Average loss: 3.3314 Perplexity: 27.9776\n",
      "Iteration: 4513; Percent complete: 90.3%; Average loss: 3.4359 Perplexity: 31.0597\n",
      "Iteration: 4514; Percent complete: 90.3%; Average loss: 3.5110 Perplexity: 33.4833\n",
      "Iteration: 4515; Percent complete: 90.3%; Average loss: 3.5511 Perplexity: 34.8526\n",
      "Iteration: 4516; Percent complete: 90.3%; Average loss: 3.4802 Perplexity: 32.4662\n",
      "Iteration: 4517; Percent complete: 90.3%; Average loss: 3.2515 Perplexity: 25.8296\n",
      "Iteration: 4518; Percent complete: 90.4%; Average loss: 3.2401 Perplexity: 25.5351\n",
      "Iteration: 4519; Percent complete: 90.4%; Average loss: 3.6142 Perplexity: 37.1223\n",
      "Iteration: 4520; Percent complete: 90.4%; Average loss: 3.4392 Perplexity: 31.1615\n",
      "Iteration: 4521; Percent complete: 90.4%; Average loss: 3.2914 Perplexity: 26.8818\n",
      "Iteration: 4522; Percent complete: 90.4%; Average loss: 3.1279 Perplexity: 22.8256\n",
      "Iteration: 4523; Percent complete: 90.5%; Average loss: 3.5358 Perplexity: 34.3227\n",
      "Iteration: 4524; Percent complete: 90.5%; Average loss: 3.3808 Perplexity: 29.3935\n",
      "Iteration: 4525; Percent complete: 90.5%; Average loss: 3.2377 Perplexity: 25.4740\n",
      "Iteration: 4526; Percent complete: 90.5%; Average loss: 3.7878 Perplexity: 44.1610\n",
      "Iteration: 4527; Percent complete: 90.5%; Average loss: 3.3661 Perplexity: 28.9646\n",
      "Iteration: 4528; Percent complete: 90.6%; Average loss: 3.7411 Perplexity: 42.1431\n",
      "Iteration: 4529; Percent complete: 90.6%; Average loss: 3.4962 Perplexity: 32.9882\n",
      "Iteration: 4530; Percent complete: 90.6%; Average loss: 3.4149 Perplexity: 30.4141\n",
      "Iteration: 4531; Percent complete: 90.6%; Average loss: 3.3370 Perplexity: 28.1359\n",
      "Iteration: 4532; Percent complete: 90.6%; Average loss: 3.0272 Perplexity: 20.6385\n",
      "Iteration: 4533; Percent complete: 90.7%; Average loss: 3.4434 Perplexity: 31.2926\n",
      "Iteration: 4534; Percent complete: 90.7%; Average loss: 3.1544 Perplexity: 23.4397\n",
      "Iteration: 4535; Percent complete: 90.7%; Average loss: 3.2558 Perplexity: 25.9411\n",
      "Iteration: 4536; Percent complete: 90.7%; Average loss: 3.6411 Perplexity: 38.1344\n",
      "Iteration: 4537; Percent complete: 90.7%; Average loss: 3.5229 Perplexity: 33.8810\n",
      "Iteration: 4538; Percent complete: 90.8%; Average loss: 3.2385 Perplexity: 25.4949\n",
      "Iteration: 4539; Percent complete: 90.8%; Average loss: 3.0282 Perplexity: 20.6603\n",
      "Iteration: 4540; Percent complete: 90.8%; Average loss: 3.4563 Perplexity: 31.6985\n",
      "Iteration: 4541; Percent complete: 90.8%; Average loss: 3.5666 Perplexity: 35.3947\n",
      "Iteration: 4542; Percent complete: 90.8%; Average loss: 3.4289 Perplexity: 30.8422\n",
      "Iteration: 4543; Percent complete: 90.9%; Average loss: 3.4303 Perplexity: 30.8873\n",
      "Iteration: 4544; Percent complete: 90.9%; Average loss: 3.3359 Perplexity: 28.1049\n",
      "Iteration: 4545; Percent complete: 90.9%; Average loss: 3.6368 Perplexity: 37.9683\n",
      "Iteration: 4546; Percent complete: 90.9%; Average loss: 3.1428 Perplexity: 23.1684\n",
      "Iteration: 4547; Percent complete: 90.9%; Average loss: 3.3846 Perplexity: 29.5070\n",
      "Iteration: 4548; Percent complete: 91.0%; Average loss: 2.9661 Perplexity: 19.4151\n",
      "Iteration: 4549; Percent complete: 91.0%; Average loss: 3.4483 Perplexity: 31.4476\n",
      "Iteration: 4550; Percent complete: 91.0%; Average loss: 3.1856 Perplexity: 24.1807\n",
      "Iteration: 4551; Percent complete: 91.0%; Average loss: 3.2503 Perplexity: 25.7983\n",
      "Iteration: 4552; Percent complete: 91.0%; Average loss: 3.3704 Perplexity: 29.0910\n",
      "Iteration: 4553; Percent complete: 91.1%; Average loss: 3.1028 Perplexity: 22.2612\n",
      "Iteration: 4554; Percent complete: 91.1%; Average loss: 3.0695 Perplexity: 21.5319\n",
      "Iteration: 4555; Percent complete: 91.1%; Average loss: 3.2615 Perplexity: 26.0892\n",
      "Iteration: 4556; Percent complete: 91.1%; Average loss: 3.7260 Perplexity: 41.5129\n",
      "Iteration: 4557; Percent complete: 91.1%; Average loss: 3.5772 Perplexity: 35.7722\n",
      "Iteration: 4558; Percent complete: 91.2%; Average loss: 3.3415 Perplexity: 28.2617\n",
      "Iteration: 4559; Percent complete: 91.2%; Average loss: 3.2271 Perplexity: 25.2061\n",
      "Iteration: 4560; Percent complete: 91.2%; Average loss: 2.8906 Perplexity: 18.0043\n",
      "Iteration: 4561; Percent complete: 91.2%; Average loss: 3.5932 Perplexity: 36.3517\n",
      "Iteration: 4562; Percent complete: 91.2%; Average loss: 3.3315 Perplexity: 27.9807\n",
      "Iteration: 4563; Percent complete: 91.3%; Average loss: 3.3365 Perplexity: 28.1210\n",
      "Iteration: 4564; Percent complete: 91.3%; Average loss: 3.1676 Perplexity: 23.7505\n",
      "Iteration: 4565; Percent complete: 91.3%; Average loss: 3.0805 Perplexity: 21.7689\n",
      "Iteration: 4566; Percent complete: 91.3%; Average loss: 3.0590 Perplexity: 21.3065\n",
      "Iteration: 4567; Percent complete: 91.3%; Average loss: 2.9252 Perplexity: 18.6374\n",
      "Iteration: 4568; Percent complete: 91.4%; Average loss: 3.1370 Perplexity: 23.0345\n",
      "Iteration: 4569; Percent complete: 91.4%; Average loss: 3.1036 Perplexity: 22.2787\n",
      "Iteration: 4570; Percent complete: 91.4%; Average loss: 3.0706 Perplexity: 21.5558\n",
      "Iteration: 4571; Percent complete: 91.4%; Average loss: 3.3052 Perplexity: 27.2528\n",
      "Iteration: 4572; Percent complete: 91.4%; Average loss: 3.1914 Perplexity: 24.3235\n",
      "Iteration: 4573; Percent complete: 91.5%; Average loss: 3.2821 Perplexity: 26.6306\n",
      "Iteration: 4574; Percent complete: 91.5%; Average loss: 3.7771 Perplexity: 43.6912\n",
      "Iteration: 4575; Percent complete: 91.5%; Average loss: 3.2024 Perplexity: 24.5924\n",
      "Iteration: 4576; Percent complete: 91.5%; Average loss: 2.9153 Perplexity: 18.4542\n",
      "Iteration: 4577; Percent complete: 91.5%; Average loss: 3.3150 Perplexity: 27.5214\n",
      "Iteration: 4578; Percent complete: 91.6%; Average loss: 3.2944 Perplexity: 26.9601\n",
      "Iteration: 4579; Percent complete: 91.6%; Average loss: 3.6718 Perplexity: 39.3231\n",
      "Iteration: 4580; Percent complete: 91.6%; Average loss: 3.6740 Perplexity: 39.4081\n",
      "Iteration: 4581; Percent complete: 91.6%; Average loss: 3.4968 Perplexity: 33.0100\n",
      "Iteration: 4582; Percent complete: 91.6%; Average loss: 3.1301 Perplexity: 22.8770\n",
      "Iteration: 4583; Percent complete: 91.7%; Average loss: 3.3844 Perplexity: 29.5008\n",
      "Iteration: 4584; Percent complete: 91.7%; Average loss: 3.5351 Perplexity: 34.2996\n",
      "Iteration: 4585; Percent complete: 91.7%; Average loss: 3.3270 Perplexity: 27.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4586; Percent complete: 91.7%; Average loss: 3.6187 Perplexity: 37.2879\n",
      "Iteration: 4587; Percent complete: 91.7%; Average loss: 3.3785 Perplexity: 29.3267\n",
      "Iteration: 4588; Percent complete: 91.8%; Average loss: 3.5904 Perplexity: 36.2472\n",
      "Iteration: 4589; Percent complete: 91.8%; Average loss: 3.3258 Perplexity: 27.8205\n",
      "Iteration: 4590; Percent complete: 91.8%; Average loss: 3.1380 Perplexity: 23.0575\n",
      "Iteration: 4591; Percent complete: 91.8%; Average loss: 3.4553 Perplexity: 31.6686\n",
      "Iteration: 4592; Percent complete: 91.8%; Average loss: 3.1608 Perplexity: 23.5903\n",
      "Iteration: 4593; Percent complete: 91.9%; Average loss: 2.9965 Perplexity: 20.0153\n",
      "Iteration: 4594; Percent complete: 91.9%; Average loss: 3.4194 Perplexity: 30.5521\n",
      "Iteration: 4595; Percent complete: 91.9%; Average loss: 3.2025 Perplexity: 24.5938\n",
      "Iteration: 4596; Percent complete: 91.9%; Average loss: 3.5928 Perplexity: 36.3363\n",
      "Iteration: 4597; Percent complete: 91.9%; Average loss: 3.3618 Perplexity: 28.8413\n",
      "Iteration: 4598; Percent complete: 92.0%; Average loss: 3.1147 Perplexity: 22.5265\n",
      "Iteration: 4599; Percent complete: 92.0%; Average loss: 2.7390 Perplexity: 15.4714\n",
      "Iteration: 4600; Percent complete: 92.0%; Average loss: 3.4289 Perplexity: 30.8417\n",
      "Iteration: 4601; Percent complete: 92.0%; Average loss: 3.0441 Perplexity: 20.9915\n",
      "Iteration: 4602; Percent complete: 92.0%; Average loss: 3.2708 Perplexity: 26.3314\n",
      "Iteration: 4603; Percent complete: 92.1%; Average loss: 3.2204 Perplexity: 25.0393\n",
      "Iteration: 4604; Percent complete: 92.1%; Average loss: 3.4279 Perplexity: 30.8122\n",
      "Iteration: 4605; Percent complete: 92.1%; Average loss: 3.2141 Perplexity: 24.8800\n",
      "Iteration: 4606; Percent complete: 92.1%; Average loss: 3.4307 Perplexity: 30.8989\n",
      "Iteration: 4607; Percent complete: 92.1%; Average loss: 3.0334 Perplexity: 20.7677\n",
      "Iteration: 4608; Percent complete: 92.2%; Average loss: 3.7515 Perplexity: 42.5831\n",
      "Iteration: 4609; Percent complete: 92.2%; Average loss: 3.6038 Perplexity: 36.7363\n",
      "Iteration: 4610; Percent complete: 92.2%; Average loss: 3.7445 Perplexity: 42.2858\n",
      "Iteration: 4611; Percent complete: 92.2%; Average loss: 3.6154 Perplexity: 37.1649\n",
      "Iteration: 4612; Percent complete: 92.2%; Average loss: 3.5560 Perplexity: 35.0215\n",
      "Iteration: 4613; Percent complete: 92.3%; Average loss: 3.1677 Perplexity: 23.7519\n",
      "Iteration: 4614; Percent complete: 92.3%; Average loss: 3.3071 Perplexity: 27.3047\n",
      "Iteration: 4615; Percent complete: 92.3%; Average loss: 3.5120 Perplexity: 33.5148\n",
      "Iteration: 4616; Percent complete: 92.3%; Average loss: 3.4916 Perplexity: 32.8387\n",
      "Iteration: 4617; Percent complete: 92.3%; Average loss: 3.8804 Perplexity: 48.4449\n",
      "Iteration: 4618; Percent complete: 92.4%; Average loss: 3.3363 Perplexity: 28.1162\n",
      "Iteration: 4619; Percent complete: 92.4%; Average loss: 3.1248 Perplexity: 22.7552\n",
      "Iteration: 4620; Percent complete: 92.4%; Average loss: 2.7914 Perplexity: 16.3040\n",
      "Iteration: 4621; Percent complete: 92.4%; Average loss: 3.3615 Perplexity: 28.8322\n",
      "Iteration: 4622; Percent complete: 92.4%; Average loss: 2.9678 Perplexity: 19.4499\n",
      "Iteration: 4623; Percent complete: 92.5%; Average loss: 3.3423 Perplexity: 28.2854\n",
      "Iteration: 4624; Percent complete: 92.5%; Average loss: 3.5432 Perplexity: 34.5781\n",
      "Iteration: 4625; Percent complete: 92.5%; Average loss: 3.0934 Perplexity: 22.0520\n",
      "Iteration: 4626; Percent complete: 92.5%; Average loss: 2.8919 Perplexity: 18.0275\n",
      "Iteration: 4627; Percent complete: 92.5%; Average loss: 2.8426 Perplexity: 17.1598\n",
      "Iteration: 4628; Percent complete: 92.6%; Average loss: 3.1194 Perplexity: 22.6329\n",
      "Iteration: 4629; Percent complete: 92.6%; Average loss: 3.3395 Perplexity: 28.2045\n",
      "Iteration: 4630; Percent complete: 92.6%; Average loss: 3.5115 Perplexity: 33.4970\n",
      "Iteration: 4631; Percent complete: 92.6%; Average loss: 3.1825 Perplexity: 24.1068\n",
      "Iteration: 4632; Percent complete: 92.6%; Average loss: 3.3931 Perplexity: 29.7584\n",
      "Iteration: 4633; Percent complete: 92.7%; Average loss: 3.3425 Perplexity: 28.2885\n",
      "Iteration: 4634; Percent complete: 92.7%; Average loss: 3.3120 Perplexity: 27.4396\n",
      "Iteration: 4635; Percent complete: 92.7%; Average loss: 3.4788 Perplexity: 32.4213\n",
      "Iteration: 4636; Percent complete: 92.7%; Average loss: 3.6699 Perplexity: 39.2469\n",
      "Iteration: 4637; Percent complete: 92.7%; Average loss: 3.2630 Perplexity: 26.1269\n",
      "Iteration: 4638; Percent complete: 92.8%; Average loss: 3.2954 Perplexity: 26.9889\n",
      "Iteration: 4639; Percent complete: 92.8%; Average loss: 3.5121 Perplexity: 33.5173\n",
      "Iteration: 4640; Percent complete: 92.8%; Average loss: 3.4753 Perplexity: 32.3072\n",
      "Iteration: 4641; Percent complete: 92.8%; Average loss: 3.0730 Perplexity: 21.6075\n",
      "Iteration: 4642; Percent complete: 92.8%; Average loss: 2.8563 Perplexity: 17.3974\n",
      "Iteration: 4643; Percent complete: 92.9%; Average loss: 3.0335 Perplexity: 20.7707\n",
      "Iteration: 4644; Percent complete: 92.9%; Average loss: 3.5323 Perplexity: 34.2041\n",
      "Iteration: 4645; Percent complete: 92.9%; Average loss: 3.2204 Perplexity: 25.0390\n",
      "Iteration: 4646; Percent complete: 92.9%; Average loss: 3.5258 Perplexity: 33.9821\n",
      "Iteration: 4647; Percent complete: 92.9%; Average loss: 2.9616 Perplexity: 19.3292\n",
      "Iteration: 4648; Percent complete: 93.0%; Average loss: 3.6353 Perplexity: 37.9116\n",
      "Iteration: 4649; Percent complete: 93.0%; Average loss: 3.3319 Perplexity: 27.9903\n",
      "Iteration: 4650; Percent complete: 93.0%; Average loss: 3.0836 Perplexity: 21.8365\n",
      "Iteration: 4651; Percent complete: 93.0%; Average loss: 2.7884 Perplexity: 16.2550\n",
      "Iteration: 4652; Percent complete: 93.0%; Average loss: 3.4792 Perplexity: 32.4324\n",
      "Iteration: 4653; Percent complete: 93.1%; Average loss: 3.4207 Perplexity: 30.5899\n",
      "Iteration: 4654; Percent complete: 93.1%; Average loss: 3.0236 Perplexity: 20.5649\n",
      "Iteration: 4655; Percent complete: 93.1%; Average loss: 3.2197 Perplexity: 25.0213\n",
      "Iteration: 4656; Percent complete: 93.1%; Average loss: 3.7235 Perplexity: 41.4078\n",
      "Iteration: 4657; Percent complete: 93.1%; Average loss: 2.8333 Perplexity: 17.0017\n",
      "Iteration: 4658; Percent complete: 93.2%; Average loss: 3.3388 Perplexity: 28.1866\n",
      "Iteration: 4659; Percent complete: 93.2%; Average loss: 3.2438 Perplexity: 25.6303\n",
      "Iteration: 4660; Percent complete: 93.2%; Average loss: 3.5353 Perplexity: 34.3051\n",
      "Iteration: 4661; Percent complete: 93.2%; Average loss: 2.8821 Perplexity: 17.8518\n",
      "Iteration: 4662; Percent complete: 93.2%; Average loss: 3.2169 Perplexity: 24.9506\n",
      "Iteration: 4663; Percent complete: 93.3%; Average loss: 3.5145 Perplexity: 33.5995\n",
      "Iteration: 4664; Percent complete: 93.3%; Average loss: 3.0949 Perplexity: 22.0842\n",
      "Iteration: 4665; Percent complete: 93.3%; Average loss: 3.4295 Perplexity: 30.8627\n",
      "Iteration: 4666; Percent complete: 93.3%; Average loss: 3.4729 Perplexity: 32.2316\n",
      "Iteration: 4667; Percent complete: 93.3%; Average loss: 3.0640 Perplexity: 21.4140\n",
      "Iteration: 4668; Percent complete: 93.4%; Average loss: 3.0156 Perplexity: 20.4020\n",
      "Iteration: 4669; Percent complete: 93.4%; Average loss: 3.2794 Perplexity: 26.5597\n",
      "Iteration: 4670; Percent complete: 93.4%; Average loss: 3.1595 Perplexity: 23.5589\n",
      "Iteration: 4671; Percent complete: 93.4%; Average loss: 2.9985 Perplexity: 20.0559\n",
      "Iteration: 4672; Percent complete: 93.4%; Average loss: 3.1849 Perplexity: 24.1645\n",
      "Iteration: 4673; Percent complete: 93.5%; Average loss: 3.6394 Perplexity: 38.0686\n",
      "Iteration: 4674; Percent complete: 93.5%; Average loss: 2.8436 Perplexity: 17.1782\n",
      "Iteration: 4675; Percent complete: 93.5%; Average loss: 3.3575 Perplexity: 28.7167\n",
      "Iteration: 4676; Percent complete: 93.5%; Average loss: 3.3755 Perplexity: 29.2382\n",
      "Iteration: 4677; Percent complete: 93.5%; Average loss: 3.1240 Perplexity: 22.7368\n",
      "Iteration: 4678; Percent complete: 93.6%; Average loss: 3.2792 Perplexity: 26.5558\n",
      "Iteration: 4679; Percent complete: 93.6%; Average loss: 3.2542 Perplexity: 25.9000\n",
      "Iteration: 4680; Percent complete: 93.6%; Average loss: 3.2441 Perplexity: 25.6393\n",
      "Iteration: 4681; Percent complete: 93.6%; Average loss: 3.5694 Perplexity: 35.4965\n",
      "Iteration: 4682; Percent complete: 93.6%; Average loss: 3.3488 Perplexity: 28.4683\n",
      "Iteration: 4683; Percent complete: 93.7%; Average loss: 3.2866 Perplexity: 26.7505\n",
      "Iteration: 4684; Percent complete: 93.7%; Average loss: 3.4343 Perplexity: 31.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4685; Percent complete: 93.7%; Average loss: 3.0167 Perplexity: 20.4228\n",
      "Iteration: 4686; Percent complete: 93.7%; Average loss: 3.4797 Perplexity: 32.4493\n",
      "Iteration: 4687; Percent complete: 93.7%; Average loss: 3.5265 Perplexity: 34.0044\n",
      "Iteration: 4688; Percent complete: 93.8%; Average loss: 3.2209 Perplexity: 25.0510\n",
      "Iteration: 4689; Percent complete: 93.8%; Average loss: 3.1831 Perplexity: 24.1218\n",
      "Iteration: 4690; Percent complete: 93.8%; Average loss: 3.8233 Perplexity: 45.7547\n",
      "Iteration: 4691; Percent complete: 93.8%; Average loss: 3.3507 Perplexity: 28.5228\n",
      "Iteration: 4692; Percent complete: 93.8%; Average loss: 3.2122 Perplexity: 24.8335\n",
      "Iteration: 4693; Percent complete: 93.9%; Average loss: 3.3279 Perplexity: 27.8808\n",
      "Iteration: 4694; Percent complete: 93.9%; Average loss: 3.6843 Perplexity: 39.8183\n",
      "Iteration: 4695; Percent complete: 93.9%; Average loss: 3.3032 Perplexity: 27.1983\n",
      "Iteration: 4696; Percent complete: 93.9%; Average loss: 2.8420 Perplexity: 17.1504\n",
      "Iteration: 4697; Percent complete: 93.9%; Average loss: 3.3008 Perplexity: 27.1350\n",
      "Iteration: 4698; Percent complete: 94.0%; Average loss: 3.2187 Perplexity: 24.9958\n",
      "Iteration: 4699; Percent complete: 94.0%; Average loss: 3.3420 Perplexity: 28.2770\n",
      "Iteration: 4700; Percent complete: 94.0%; Average loss: 2.8605 Perplexity: 17.4701\n",
      "Iteration: 4701; Percent complete: 94.0%; Average loss: 2.9920 Perplexity: 19.9264\n",
      "Iteration: 4702; Percent complete: 94.0%; Average loss: 3.2582 Perplexity: 26.0021\n",
      "Iteration: 4703; Percent complete: 94.1%; Average loss: 3.3390 Perplexity: 28.1900\n",
      "Iteration: 4704; Percent complete: 94.1%; Average loss: 3.5257 Perplexity: 33.9775\n",
      "Iteration: 4705; Percent complete: 94.1%; Average loss: 2.9155 Perplexity: 18.4575\n",
      "Iteration: 4706; Percent complete: 94.1%; Average loss: 3.5010 Perplexity: 33.1499\n",
      "Iteration: 4707; Percent complete: 94.1%; Average loss: 3.0534 Perplexity: 21.1862\n",
      "Iteration: 4708; Percent complete: 94.2%; Average loss: 3.1335 Perplexity: 22.9540\n",
      "Iteration: 4709; Percent complete: 94.2%; Average loss: 3.5261 Perplexity: 33.9909\n",
      "Iteration: 4710; Percent complete: 94.2%; Average loss: 3.0692 Perplexity: 21.5240\n",
      "Iteration: 4711; Percent complete: 94.2%; Average loss: 3.6252 Perplexity: 37.5332\n",
      "Iteration: 4712; Percent complete: 94.2%; Average loss: 3.2994 Perplexity: 27.0976\n",
      "Iteration: 4713; Percent complete: 94.3%; Average loss: 3.2937 Perplexity: 26.9417\n",
      "Iteration: 4714; Percent complete: 94.3%; Average loss: 3.0763 Perplexity: 21.6781\n",
      "Iteration: 4715; Percent complete: 94.3%; Average loss: 3.3458 Perplexity: 28.3832\n",
      "Iteration: 4716; Percent complete: 94.3%; Average loss: 2.9790 Perplexity: 19.6675\n",
      "Iteration: 4717; Percent complete: 94.3%; Average loss: 3.4161 Perplexity: 30.4515\n",
      "Iteration: 4718; Percent complete: 94.4%; Average loss: 3.2404 Perplexity: 25.5451\n",
      "Iteration: 4719; Percent complete: 94.4%; Average loss: 3.8885 Perplexity: 48.8368\n",
      "Iteration: 4720; Percent complete: 94.4%; Average loss: 3.0121 Perplexity: 20.3295\n",
      "Iteration: 4721; Percent complete: 94.4%; Average loss: 2.9092 Perplexity: 18.3423\n",
      "Iteration: 4722; Percent complete: 94.4%; Average loss: 3.2259 Perplexity: 25.1759\n",
      "Iteration: 4723; Percent complete: 94.5%; Average loss: 3.3261 Perplexity: 27.8285\n",
      "Iteration: 4724; Percent complete: 94.5%; Average loss: 3.1365 Perplexity: 23.0222\n",
      "Iteration: 4725; Percent complete: 94.5%; Average loss: 3.4479 Perplexity: 31.4346\n",
      "Iteration: 4726; Percent complete: 94.5%; Average loss: 3.4053 Perplexity: 30.1235\n",
      "Iteration: 4727; Percent complete: 94.5%; Average loss: 3.4228 Perplexity: 30.6539\n",
      "Iteration: 4728; Percent complete: 94.6%; Average loss: 3.1402 Perplexity: 23.1089\n",
      "Iteration: 4729; Percent complete: 94.6%; Average loss: 3.1785 Perplexity: 24.0103\n",
      "Iteration: 4730; Percent complete: 94.6%; Average loss: 3.0191 Perplexity: 20.4727\n",
      "Iteration: 4731; Percent complete: 94.6%; Average loss: 3.2841 Perplexity: 26.6854\n",
      "Iteration: 4732; Percent complete: 94.6%; Average loss: 3.3803 Perplexity: 29.3798\n",
      "Iteration: 4733; Percent complete: 94.7%; Average loss: 3.3177 Perplexity: 27.5965\n",
      "Iteration: 4734; Percent complete: 94.7%; Average loss: 2.8817 Perplexity: 17.8447\n",
      "Iteration: 4735; Percent complete: 94.7%; Average loss: 2.9058 Perplexity: 18.2799\n",
      "Iteration: 4736; Percent complete: 94.7%; Average loss: 3.6370 Perplexity: 37.9791\n",
      "Iteration: 4737; Percent complete: 94.7%; Average loss: 3.6562 Perplexity: 38.7139\n",
      "Iteration: 4738; Percent complete: 94.8%; Average loss: 3.0784 Perplexity: 21.7227\n",
      "Iteration: 4739; Percent complete: 94.8%; Average loss: 2.9977 Perplexity: 20.0391\n",
      "Iteration: 4740; Percent complete: 94.8%; Average loss: 3.4331 Perplexity: 30.9739\n",
      "Iteration: 4741; Percent complete: 94.8%; Average loss: 3.2884 Perplexity: 26.8004\n",
      "Iteration: 4742; Percent complete: 94.8%; Average loss: 3.0427 Perplexity: 20.9610\n",
      "Iteration: 4743; Percent complete: 94.9%; Average loss: 3.4328 Perplexity: 30.9630\n",
      "Iteration: 4744; Percent complete: 94.9%; Average loss: 3.0166 Perplexity: 20.4224\n",
      "Iteration: 4745; Percent complete: 94.9%; Average loss: 3.0486 Perplexity: 21.0852\n",
      "Iteration: 4746; Percent complete: 94.9%; Average loss: 3.3986 Perplexity: 29.9229\n",
      "Iteration: 4747; Percent complete: 94.9%; Average loss: 3.2622 Perplexity: 26.1069\n",
      "Iteration: 4748; Percent complete: 95.0%; Average loss: 3.5696 Perplexity: 35.5030\n",
      "Iteration: 4749; Percent complete: 95.0%; Average loss: 3.0972 Perplexity: 22.1352\n",
      "Iteration: 4750; Percent complete: 95.0%; Average loss: 3.1955 Perplexity: 24.4233\n",
      "Iteration: 4751; Percent complete: 95.0%; Average loss: 3.2742 Perplexity: 26.4210\n",
      "Iteration: 4752; Percent complete: 95.0%; Average loss: 3.6131 Perplexity: 37.0797\n",
      "Iteration: 4753; Percent complete: 95.1%; Average loss: 2.9811 Perplexity: 19.7097\n",
      "Iteration: 4754; Percent complete: 95.1%; Average loss: 3.3369 Perplexity: 28.1331\n",
      "Iteration: 4755; Percent complete: 95.1%; Average loss: 3.4123 Perplexity: 30.3348\n",
      "Iteration: 4756; Percent complete: 95.1%; Average loss: 2.9232 Perplexity: 18.6005\n",
      "Iteration: 4757; Percent complete: 95.1%; Average loss: 3.2468 Perplexity: 25.7074\n",
      "Iteration: 4758; Percent complete: 95.2%; Average loss: 3.4867 Perplexity: 32.6770\n",
      "Iteration: 4759; Percent complete: 95.2%; Average loss: 3.2659 Perplexity: 26.2032\n",
      "Iteration: 4760; Percent complete: 95.2%; Average loss: 3.6425 Perplexity: 38.1868\n",
      "Iteration: 4761; Percent complete: 95.2%; Average loss: 3.3386 Perplexity: 28.1804\n",
      "Iteration: 4762; Percent complete: 95.2%; Average loss: 3.3484 Perplexity: 28.4585\n",
      "Iteration: 4763; Percent complete: 95.3%; Average loss: 3.2438 Perplexity: 25.6310\n",
      "Iteration: 4764; Percent complete: 95.3%; Average loss: 3.2551 Perplexity: 25.9233\n",
      "Iteration: 4765; Percent complete: 95.3%; Average loss: 3.5213 Perplexity: 33.8291\n",
      "Iteration: 4766; Percent complete: 95.3%; Average loss: 2.9994 Perplexity: 20.0726\n",
      "Iteration: 4767; Percent complete: 95.3%; Average loss: 3.8720 Perplexity: 48.0402\n",
      "Iteration: 4768; Percent complete: 95.4%; Average loss: 3.6976 Perplexity: 40.3495\n",
      "Iteration: 4769; Percent complete: 95.4%; Average loss: 3.6024 Perplexity: 36.6845\n",
      "Iteration: 4770; Percent complete: 95.4%; Average loss: 3.0726 Perplexity: 21.5980\n",
      "Iteration: 4771; Percent complete: 95.4%; Average loss: 3.2977 Perplexity: 27.0505\n",
      "Iteration: 4772; Percent complete: 95.4%; Average loss: 3.4026 Perplexity: 30.0428\n",
      "Iteration: 4773; Percent complete: 95.5%; Average loss: 3.2692 Perplexity: 26.2912\n",
      "Iteration: 4774; Percent complete: 95.5%; Average loss: 3.2601 Perplexity: 26.0512\n",
      "Iteration: 4775; Percent complete: 95.5%; Average loss: 3.3265 Perplexity: 27.8396\n",
      "Iteration: 4776; Percent complete: 95.5%; Average loss: 3.3819 Perplexity: 29.4258\n",
      "Iteration: 4777; Percent complete: 95.5%; Average loss: 3.6607 Perplexity: 38.8887\n",
      "Iteration: 4778; Percent complete: 95.6%; Average loss: 3.0312 Perplexity: 20.7213\n",
      "Iteration: 4779; Percent complete: 95.6%; Average loss: 3.5365 Perplexity: 34.3463\n",
      "Iteration: 4780; Percent complete: 95.6%; Average loss: 2.9522 Perplexity: 19.1478\n",
      "Iteration: 4781; Percent complete: 95.6%; Average loss: 3.1427 Perplexity: 23.1669\n",
      "Iteration: 4782; Percent complete: 95.6%; Average loss: 3.3491 Perplexity: 28.4777\n",
      "Iteration: 4783; Percent complete: 95.7%; Average loss: 3.5825 Perplexity: 35.9643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4784; Percent complete: 95.7%; Average loss: 3.3213 Perplexity: 27.6967\n",
      "Iteration: 4785; Percent complete: 95.7%; Average loss: 3.4752 Perplexity: 32.3045\n",
      "Iteration: 4786; Percent complete: 95.7%; Average loss: 3.1523 Perplexity: 23.3893\n",
      "Iteration: 4787; Percent complete: 95.7%; Average loss: 3.2550 Perplexity: 25.9209\n",
      "Iteration: 4788; Percent complete: 95.8%; Average loss: 3.4243 Perplexity: 30.7020\n",
      "Iteration: 4789; Percent complete: 95.8%; Average loss: 3.0849 Perplexity: 21.8646\n",
      "Iteration: 4790; Percent complete: 95.8%; Average loss: 3.2059 Perplexity: 24.6774\n",
      "Iteration: 4791; Percent complete: 95.8%; Average loss: 3.4293 Perplexity: 30.8543\n",
      "Iteration: 4792; Percent complete: 95.8%; Average loss: 3.0073 Perplexity: 20.2318\n",
      "Iteration: 4793; Percent complete: 95.9%; Average loss: 2.7229 Perplexity: 15.2242\n",
      "Iteration: 4794; Percent complete: 95.9%; Average loss: 3.1676 Perplexity: 23.7513\n",
      "Iteration: 4795; Percent complete: 95.9%; Average loss: 3.0071 Perplexity: 20.2293\n",
      "Iteration: 4796; Percent complete: 95.9%; Average loss: 3.0583 Perplexity: 21.2915\n",
      "Iteration: 4797; Percent complete: 95.9%; Average loss: 3.4964 Perplexity: 32.9965\n",
      "Iteration: 4798; Percent complete: 96.0%; Average loss: 3.1449 Perplexity: 23.2177\n",
      "Iteration: 4799; Percent complete: 96.0%; Average loss: 3.1955 Perplexity: 24.4223\n",
      "Iteration: 4800; Percent complete: 96.0%; Average loss: 3.1373 Perplexity: 23.0406\n",
      "Iteration: 4801; Percent complete: 96.0%; Average loss: 3.4920 Perplexity: 32.8519\n",
      "Iteration: 4802; Percent complete: 96.0%; Average loss: 3.0615 Perplexity: 21.3604\n",
      "Iteration: 4803; Percent complete: 96.1%; Average loss: 3.0318 Perplexity: 20.7343\n",
      "Iteration: 4804; Percent complete: 96.1%; Average loss: 3.5216 Perplexity: 33.8395\n",
      "Iteration: 4805; Percent complete: 96.1%; Average loss: 3.3174 Perplexity: 27.5895\n",
      "Iteration: 4806; Percent complete: 96.1%; Average loss: 3.2499 Perplexity: 25.7873\n",
      "Iteration: 4807; Percent complete: 96.1%; Average loss: 3.4221 Perplexity: 30.6328\n",
      "Iteration: 4808; Percent complete: 96.2%; Average loss: 3.1466 Perplexity: 23.2567\n",
      "Iteration: 4809; Percent complete: 96.2%; Average loss: 2.8411 Perplexity: 17.1342\n",
      "Iteration: 4810; Percent complete: 96.2%; Average loss: 3.1698 Perplexity: 23.8026\n",
      "Iteration: 4811; Percent complete: 96.2%; Average loss: 3.5293 Perplexity: 34.1010\n",
      "Iteration: 4812; Percent complete: 96.2%; Average loss: 3.3513 Perplexity: 28.5406\n",
      "Iteration: 4813; Percent complete: 96.3%; Average loss: 3.6258 Perplexity: 37.5531\n",
      "Iteration: 4814; Percent complete: 96.3%; Average loss: 3.3263 Perplexity: 27.8353\n",
      "Iteration: 4815; Percent complete: 96.3%; Average loss: 3.2605 Perplexity: 26.0614\n",
      "Iteration: 4816; Percent complete: 96.3%; Average loss: 3.1440 Perplexity: 23.1968\n",
      "Iteration: 4817; Percent complete: 96.3%; Average loss: 3.0794 Perplexity: 21.7445\n",
      "Iteration: 4818; Percent complete: 96.4%; Average loss: 3.3724 Perplexity: 29.1479\n",
      "Iteration: 4819; Percent complete: 96.4%; Average loss: 3.0738 Perplexity: 21.6248\n",
      "Iteration: 4820; Percent complete: 96.4%; Average loss: 3.8337 Perplexity: 46.2356\n",
      "Iteration: 4821; Percent complete: 96.4%; Average loss: 3.4056 Perplexity: 30.1338\n",
      "Iteration: 4822; Percent complete: 96.4%; Average loss: 3.4406 Perplexity: 31.2070\n",
      "Iteration: 4823; Percent complete: 96.5%; Average loss: 3.0379 Perplexity: 20.8609\n",
      "Iteration: 4824; Percent complete: 96.5%; Average loss: 3.4107 Perplexity: 30.2857\n",
      "Iteration: 4825; Percent complete: 96.5%; Average loss: 2.9413 Perplexity: 18.9411\n",
      "Iteration: 4826; Percent complete: 96.5%; Average loss: 3.4556 Perplexity: 31.6769\n",
      "Iteration: 4827; Percent complete: 96.5%; Average loss: 2.9434 Perplexity: 18.9799\n",
      "Iteration: 4828; Percent complete: 96.6%; Average loss: 3.1910 Perplexity: 24.3130\n",
      "Iteration: 4829; Percent complete: 96.6%; Average loss: 3.2948 Perplexity: 26.9710\n",
      "Iteration: 4830; Percent complete: 96.6%; Average loss: 3.5079 Perplexity: 33.3789\n",
      "Iteration: 4831; Percent complete: 96.6%; Average loss: 3.2464 Perplexity: 25.6985\n",
      "Iteration: 4832; Percent complete: 96.6%; Average loss: 3.4178 Perplexity: 30.5023\n",
      "Iteration: 4833; Percent complete: 96.7%; Average loss: 3.2194 Perplexity: 25.0143\n",
      "Iteration: 4834; Percent complete: 96.7%; Average loss: 2.9228 Perplexity: 18.5932\n",
      "Iteration: 4835; Percent complete: 96.7%; Average loss: 3.1025 Perplexity: 22.2527\n",
      "Iteration: 4836; Percent complete: 96.7%; Average loss: 3.2570 Perplexity: 25.9705\n",
      "Iteration: 4837; Percent complete: 96.7%; Average loss: 3.1941 Perplexity: 24.3889\n",
      "Iteration: 4838; Percent complete: 96.8%; Average loss: 3.3130 Perplexity: 27.4672\n",
      "Iteration: 4839; Percent complete: 96.8%; Average loss: 3.1219 Perplexity: 22.6886\n",
      "Iteration: 4840; Percent complete: 96.8%; Average loss: 3.0115 Perplexity: 20.3181\n",
      "Iteration: 4841; Percent complete: 96.8%; Average loss: 3.3172 Perplexity: 27.5818\n",
      "Iteration: 4842; Percent complete: 96.8%; Average loss: 3.4549 Perplexity: 31.6566\n",
      "Iteration: 4843; Percent complete: 96.9%; Average loss: 3.1833 Perplexity: 24.1272\n",
      "Iteration: 4844; Percent complete: 96.9%; Average loss: 3.1309 Perplexity: 22.8946\n",
      "Iteration: 4845; Percent complete: 96.9%; Average loss: 2.8298 Perplexity: 16.9427\n",
      "Iteration: 4846; Percent complete: 96.9%; Average loss: 3.2338 Perplexity: 25.3754\n",
      "Iteration: 4847; Percent complete: 96.9%; Average loss: 2.8525 Perplexity: 17.3314\n",
      "Iteration: 4848; Percent complete: 97.0%; Average loss: 3.3052 Perplexity: 27.2547\n",
      "Iteration: 4849; Percent complete: 97.0%; Average loss: 3.3497 Perplexity: 28.4929\n",
      "Iteration: 4850; Percent complete: 97.0%; Average loss: 2.9496 Perplexity: 19.0986\n",
      "Iteration: 4851; Percent complete: 97.0%; Average loss: 3.2171 Perplexity: 24.9564\n",
      "Iteration: 4852; Percent complete: 97.0%; Average loss: 3.5327 Perplexity: 34.2150\n",
      "Iteration: 4853; Percent complete: 97.1%; Average loss: 2.9418 Perplexity: 18.9496\n",
      "Iteration: 4854; Percent complete: 97.1%; Average loss: 3.0507 Perplexity: 21.1296\n",
      "Iteration: 4855; Percent complete: 97.1%; Average loss: 3.0883 Perplexity: 21.9392\n",
      "Iteration: 4856; Percent complete: 97.1%; Average loss: 3.4421 Perplexity: 31.2516\n",
      "Iteration: 4857; Percent complete: 97.1%; Average loss: 3.4452 Perplexity: 31.3497\n",
      "Iteration: 4858; Percent complete: 97.2%; Average loss: 3.5947 Perplexity: 36.4060\n",
      "Iteration: 4859; Percent complete: 97.2%; Average loss: 3.1506 Perplexity: 23.3505\n",
      "Iteration: 4860; Percent complete: 97.2%; Average loss: 3.4920 Perplexity: 32.8527\n",
      "Iteration: 4861; Percent complete: 97.2%; Average loss: 3.3000 Perplexity: 27.1137\n",
      "Iteration: 4862; Percent complete: 97.2%; Average loss: 3.4639 Perplexity: 31.9420\n",
      "Iteration: 4863; Percent complete: 97.3%; Average loss: 3.3829 Perplexity: 29.4562\n",
      "Iteration: 4864; Percent complete: 97.3%; Average loss: 3.0459 Perplexity: 21.0280\n",
      "Iteration: 4865; Percent complete: 97.3%; Average loss: 3.3150 Perplexity: 27.5232\n",
      "Iteration: 4866; Percent complete: 97.3%; Average loss: 3.1077 Perplexity: 22.3703\n",
      "Iteration: 4867; Percent complete: 97.3%; Average loss: 3.5972 Perplexity: 36.4958\n",
      "Iteration: 4868; Percent complete: 97.4%; Average loss: 3.2707 Perplexity: 26.3292\n",
      "Iteration: 4869; Percent complete: 97.4%; Average loss: 3.4631 Perplexity: 31.9147\n",
      "Iteration: 4870; Percent complete: 97.4%; Average loss: 3.4656 Perplexity: 31.9968\n",
      "Iteration: 4871; Percent complete: 97.4%; Average loss: 2.9038 Perplexity: 18.2436\n",
      "Iteration: 4872; Percent complete: 97.4%; Average loss: 3.1679 Perplexity: 23.7585\n",
      "Iteration: 4873; Percent complete: 97.5%; Average loss: 3.3839 Perplexity: 29.4855\n",
      "Iteration: 4874; Percent complete: 97.5%; Average loss: 3.4083 Perplexity: 30.2138\n",
      "Iteration: 4875; Percent complete: 97.5%; Average loss: 3.1252 Perplexity: 22.7651\n",
      "Iteration: 4876; Percent complete: 97.5%; Average loss: 3.6177 Perplexity: 37.2521\n",
      "Iteration: 4877; Percent complete: 97.5%; Average loss: 3.4258 Perplexity: 30.7458\n",
      "Iteration: 4878; Percent complete: 97.6%; Average loss: 3.3464 Perplexity: 28.3996\n",
      "Iteration: 4879; Percent complete: 97.6%; Average loss: 3.3585 Perplexity: 28.7452\n",
      "Iteration: 4880; Percent complete: 97.6%; Average loss: 3.4028 Perplexity: 30.0473\n",
      "Iteration: 4881; Percent complete: 97.6%; Average loss: 3.5219 Perplexity: 33.8478\n",
      "Iteration: 4882; Percent complete: 97.6%; Average loss: 3.4379 Perplexity: 31.1203\n",
      "Iteration: 4883; Percent complete: 97.7%; Average loss: 3.2562 Perplexity: 25.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4884; Percent complete: 97.7%; Average loss: 3.3416 Perplexity: 28.2648\n",
      "Iteration: 4885; Percent complete: 97.7%; Average loss: 3.5199 Perplexity: 33.7817\n",
      "Iteration: 4886; Percent complete: 97.7%; Average loss: 3.3774 Perplexity: 29.2936\n",
      "Iteration: 4887; Percent complete: 97.7%; Average loss: 3.3489 Perplexity: 28.4722\n",
      "Iteration: 4888; Percent complete: 97.8%; Average loss: 3.0200 Perplexity: 20.4911\n",
      "Iteration: 4889; Percent complete: 97.8%; Average loss: 3.0296 Perplexity: 20.6899\n",
      "Iteration: 4890; Percent complete: 97.8%; Average loss: 2.8783 Perplexity: 17.7838\n",
      "Iteration: 4891; Percent complete: 97.8%; Average loss: 3.0978 Perplexity: 22.1501\n",
      "Iteration: 4892; Percent complete: 97.8%; Average loss: 2.9748 Perplexity: 19.5851\n",
      "Iteration: 4893; Percent complete: 97.9%; Average loss: 3.5143 Perplexity: 33.5910\n",
      "Iteration: 4894; Percent complete: 97.9%; Average loss: 3.4072 Perplexity: 30.1793\n",
      "Iteration: 4895; Percent complete: 97.9%; Average loss: 3.6548 Perplexity: 38.6602\n",
      "Iteration: 4896; Percent complete: 97.9%; Average loss: 3.0395 Perplexity: 20.8945\n",
      "Iteration: 4897; Percent complete: 97.9%; Average loss: 3.8948 Perplexity: 49.1459\n",
      "Iteration: 4898; Percent complete: 98.0%; Average loss: 3.1968 Perplexity: 24.4530\n",
      "Iteration: 4899; Percent complete: 98.0%; Average loss: 3.2516 Perplexity: 25.8304\n",
      "Iteration: 4900; Percent complete: 98.0%; Average loss: 3.4189 Perplexity: 30.5347\n",
      "Iteration: 4901; Percent complete: 98.0%; Average loss: 3.1691 Perplexity: 23.7864\n",
      "Iteration: 4902; Percent complete: 98.0%; Average loss: 3.0425 Perplexity: 20.9576\n",
      "Iteration: 4903; Percent complete: 98.1%; Average loss: 3.0500 Perplexity: 21.1159\n",
      "Iteration: 4904; Percent complete: 98.1%; Average loss: 3.7098 Perplexity: 40.8437\n",
      "Iteration: 4905; Percent complete: 98.1%; Average loss: 2.8080 Perplexity: 16.5764\n",
      "Iteration: 4906; Percent complete: 98.1%; Average loss: 3.3716 Perplexity: 29.1243\n",
      "Iteration: 4907; Percent complete: 98.1%; Average loss: 3.2570 Perplexity: 25.9711\n",
      "Iteration: 4908; Percent complete: 98.2%; Average loss: 3.3495 Perplexity: 28.4895\n",
      "Iteration: 4909; Percent complete: 98.2%; Average loss: 3.3863 Perplexity: 29.5552\n",
      "Iteration: 4910; Percent complete: 98.2%; Average loss: 3.2511 Perplexity: 25.8182\n",
      "Iteration: 4911; Percent complete: 98.2%; Average loss: 3.1838 Perplexity: 24.1390\n",
      "Iteration: 4912; Percent complete: 98.2%; Average loss: 3.0687 Perplexity: 21.5149\n",
      "Iteration: 4913; Percent complete: 98.3%; Average loss: 3.3468 Perplexity: 28.4107\n",
      "Iteration: 4914; Percent complete: 98.3%; Average loss: 3.2664 Perplexity: 26.2175\n",
      "Iteration: 4915; Percent complete: 98.3%; Average loss: 3.4140 Perplexity: 30.3858\n",
      "Iteration: 4916; Percent complete: 98.3%; Average loss: 3.3580 Perplexity: 28.7321\n",
      "Iteration: 4917; Percent complete: 98.3%; Average loss: 3.0727 Perplexity: 21.6010\n",
      "Iteration: 4918; Percent complete: 98.4%; Average loss: 3.3067 Perplexity: 27.2946\n",
      "Iteration: 4919; Percent complete: 98.4%; Average loss: 3.1389 Perplexity: 23.0774\n",
      "Iteration: 4920; Percent complete: 98.4%; Average loss: 3.2716 Perplexity: 26.3539\n",
      "Iteration: 4921; Percent complete: 98.4%; Average loss: 3.2947 Perplexity: 26.9693\n",
      "Iteration: 4922; Percent complete: 98.4%; Average loss: 2.9821 Perplexity: 19.7291\n",
      "Iteration: 4923; Percent complete: 98.5%; Average loss: 3.6508 Perplexity: 38.5048\n",
      "Iteration: 4924; Percent complete: 98.5%; Average loss: 3.2984 Perplexity: 27.0682\n",
      "Iteration: 4925; Percent complete: 98.5%; Average loss: 3.3396 Perplexity: 28.2075\n",
      "Iteration: 4926; Percent complete: 98.5%; Average loss: 3.2318 Perplexity: 25.3262\n",
      "Iteration: 4927; Percent complete: 98.5%; Average loss: 3.1261 Perplexity: 22.7851\n",
      "Iteration: 4928; Percent complete: 98.6%; Average loss: 2.9837 Perplexity: 19.7614\n",
      "Iteration: 4929; Percent complete: 98.6%; Average loss: 3.0361 Perplexity: 20.8245\n",
      "Iteration: 4930; Percent complete: 98.6%; Average loss: 3.1811 Perplexity: 24.0727\n",
      "Iteration: 4931; Percent complete: 98.6%; Average loss: 3.2524 Perplexity: 25.8515\n",
      "Iteration: 4932; Percent complete: 98.6%; Average loss: 3.0817 Perplexity: 21.7948\n",
      "Iteration: 4933; Percent complete: 98.7%; Average loss: 2.9377 Perplexity: 18.8716\n",
      "Iteration: 4934; Percent complete: 98.7%; Average loss: 3.1984 Perplexity: 24.4943\n",
      "Iteration: 4935; Percent complete: 98.7%; Average loss: 2.7821 Perplexity: 16.1526\n",
      "Iteration: 4936; Percent complete: 98.7%; Average loss: 3.4828 Perplexity: 32.5504\n",
      "Iteration: 4937; Percent complete: 98.7%; Average loss: 3.3701 Perplexity: 29.0802\n",
      "Iteration: 4938; Percent complete: 98.8%; Average loss: 3.4724 Perplexity: 32.2132\n",
      "Iteration: 4939; Percent complete: 98.8%; Average loss: 3.0375 Perplexity: 20.8522\n",
      "Iteration: 4940; Percent complete: 98.8%; Average loss: 3.0826 Perplexity: 21.8157\n",
      "Iteration: 4941; Percent complete: 98.8%; Average loss: 3.2035 Perplexity: 24.6192\n",
      "Iteration: 4942; Percent complete: 98.8%; Average loss: 3.1228 Perplexity: 22.7102\n",
      "Iteration: 4943; Percent complete: 98.9%; Average loss: 3.1596 Perplexity: 23.5601\n",
      "Iteration: 4944; Percent complete: 98.9%; Average loss: 3.4102 Perplexity: 30.2719\n",
      "Iteration: 4945; Percent complete: 98.9%; Average loss: 2.9241 Perplexity: 18.6176\n",
      "Iteration: 4946; Percent complete: 98.9%; Average loss: 3.2492 Perplexity: 25.7692\n",
      "Iteration: 4947; Percent complete: 98.9%; Average loss: 3.3350 Perplexity: 28.0784\n",
      "Iteration: 4948; Percent complete: 99.0%; Average loss: 3.2528 Perplexity: 25.8623\n",
      "Iteration: 4949; Percent complete: 99.0%; Average loss: 3.3173 Perplexity: 27.5866\n",
      "Iteration: 4950; Percent complete: 99.0%; Average loss: 3.0191 Perplexity: 20.4735\n",
      "Iteration: 4951; Percent complete: 99.0%; Average loss: 3.0881 Perplexity: 21.9361\n",
      "Iteration: 4952; Percent complete: 99.0%; Average loss: 3.1841 Perplexity: 24.1466\n",
      "Iteration: 4953; Percent complete: 99.1%; Average loss: 3.0177 Perplexity: 20.4448\n",
      "Iteration: 4954; Percent complete: 99.1%; Average loss: 3.2918 Perplexity: 26.8909\n",
      "Iteration: 4955; Percent complete: 99.1%; Average loss: 3.2539 Perplexity: 25.8918\n",
      "Iteration: 4956; Percent complete: 99.1%; Average loss: 2.8699 Perplexity: 17.6347\n",
      "Iteration: 4957; Percent complete: 99.1%; Average loss: 3.1524 Perplexity: 23.3920\n",
      "Iteration: 4958; Percent complete: 99.2%; Average loss: 3.2146 Perplexity: 24.8925\n",
      "Iteration: 4959; Percent complete: 99.2%; Average loss: 3.2690 Perplexity: 26.2860\n",
      "Iteration: 4960; Percent complete: 99.2%; Average loss: 3.4532 Perplexity: 31.6008\n",
      "Iteration: 4961; Percent complete: 99.2%; Average loss: 3.1846 Perplexity: 24.1577\n",
      "Iteration: 4962; Percent complete: 99.2%; Average loss: 3.3446 Perplexity: 28.3498\n",
      "Iteration: 4963; Percent complete: 99.3%; Average loss: 3.1427 Perplexity: 23.1656\n",
      "Iteration: 4964; Percent complete: 99.3%; Average loss: 3.3218 Perplexity: 27.7116\n",
      "Iteration: 4965; Percent complete: 99.3%; Average loss: 3.5163 Perplexity: 33.6604\n",
      "Iteration: 4966; Percent complete: 99.3%; Average loss: 3.3133 Perplexity: 27.4749\n",
      "Iteration: 4967; Percent complete: 99.3%; Average loss: 3.0332 Perplexity: 20.7628\n",
      "Iteration: 4968; Percent complete: 99.4%; Average loss: 3.3262 Perplexity: 27.8326\n",
      "Iteration: 4969; Percent complete: 99.4%; Average loss: 3.3762 Perplexity: 29.2607\n",
      "Iteration: 4970; Percent complete: 99.4%; Average loss: 3.0687 Perplexity: 21.5130\n",
      "Iteration: 4971; Percent complete: 99.4%; Average loss: 2.9347 Perplexity: 18.8151\n",
      "Iteration: 4972; Percent complete: 99.4%; Average loss: 3.3198 Perplexity: 27.6559\n",
      "Iteration: 4973; Percent complete: 99.5%; Average loss: 3.4929 Perplexity: 32.8810\n",
      "Iteration: 4974; Percent complete: 99.5%; Average loss: 3.1245 Perplexity: 22.7492\n",
      "Iteration: 4975; Percent complete: 99.5%; Average loss: 3.6052 Perplexity: 36.7901\n",
      "Iteration: 4976; Percent complete: 99.5%; Average loss: 3.1941 Perplexity: 24.3871\n",
      "Iteration: 4977; Percent complete: 99.5%; Average loss: 3.3855 Perplexity: 29.5322\n",
      "Iteration: 4978; Percent complete: 99.6%; Average loss: 3.1805 Perplexity: 24.0584\n",
      "Iteration: 4979; Percent complete: 99.6%; Average loss: 3.2902 Perplexity: 26.8469\n",
      "Iteration: 4980; Percent complete: 99.6%; Average loss: 2.8015 Perplexity: 16.4692\n",
      "Iteration: 4981; Percent complete: 99.6%; Average loss: 2.9648 Perplexity: 19.3900\n",
      "Iteration: 4982; Percent complete: 99.6%; Average loss: 3.2666 Perplexity: 26.2222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4983; Percent complete: 99.7%; Average loss: 3.1876 Perplexity: 24.2299\n",
      "Iteration: 4984; Percent complete: 99.7%; Average loss: 3.0721 Perplexity: 21.5882\n",
      "Iteration: 4985; Percent complete: 99.7%; Average loss: 2.9787 Perplexity: 19.6621\n",
      "Iteration: 4986; Percent complete: 99.7%; Average loss: 3.0946 Perplexity: 22.0793\n",
      "Iteration: 4987; Percent complete: 99.7%; Average loss: 2.8371 Perplexity: 17.0663\n",
      "Iteration: 4988; Percent complete: 99.8%; Average loss: 3.4621 Perplexity: 31.8835\n",
      "Iteration: 4989; Percent complete: 99.8%; Average loss: 2.9614 Perplexity: 19.3248\n",
      "Iteration: 4990; Percent complete: 99.8%; Average loss: 3.3500 Perplexity: 28.5038\n",
      "Iteration: 4991; Percent complete: 99.8%; Average loss: 3.0944 Perplexity: 22.0732\n",
      "Iteration: 4992; Percent complete: 99.8%; Average loss: 3.2218 Perplexity: 25.0723\n",
      "Iteration: 4993; Percent complete: 99.9%; Average loss: 2.9366 Perplexity: 18.8523\n",
      "Iteration: 4994; Percent complete: 99.9%; Average loss: 3.3008 Perplexity: 27.1346\n",
      "Iteration: 4995; Percent complete: 99.9%; Average loss: 3.2330 Perplexity: 25.3557\n",
      "Iteration: 4996; Percent complete: 99.9%; Average loss: 3.3882 Perplexity: 29.6125\n",
      "Iteration: 4997; Percent complete: 99.9%; Average loss: 3.2294 Perplexity: 25.2636\n",
      "Iteration: 4998; Percent complete: 100.0%; Average loss: 3.4301 Perplexity: 30.8807\n",
      "Iteration: 4999; Percent complete: 100.0%; Average loss: 3.1257 Perplexity: 22.7756\n",
      "Iteration: 5000; Percent complete: 100.0%; Average loss: 3.1241 Perplexity: 22.7401\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 5000\n",
    "print_every = 1\n",
    "save_every = 300\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, \"story\", loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Evaluation\n",
    "~~~~~~~~~~~~~~\n",
    "\n",
    "To chat with your model, run the following block.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'encoder': encoder.state_dict(),\n",
    "            'decoder': decoder.state_dict(),\n",
    "            'en_opt': encoder_optimizer.state_dict(),\n",
    "            'de_opt': decoder_optimizer.state_dict(),\n",
    "            }, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model')\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "decoder.load_state_dict(checkpoint['decoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(encoder_sd)\n",
    "LuongAttnDecoderRNN.load_state_dict(decoder_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> a city street with a man in the background\n",
      "Bot: t h e   m a n   i s   s o   b a d   h e   s   g o i n g   t o   b e   t h e   o n e   t o   g e t   t h e   n e w   m o m e n t   .\n",
      "> a man is cutting a pizza with a knife\n",
      "Bot: h e   s   g o i n g   t o   b e   t h e   o n e   t o   t e l l   h e r   h e   s   s t i l l   s t i l l   i n   t h e   h o s p i t a l   .\n",
      "> a close up of a plate of broccoli and meat\n",
      "Error: Encountered unknown word.\n",
      ">  a close up of a plate of broccoli and meat\n",
      "Error: Encountered unknown word.\n",
      "> a bear is walking through the water near a forest\n",
      "Bot: i n   o t h e r   w o r d s   t h e   p o p e   i s   s t i l l   i n   t h e   m i d d l e   o f   t h e   f i e l d   .\n",
      "> a skier is coming down the slope on a sunny day\n",
      "Error: Encountered unknown word.\n",
      "> a woman walking down a street holding an umbrella\n",
      "Bot: t h e   w o m a n   i s   s o   b a d   h e   w a s   a b l e   t o   b e   t o u c h e d   t h e   p h r a s e   h e y   i   m   i n v e s t i g a t i n   h e r e   !\n",
      ">  a dog is laying on a blanket on a bed\n",
      "Error: Encountered unknown word.\n",
      "> a group of people sitting around a table with a cake on it\n",
      "Bot: t h e   s i g n a l s   a l s o   f o u n d   t h a t   t h e   g u y   w h o   h a s   t h e   h e a r t   t o   b e   c a l l e d   t h e   c a s t   o f   c o l l e g e   .\n",
      "> a man riding a skateboard down a street\n",
      "Bot: t h e   m a n   i s   s o   u g l y   h e   s   g o i n g   t o   b e   a   h u g e   p l a y e r   .\n",
      "> a red stop sign sitting on top of a sandy beach\n",
      "Bot: t h e   w o m a n   i s   t h e   o n l y   t h i n g   t h a t   s   n o t   t h e   o n l y   t h i n g   i   m   n o t   a   w o m a n   w h o   s t o l e   t h e   b a b y   .\n",
      "> a baseball player is swinging his bat at a ball\n",
      "Error: Encountered unknown word.\n",
      "> a table with a bunch of different items on it\n",
      "Bot: t h e   s i g n a l s   a l s o   f o u n d   t h a t   t h e   g u y   w h o   m a d e   t h e   n e w s   .\n",
      "> a bird flying over a body of water\n",
      "Bot: i t   s   t h e   f i r s t   t i m e   a   b u n c h   o f   t h r o n e s   i s   n o w   t h a t   i t   s   e a s i e r   t o   s e e   h o w   m u c h   c a s h   t h e y   c a n   g e t   f o r   t h e   t o i l e t   .\n",
      "> a woman is holding a cell phone in her hand\n",
      "Bot: i n   o t h e r   w o r d s   t h e   g u y   w h o   h a s   t o   d o   w i t h   t h e   h e l l   s h e   h a d   t o   d o   w i t h   h e r   .\n",
      "> a group of people standing outside of a building\n",
      "Bot: i t   s   t h e   f i r s t   t i m e   t h e   p o s s i b i l i t y   w a s   m a d e   b y   a   h u g e   m a n   c a l l e d   t h e   m e t e r   w a n d e r   .\n",
      "> a boat is docked at a dock in the water\n",
      "Error: Encountered unknown word.\n",
      ">  a person flying a kite in a field\n",
      "Error: Encountered unknown word.\n",
      "> a teddy bear sitting on a blanket on a train track\n",
      "Error: Encountered unknown word.\n",
      "> a refrigerator with a lot of food on it\n",
      "Bot: t h e   s i g n a l s   a l s o   f o u n d   t h a t   t h e   g u y   w h o   h a s   t h e   h e a r t   t o   t e l l   t h e   m o t h e r   i t   s   t h e   f i r s t   t h i n g   y o u   r e   g o i n g   t o   d o   t h a t   ?\n",
      "> a stop sign with a red arrow on it\n",
      "Error: Encountered unknown word.\n",
      "> 'a', 'person', 'flying', 'a', 'kite', 'in', 'the', ‘sky'\n",
      "Error: Encountered unknown word.\n",
      "> 'a', 'baseball', 'player', 'is', 'swinging', 'at', 'a', ‘pitch'\n",
      "Error: Encountered unknown word.\n",
      "> a person flying a kite in the sky\n",
      "Error: Encountered unknown word.\n",
      "> a baseball player is swinging at a pitch\n",
      "Error: Encountered unknown word.\n",
      "> a cup of coffee and a cup of coffee\n",
      "Bot: t h e   s t o r e   i s   c a l l e d   t h e   s t o r e   .\n",
      "> a living room with a couch and a couch\n",
      "Bot: i n   r e s p o n s e   t h e   c e o   o f   t h e   m a n   s a i d   h e   s   s t i l l   t r y i n g   t o   t a l k   a   w o m a n   t o   b e   a   d o c t o r   .\n",
      ">  a large clock on a shelf in a room\n",
      "Bot: t h e   s i g n a l s   s a i d   t h a t   s   t h e   f i r s t   t h i n g   i   h a v e   t o   m o v e   i n   w i t h   t h e   p e o p l e   o f   c e l i b a c y   c r u i s i n g   t o   t w e r k   .\n"
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, searcher,voc, pair[0])\n",
    "        # Format and print response sentence\n",
    "        #output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "        final_output = []\n",
    "        for x in output_words:\n",
    "            if not (x == 'EOS' or x == 'PAD'):\n",
    "                final_output.append(x)\n",
    "            elif (x == 'EOS'):\n",
    "                break;\n",
    "        output_sentence = ' '.join(final_output)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> oprah winfrey is now th on fortune s list of most powerful women in business \n",
      "= in a related story oprah winfrey just released o magazine s list of women to destroy .\n",
      "< in a related story the report said you know what ? i m going to do to be a job ?\n",
      "\n",
      "> michigan has put forth a plan to give visas to immigrants if they promise to spend five years living in detroit \n",
      "= when they heard immigrants from dozens of impoverished war torn countries said we re good .\n",
      "< the ceo said they re going to be the one to tell it to the people who make them .\n",
      "\n",
      "> kobe bryant has a lot of work to do to get ready for the season \n",
      "= we just played one on one and he only beat me .\n",
      "< the first thing that s the first time you re the first time in the show that you re the same season .\n",
      "\n",
      "> in florida justin bieber was arrested for dui \n",
      "= police reports said bieber s blood contained large amounts of alcohol pot and flinstones chewables .\n",
      "< he said he can t wait to rent his name to his th view of his car .\n",
      "\n",
      "> today the orioles and the white sox played their game in front of a completely empty stadium \n",
      "= it was the first major sporting event to be played for an empty stadium unless you count every professional soccer game in america .\n",
      "< the secret service agents are being called the police in the race .\n",
      "\n",
      "> two parents in canada are weaning their kids off technology by banning any device invented after \n",
      "= the children describe their parents as total donkey kongs who should go fax themselves .\n",
      "< the woman was not as armed and not as well as they have sex .\n",
      "\n",
      "> the stock market dropped points today because standard and poor s downgraded our credit rating from aaa to aa \n",
      "= on the bright side pat sajak has offered to sell us another a for trillion .\n",
      "< the first thing is the most popular news to tell the movie is they re going to watch the bathroom .\n",
      "\n",
      "> the online dating site match .com says it will begin screening its members against a sex offender registry \n",
      "= the site expects to be pervert free by july and out of business by august .\n",
      "< the new device is called a sex .\n",
      "\n",
      "> disney has confirmed there will be a sequel to frozen \n",
      "= in this one princess elsa moves to boston to see what a real winter looks like .\n",
      "< the survey is called the tsa is available .\n",
      "\n",
      "> visitors to the winter olympics in sochi are reporting horror stories of rooms without heat hot water or working toilets \n",
      "= which explains why these olympics are being sponsored by royal caribbean cruises .\n",
      "< which explains why the most popular pope choices had the cave of hidden .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words = evaluate(encoder, decoder, searcher,voc, \"play station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< I 'm not a good man . I 'm not a good thing . <newline> <newline> I 'm not a good , but I 'm not a good . <newline> <newline> I 'm not a good , but I 'm not a good . <newline> <newline> I 'm not a good , but I 'm not a good . <newline> <newline> I 'm not a good , but I 'm not a good . EOS , I 'm not a good . EOS , I 'm not a good . EOS , I 'm not a good . EOS , I 'm not a good . EOS , I 'm not a good . EOS , I 'm not a good . EOS , I 'm not a good . EOS , I 'm not a good . EOS , I 'm not a good . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS . EOS .\n"
     ]
    }
   ],
   "source": [
    "output_sentence = ' '.join(output_words)\n",
    "print('<', output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "That’s all for this one, folks. Congratulations, you now know the\n",
    "fundamentals to building a generative chatbot model! If you’re\n",
    "interested, you can try tailoring the chatbot’s behavior by tweaking the\n",
    "model and training parameters and customizing the data that you train\n",
    "the model on.\n",
    "\n",
    "Check out the other tutorials for more cool deep learning applications\n",
    "in PyTorch!\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
